[0m11:06:07.075215 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029C771B67B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029C752E1590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029C77E60F50>]}


============================== 11:06:07.087257 | 1ffd9f8d-d154-481c-af20-0666825e5246 ==============================
[0m11:06:07.087257 [info ] [MainThread]: Running with dbt=1.9.3
[0m11:06:07.088698 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\karak\\.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\karak\\dbt_cursor\\analytics_project\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m11:06:07.312415 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1ffd9f8d-d154-481c-af20-0666825e5246', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029C78934E90>]}
[0m11:06:07.378746 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1ffd9f8d-d154-481c-af20-0666825e5246', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029C781DFF00>]}
[0m11:06:07.380572 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m11:06:07.629593 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m11:06:07.630849 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m11:06:07.631814 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '1ffd9f8d-d154-481c-af20-0666825e5246', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029C781B2B50>]}
[0m11:06:08.765138 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.analytics_project.analytics_orders' (models\example\analytics_orders.sql) depends on a node named 'stg_orders' in package or project 'ecommerce_project' which was not found
[0m11:06:08.767148 [debug] [MainThread]: Command `dbt run` failed at 11:06:08.766916 after 2.01 seconds
[0m11:06:08.767732 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029C78B62120>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029C78B60F50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029C79CE99B0>]}
[0m11:06:08.768301 [debug] [MainThread]: Flushing usage events
[0m11:06:10.953201 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:14:17.390613 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A6BB8DA7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A6B99D5590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A6BC580F50>]}


============================== 11:14:17.403211 | 5e2c5d54-547b-4fb3-b3ba-42941f7c44d1 ==============================
[0m11:14:17.403211 [info ] [MainThread]: Running with dbt=1.9.3
[0m11:14:17.404466 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\karak\\.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\karak\\dbt_cursor\\analytics_project\\logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt docs generate', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:14:17.658874 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5e2c5d54-547b-4fb3-b3ba-42941f7c44d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A6BCC20FC0>]}
[0m11:14:17.734322 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5e2c5d54-547b-4fb3-b3ba-42941f7c44d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A6BC8FFF00>]}
[0m11:14:17.736333 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m11:14:17.944515 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m11:14:17.945762 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m11:14:17.946805 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '5e2c5d54-547b-4fb3-b3ba-42941f7c44d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A6BC8D2B50>]}
[0m11:14:19.087672 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.analytics_project.analytics_orders' (models\example\analytics_orders.sql) depends on a node named 'stg_orders' in package or project 'ecommerce_project' which was not found
[0m11:14:19.089220 [debug] [MainThread]: Command `dbt docs generate` failed at 11:14:19.089029 after 2.00 seconds
[0m11:14:19.089701 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A6BD1B6210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A6BD1B5040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A6BE33D710>]}
[0m11:14:19.090137 [debug] [MainThread]: Flushing usage events
[0m11:14:20.449901 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:55:37.963251 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014D3CD9A7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014D3AE95590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014D3DA40F50>]}


============================== 11:55:37.974614 | ad68a81a-f30c-4e3f-a14b-134356e123c5 ==============================
[0m11:55:37.974614 [info ] [MainThread]: Running with dbt=1.9.3
[0m11:55:37.976808 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\karak\\.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\karak\\dbt_cursor\\analytics_project\\logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:55:38.187162 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ad68a81a-f30c-4e3f-a14b-134356e123c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014D3E514E90>]}
[0m11:55:38.254205 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ad68a81a-f30c-4e3f-a14b-134356e123c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014D3DDBBF00>]}
[0m11:55:38.255821 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m11:55:38.465045 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m11:55:38.466306 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m11:55:38.467322 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ad68a81a-f30c-4e3f-a14b-134356e123c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014D3DD92B50>]}
[0m11:55:39.400350 [error] [MainThread]: Encountered an error:
Compilation Error in model analytics_orders (models\example\analytics_orders.sql)
  invalid syntax for function call expression
    line 1
      {{ config(
[0m11:55:39.401845 [debug] [MainThread]: Command `dbt run` failed at 11:55:39.401657 after 1.63 seconds
[0m11:55:39.402310 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014D3E6E1E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014D3E6E26C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014D3DDEBE70>]}
[0m11:55:39.402756 [debug] [MainThread]: Flushing usage events
[0m11:55:40.754720 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:59:11.767265 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024C883DA7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024C864D1590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024C89080F50>]}


============================== 11:59:11.777769 | bcccd306-a103-4087-8559-de5447e0859d ==============================
[0m11:59:11.777769 [info ] [MainThread]: Running with dbt=1.9.3
[0m11:59:11.778860 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\karak\\.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\karak\\dbt_cursor\\analytics_project\\logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m11:59:12.006803 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bcccd306-a103-4087-8559-de5447e0859d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024C89A74E90>]}
[0m11:59:12.077868 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bcccd306-a103-4087-8559-de5447e0859d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024C893FFF00>]}
[0m11:59:12.079484 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m11:59:12.289579 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m11:59:12.290899 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m11:59:12.291860 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'bcccd306-a103-4087-8559-de5447e0859d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024C893D2B50>]}
[0m11:59:13.448676 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.analytics_project.analytics_orders' (models\example\analytics_orders.sql) depends on a node named 'stg_orders' which was not found
[0m11:59:13.450098 [debug] [MainThread]: Command `dbt run` failed at 11:59:13.449935 after 1.98 seconds
[0m11:59:13.450568 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024C89CA0500>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024C89CA19A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024C8AE319B0>]}
[0m11:59:13.450986 [debug] [MainThread]: Flushing usage events
[0m11:59:15.067052 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:27:32.861590 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB515967B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB4F69D590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB52240F50>]}


============================== 13:27:32.868824 | cdd35612-6278-46e2-a4b0-f6c3cf64e8ac ==============================
[0m13:27:32.868824 [info ] [MainThread]: Running with dbt=1.9.3
[0m13:27:32.869561 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\karak\\.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\karak\\dbt_cursor\\analytics_project\\logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m13:27:32.888229 [info ] [MainThread]: dbt version: 1.9.3
[0m13:27:32.888881 [info ] [MainThread]: python version: 3.13.1
[0m13:27:32.889262 [info ] [MainThread]: python path: C:\Users\karak\dbt_cursor\dbt-env\Scripts\python.exe
[0m13:27:32.889726 [info ] [MainThread]: os info: Windows-11-10.0.26100-SP0
[0m13:27:32.948510 [info ] [MainThread]: Using profiles dir at C:\Users\karak\.dbt
[0m13:27:32.949089 [info ] [MainThread]: Using profiles.yml file at C:\Users\karak\.dbt\profiles.yml
[0m13:27:32.949434 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\karak\dbt_cursor\analytics_project\dbt_project.yml
[0m13:27:32.950451 [info ] [MainThread]: adapter type: postgres
[0m13:27:32.950971 [info ] [MainThread]: adapter version: 1.9.0
[0m13:27:33.032657 [info ] [MainThread]: Configuration:
[0m13:27:33.033308 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m13:27:33.033579 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m13:27:33.033819 [info ] [MainThread]: Required dependencies:
[0m13:27:33.034109 [debug] [MainThread]: Executing "git --help"
[0m13:27:33.082025 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--config-env=<name>=<envvar>] <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m13:27:33.082435 [debug] [MainThread]: STDERR: "b''"
[0m13:27:33.082756 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m13:27:33.083346 [info ] [MainThread]: Connection:
[0m13:27:33.083899 [info ] [MainThread]:   host: localhost
[0m13:27:33.084475 [info ] [MainThread]:   port: 5434
[0m13:27:33.084906 [info ] [MainThread]:   user: postgres
[0m13:27:33.085373 [info ] [MainThread]:   database: dbt_sample
[0m13:27:33.085870 [info ] [MainThread]:   schema: analytics_schema
[0m13:27:33.086413 [info ] [MainThread]:   connect_timeout: 10
[0m13:27:33.086813 [info ] [MainThread]:   role: None
[0m13:27:33.087131 [info ] [MainThread]:   search_path: None
[0m13:27:33.087493 [info ] [MainThread]:   keepalives_idle: 0
[0m13:27:33.087896 [info ] [MainThread]:   sslmode: None
[0m13:27:33.088388 [info ] [MainThread]:   sslcert: None
[0m13:27:33.088823 [info ] [MainThread]:   sslkey: None
[0m13:27:33.089264 [info ] [MainThread]:   sslrootcert: None
[0m13:27:33.089664 [info ] [MainThread]:   application_name: dbt
[0m13:27:33.090068 [info ] [MainThread]:   retries: 1
[0m13:27:33.090707 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m13:27:33.260059 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m13:27:33.294826 [debug] [MainThread]: Using postgres connection "debug"
[0m13:27:33.295153 [debug] [MainThread]: On debug: select 1 as id
[0m13:27:33.295393 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:27:33.331690 [debug] [MainThread]: SQL status: SELECT 1 in 0.036 seconds
[0m13:27:33.332454 [debug] [MainThread]: On debug: Close
[0m13:27:33.332745 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m13:27:33.333625 [info ] [MainThread]: [32mAll checks passed![0m
[0m13:27:33.334778 [debug] [MainThread]: Command `dbt debug` succeeded at 13:27:33.334573 after 0.65 seconds
[0m13:27:33.335436 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m13:27:33.335737 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB52D3BE10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB52E41490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB527A79B0>]}
[0m13:27:33.336111 [debug] [MainThread]: Flushing usage events
[0m13:27:34.282939 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:28:48.115462 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9916967B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E98F795590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E992350F50>]}


============================== 13:28:48.122955 | c03c0c81-8e56-4ae0-b229-defb06c884cc ==============================
[0m13:28:48.122955 [info ] [MainThread]: Running with dbt=1.9.3
[0m13:28:48.123629 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\karak\\.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\karak\\dbt_cursor\\analytics_project\\logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select analytics_orders', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m13:28:48.261887 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c03c0c81-8e56-4ae0-b229-defb06c884cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E992D94E90>]}
[0m13:28:48.308738 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c03c0c81-8e56-4ae0-b229-defb06c884cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9926CFF00>]}
[0m13:28:48.310056 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m13:28:48.452668 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m13:28:48.453571 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m13:28:48.454192 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'c03c0c81-8e56-4ae0-b229-defb06c884cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9926A2B50>]}
[0m13:28:49.192838 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.analytics_project.analytics_orders' (models\example\analytics_orders.sql) depends on a node named 'stg_orders' which was not found
[0m13:28:49.193836 [debug] [MainThread]: Command `dbt run` failed at 13:28:49.193699 after 1.35 seconds
[0m13:28:49.194134 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E992FC0500>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E992FC19A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E99414D9B0>]}
[0m13:28:49.194418 [debug] [MainThread]: Flushing usage events
[0m13:28:50.137666 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:33:07.982242 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BE6903A7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BE6712D590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BE69CE0F50>]}


============================== 13:33:07.989305 | 30c5c566-18f7-4e34-92a2-9a6db36d89f1 ==============================
[0m13:33:07.989305 [info ] [MainThread]: Running with dbt=1.9.3
[0m13:33:07.990102 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\karak\\.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\karak\\dbt_cursor\\analytics_project\\logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt deps', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m13:33:08.067810 [error] [MainThread]: Encountered an error:
Runtime Error
  The packages.yml file in this project is malformed. Please double check
  the contents of this file and fix any errors before retrying.
  
  You can find more information on the syntax for this file here:
  https://docs.getdbt.com/docs/package-management
  
  Validator Error:
  {'local': '../ecommerce_project', 'name': 'ecommerce_project', 'unrendered': {'local': '../ecommerce_project', 'name': 'ecommerce_project'}} is not valid under any of the given schemas
  

Error encountered in C:\Users\karak\dbt_cursor\analytics_project\dbt_project.yml
[0m13:33:08.069449 [debug] [MainThread]: Command `dbt deps` failed at 13:33:08.069231 after 0.29 seconds
[0m13:33:08.069804 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BE6A251CD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BE6A299FD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BE6A05ECF0>]}
[0m13:33:08.070111 [debug] [MainThread]: Flushing usage events
[0m13:33:09.073388 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:33:23.532423 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002818A81A7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028188911590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002818B4B4F50>]}


============================== 13:33:23.539336 | b1e0db06-2db9-41e0-8386-3ded8b772a8a ==============================
[0m13:33:23.539336 [info ] [MainThread]: Running with dbt=1.9.3
[0m13:33:23.540050 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\karak\\.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\karak\\dbt_cursor\\analytics_project\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt deps', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m13:33:23.604731 [error] [MainThread]: Encountered an error:
'version'
[0m13:33:23.689875 [error] [MainThread]: Traceback (most recent call last):
  File "C:\Users\karak\dbt_cursor\dbt-env\Lib\site-packages\dbt\cli\requires.py", line 153, in wrapper
    result, success = func(*args, **kwargs)
                      ~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\karak\dbt_cursor\dbt-env\Lib\site-packages\dbt\cli\requires.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\karak\dbt_cursor\dbt-env\Lib\site-packages\dbt\cli\requires.py", line 218, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\karak\dbt_cursor\dbt-env\Lib\site-packages\dbt\cli\requires.py", line 251, in wrapper
    project = load_project(
        flags.PROJECT_DIR, flags.VERSION_CHECK, ctx.obj["profile"], flags.VARS
    )
  File "C:\Users\karak\dbt_cursor\dbt-env\Lib\site-packages\dbt\config\runtime.py", line 59, in load_project
    project = Project.from_project_root(
        project_root, project_renderer, verify_version=version_check
    )
  File "C:\Users\karak\dbt_cursor\dbt-env\Lib\site-packages\dbt\config\project.py", line 752, in from_project_root
    return partial.render(renderer)
           ~~~~~~~~~~~~~~^^^^^^^^^^
  File "C:\Users\karak\dbt_cursor\dbt-env\Lib\site-packages\dbt\config\project.py", line 321, in render
    return self.create_project(rendered)
           ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
  File "C:\Users\karak\dbt_cursor\dbt-env\Lib\site-packages\dbt\config\project.py", line 468, in create_project
    packages: PackageConfig = package_config_from_data(
                              ~~~~~~~~~~~~~~~~~~~~~~~~^
        rendered.packages_dict, unrendered.packages_dict
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\karak\dbt_cursor\dbt-env\Lib\site-packages\dbt\config\project.py", line 139, in package_config_from_data
    PackageConfig.validate(packages_data)
    ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^
  File "C:\Users\karak\dbt_cursor\dbt-env\Lib\site-packages\dbt\contracts\project.py", line 129, in validate
    if not package["version"]:
           ~~~~~~~^^^^^^^^^^^
KeyError: 'version'

[0m13:33:23.691146 [debug] [MainThread]: Command `dbt deps` failed at 13:33:23.691024 after 0.30 seconds
[0m13:33:23.691449 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002818BA31350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002818B7FD5B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002818B83F130>]}
[0m13:33:23.691747 [debug] [MainThread]: Flushing usage events
[0m13:33:24.619852 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:33:46.418670 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A9CF26A7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A9CD361590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A9CFF10F50>]}


============================== 13:33:46.425276 | 84f2a165-fe9d-465f-8a5b-3b10ef5d528a ==============================
[0m13:33:46.425276 [info ] [MainThread]: Running with dbt=1.9.3
[0m13:33:46.426060 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\karak\\dbt_cursor\\analytics_project\\logs', 'profiles_dir': 'C:\\Users\\karak\\.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m13:33:46.487734 [error] [MainThread]: Encountered an error:
Runtime Error
  The packages.yml file in this project is malformed. Please double check
  the contents of this file and fix any errors before retrying.
  
  You can find more information on the syntax for this file here:
  https://docs.getdbt.com/docs/package-management
  
  Validator Error:
  ecommerce_project was not found in the package index. Packages on the index require a namespace, e.g dbt-labs/dbt_utils
  

Error encountered in C:\Users\karak\dbt_cursor\analytics_project\dbt_project.yml
[0m13:33:46.489061 [debug] [MainThread]: Command `dbt deps` failed at 13:33:46.488938 after 0.22 seconds
[0m13:33:46.489363 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A9D0481350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A9D024D5B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A9D028ECF0>]}
[0m13:33:46.489655 [debug] [MainThread]: Flushing usage events
[0m13:33:47.592659 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:46:16.316112 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025A70E3A7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025A6EF35590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025A71AE0F50>]}


============================== 14:46:16.327821 | 270d4748-9e8f-4585-9c47-1ea280eefbfd ==============================
[0m14:46:16.327821 [info ] [MainThread]: Running with dbt=1.9.3
[0m14:46:16.329173 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\karak\\.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\karak\\dbt_cursor\\analytics_project\\logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt run --select analytics_orders', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:46:16.503113 [error] [MainThread]: Encountered an error:
Runtime Error
  The packages.yml file in this project is malformed. Please double check
  the contents of this file and fix any errors before retrying.
  
  You can find more information on the syntax for this file here:
  https://docs.getdbt.com/docs/package-management
  
  Validator Error:
  ecommerce_project was not found in the package index. Packages on the index require a namespace, e.g dbt-labs/dbt_utils
  

Error encountered in C:\Users\karak\dbt_cursor\analytics_project\dbt_project.yml
[0m14:46:16.504491 [debug] [MainThread]: Command `dbt run` failed at 14:46:16.504335 after 0.47 seconds
[0m14:46:16.504852 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025A721843E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025A72128EF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025A71E5A7A0>]}
[0m14:46:16.505215 [debug] [MainThread]: Flushing usage events
[0m14:46:17.479436 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:46:36.378187 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023E8155A7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023EFF655590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023E82200F50>]}


============================== 14:46:36.387386 | 50ff1556-7715-490b-8b9a-107fbd3bd76b ==============================
[0m14:46:36.387386 [info ] [MainThread]: Running with dbt=1.9.3
[0m14:46:36.388501 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\karak\\.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'C:\\Users\\karak\\dbt_cursor\\analytics_project\\logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select analytics_orders', 'send_anonymous_usage_stats': 'True'}
[0m14:46:36.585776 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '50ff1556-7715-490b-8b9a-107fbd3bd76b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023E828A4E90>]}
[0m14:46:36.651765 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '50ff1556-7715-490b-8b9a-107fbd3bd76b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023E8257FF00>]}
[0m14:46:36.653179 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m14:46:36.862628 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m14:46:36.863862 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:46:36.864461 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '50ff1556-7715-490b-8b9a-107fbd3bd76b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023E82552B50>]}
[0m14:46:37.697494 [error] [MainThread]: Encountered an error:
Compilation Error in model analytics_orders (models\example\analytics_orders.sql)
  expected token ',', got 'where'
    line 3
      schema='analytics_schema'  -- This is the schema where the model will be created
[0m14:46:37.698670 [debug] [MainThread]: Command `dbt run` failed at 14:46:37.698504 after 1.52 seconds
[0m14:46:37.699065 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023E82E51E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023E82E526C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023E825ABE70>]}
[0m14:46:37.699430 [debug] [MainThread]: Flushing usage events
[0m14:46:39.120618 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:46:58.699250 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000177104067B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001770E505590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000177110C0F50>]}


============================== 14:46:58.708299 | 791d7617-7226-4fe5-aaea-29218604f2f8 ==============================
[0m14:46:58.708299 [info ] [MainThread]: Running with dbt=1.9.3
[0m14:46:58.709209 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\karak\\dbt_cursor\\analytics_project\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\karak\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt run --select analytics_orders', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:46:58.897536 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '791d7617-7226-4fe5-aaea-29218604f2f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017711AF4E90>]}
[0m14:46:58.958705 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '791d7617-7226-4fe5-aaea-29218604f2f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001771143BF00>]}
[0m14:46:58.960563 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m14:46:59.154188 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m14:46:59.155682 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:46:59.156521 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '791d7617-7226-4fe5-aaea-29218604f2f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017711412B50>]}
[0m14:47:00.391860 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '791d7617-7226-4fe5-aaea-29218604f2f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017711CC32F0>]}
[0m14:47:00.472158 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\karak\dbt_cursor\analytics_project\target\manifest.json
[0m14:47:00.485397 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\karak\dbt_cursor\analytics_project\target\semantic_manifest.json
[0m14:47:00.525122 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '791d7617-7226-4fe5-aaea-29218604f2f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017712E37070>]}
[0m14:47:00.525849 [info ] [MainThread]: Found 3 models, 3 data tests, 2 sources, 433 macros
[0m14:47:00.526489 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '791d7617-7226-4fe5-aaea-29218604f2f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017712EEE8F0>]}
[0m14:47:00.528275 [info ] [MainThread]: 
[0m14:47:00.528986 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:47:00.529623 [info ] [MainThread]: 
[0m14:47:00.530346 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:47:00.531424 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbt_sample'
[0m14:47:00.616945 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample"
[0m14:47:00.617366 [debug] [ThreadPool]: On list_dbt_sample: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample"} */

    select distinct nspname from pg_namespace
  
[0m14:47:00.617651 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:47:00.666609 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.049 seconds
[0m14:47:00.667964 [debug] [ThreadPool]: On list_dbt_sample: Close
[0m14:47:00.668853 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dbt_sample, now create_dbt_sample_analytics_schema_analytics_schema)
[0m14:47:00.669497 [debug] [ThreadPool]: Creating schema "database: "dbt_sample"
schema: "analytics_schema_analytics_schema"
"
[0m14:47:00.674801 [debug] [ThreadPool]: Using postgres connection "create_dbt_sample_analytics_schema_analytics_schema"
[0m14:47:00.675318 [debug] [ThreadPool]: On create_dbt_sample_analytics_schema_analytics_schema: BEGIN
[0m14:47:00.675667 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:47:00.717689 [debug] [ThreadPool]: SQL status: BEGIN in 0.042 seconds
[0m14:47:00.718235 [debug] [ThreadPool]: Using postgres connection "create_dbt_sample_analytics_schema_analytics_schema"
[0m14:47:00.718534 [debug] [ThreadPool]: On create_dbt_sample_analytics_schema_analytics_schema: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "create_dbt_sample_analytics_schema_analytics_schema"} */
create schema if not exists "analytics_schema_analytics_schema"
[0m14:47:00.719907 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m14:47:00.720762 [debug] [ThreadPool]: On create_dbt_sample_analytics_schema_analytics_schema: COMMIT
[0m14:47:00.721091 [debug] [ThreadPool]: Using postgres connection "create_dbt_sample_analytics_schema_analytics_schema"
[0m14:47:00.721349 [debug] [ThreadPool]: On create_dbt_sample_analytics_schema_analytics_schema: COMMIT
[0m14:47:00.731129 [debug] [ThreadPool]: SQL status: COMMIT in 0.009 seconds
[0m14:47:00.731619 [debug] [ThreadPool]: On create_dbt_sample_analytics_schema_analytics_schema: Close
[0m14:47:00.736783 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbt_sample_analytics_schema'
[0m14:47:00.743627 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema"
[0m14:47:00.744066 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: BEGIN
[0m14:47:00.744334 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:47:00.785968 [debug] [ThreadPool]: SQL status: BEGIN in 0.042 seconds
[0m14:47:00.786370 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema"
[0m14:47:00.786653 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample_analytics_schema"} */
select
      'dbt_sample' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_schema'
    union all
    select
      'dbt_sample' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_schema'
    union all
    select
      'dbt_sample' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_schema'
  
[0m14:47:00.795225 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.008 seconds
[0m14:47:00.797089 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: ROLLBACK
[0m14:47:00.797668 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: Close
[0m14:47:00.798274 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dbt_sample_analytics_schema, now list_dbt_sample_analytics_schema_analytics_schema)
[0m14:47:00.800038 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema_analytics_schema"
[0m14:47:00.800482 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: BEGIN
[0m14:47:00.800761 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:47:00.842766 [debug] [ThreadPool]: SQL status: BEGIN in 0.042 seconds
[0m14:47:00.843172 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema_analytics_schema"
[0m14:47:00.843458 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample_analytics_schema_analytics_schema"} */
select
      'dbt_sample' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_schema_analytics_schema'
    union all
    select
      'dbt_sample' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_schema_analytics_schema'
    union all
    select
      'dbt_sample' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_schema_analytics_schema'
  
[0m14:47:00.849391 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.006 seconds
[0m14:47:00.850659 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: ROLLBACK
[0m14:47:00.851179 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: Close
[0m14:47:00.855403 [debug] [MainThread]: Using postgres connection "master"
[0m14:47:00.855742 [debug] [MainThread]: On master: BEGIN
[0m14:47:00.856350 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:47:00.895559 [debug] [MainThread]: SQL status: BEGIN in 0.039 seconds
[0m14:47:00.895962 [debug] [MainThread]: Using postgres connection "master"
[0m14:47:00.896320 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:47:00.904864 [debug] [MainThread]: SQL status: SELECT 9 in 0.008 seconds
[0m14:47:00.906346 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '791d7617-7226-4fe5-aaea-29218604f2f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001771309DB50>]}
[0m14:47:00.906829 [debug] [MainThread]: On master: ROLLBACK
[0m14:47:00.907803 [debug] [MainThread]: Using postgres connection "master"
[0m14:47:00.908117 [debug] [MainThread]: On master: BEGIN
[0m14:47:00.908638 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m14:47:00.908960 [debug] [MainThread]: On master: COMMIT
[0m14:47:00.909225 [debug] [MainThread]: Using postgres connection "master"
[0m14:47:00.909454 [debug] [MainThread]: On master: COMMIT
[0m14:47:00.909813 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:47:00.910088 [debug] [MainThread]: On master: Close
[0m14:47:00.915061 [debug] [Thread-1 (]: Began running node model.analytics_project.analytics_orders
[0m14:47:00.915624 [info ] [Thread-1 (]: 1 of 1 START sql view model analytics_schema_analytics_schema.analytics_orders . [RUN]
[0m14:47:00.916387 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.analytics_project.analytics_orders'
[0m14:47:00.916765 [debug] [Thread-1 (]: Began compiling node model.analytics_project.analytics_orders
[0m14:47:00.924746 [debug] [Thread-1 (]: Writing injected SQL for node "model.analytics_project.analytics_orders"
[0m14:47:00.926716 [debug] [Thread-1 (]: Began executing node model.analytics_project.analytics_orders
[0m14:47:01.002281 [debug] [Thread-1 (]: Writing runtime sql for node "model.analytics_project.analytics_orders"
[0m14:47:01.004716 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m14:47:01.005345 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: BEGIN
[0m14:47:01.006200 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:47:01.101329 [debug] [Thread-1 (]: SQL status: BEGIN in 0.095 seconds
[0m14:47:01.102011 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m14:47:01.102600 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.analytics_orders"} */

  create view "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders__dbt_tmp"
    
    
  as (
    

WITH ecommerce_orders AS (
    -- Use source() to reference ecommerce models
    SELECT * FROM "dbt_sample"."ecommerce"."stg_orders"
),
test_project_data AS (
    -- Use source() to reference test project models
    SELECT * FROM "dbt_sample"."my_test"."my_first_dbt_model"
)

SELECT
    eo.order_id,
    eo.customer_id,
    td.id as test_project_id,
    td.amount as some_metric
FROM ecommerce_orders eo
LEFT JOIN test_project_data td
ON eo.customer_id = td.order_id;
  );
[0m14:47:01.114567 [debug] [Thread-1 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 25: ON eo.customer_id = td.order_id;
                                        ^

[0m14:47:01.115272 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: ROLLBACK
[0m14:47:01.116207 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: Close
[0m14:47:01.273333 [debug] [Thread-1 (]: Database Error in model analytics_orders (models\example\analytics_orders.sql)
  syntax error at or near ";"
  LINE 25: ON eo.customer_id = td.order_id;
                                          ^
  compiled code at target\run\analytics_project\models\example\analytics_orders.sql
[0m14:47:01.276192 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '791d7617-7226-4fe5-aaea-29218604f2f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000177132D4D60>]}
[0m14:47:01.277268 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model analytics_schema_analytics_schema.analytics_orders  [[31mERROR[0m in 0.36s]
[0m14:47:01.278420 [debug] [Thread-1 (]: Finished running node model.analytics_project.analytics_orders
[0m14:47:01.279094 [debug] [Thread-4 (]: Marking all children of 'model.analytics_project.analytics_orders' to be skipped because of status 'error'.  Reason: Database Error in model analytics_orders (models\example\analytics_orders.sql)
  syntax error at or near ";"
  LINE 25: ON eo.customer_id = td.order_id;
                                          ^
  compiled code at target\run\analytics_project\models\example\analytics_orders.sql.
[0m14:47:01.281092 [debug] [MainThread]: Using postgres connection "master"
[0m14:47:01.281440 [debug] [MainThread]: On master: BEGIN
[0m14:47:01.281697 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:47:01.326861 [debug] [MainThread]: SQL status: BEGIN in 0.045 seconds
[0m14:47:01.327909 [debug] [MainThread]: On master: COMMIT
[0m14:47:01.328604 [debug] [MainThread]: Using postgres connection "master"
[0m14:47:01.329069 [debug] [MainThread]: On master: COMMIT
[0m14:47:01.329738 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:47:01.330219 [debug] [MainThread]: On master: Close
[0m14:47:01.330920 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:47:01.331302 [debug] [MainThread]: Connection 'create_dbt_sample_analytics_schema_analytics_schema' was properly closed.
[0m14:47:01.331764 [debug] [MainThread]: Connection 'list_dbt_sample_analytics_schema_analytics_schema' was properly closed.
[0m14:47:01.332127 [debug] [MainThread]: Connection 'model.analytics_project.analytics_orders' was properly closed.
[0m14:47:01.332543 [info ] [MainThread]: 
[0m14:47:01.333112 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.80 seconds (0.80s).
[0m14:47:01.334239 [debug] [MainThread]: Command end result
[0m14:47:01.353917 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\karak\dbt_cursor\analytics_project\target\manifest.json
[0m14:47:01.356478 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\karak\dbt_cursor\analytics_project\target\semantic_manifest.json
[0m14:47:01.364378 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\karak\dbt_cursor\analytics_project\target\run_results.json
[0m14:47:01.364961 [info ] [MainThread]: 
[0m14:47:01.365680 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m14:47:01.366326 [info ] [MainThread]: 
[0m14:47:01.367010 [error] [MainThread]:   Database Error in model analytics_orders (models\example\analytics_orders.sql)
  syntax error at or near ";"
  LINE 25: ON eo.customer_id = td.order_id;
                                          ^
  compiled code at target\run\analytics_project\models\example\analytics_orders.sql
[0m14:47:01.367694 [info ] [MainThread]: 
[0m14:47:01.368223 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m14:47:01.369027 [debug] [MainThread]: Command `dbt run` failed at 14:47:01.368895 after 2.84 seconds
[0m14:47:01.369395 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000177133F2670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001771323F4A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000177130324D0>]}
[0m14:47:01.369727 [debug] [MainThread]: Flushing usage events
[0m14:47:02.522195 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:47:20.336065 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002483B00A7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024839101590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002483BCC0F50>]}


============================== 14:47:20.345087 | 78bbcab9-d42f-4678-8145-7359b1fd2364 ==============================
[0m14:47:20.345087 [info ] [MainThread]: Running with dbt=1.9.3
[0m14:47:20.345976 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\karak\\dbt_cursor\\analytics_project\\logs', 'profiles_dir': 'C:\\Users\\karak\\.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select analytics_orders', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:47:20.535539 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '78bbcab9-d42f-4678-8145-7359b1fd2364', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002483C744E90>]}
[0m14:47:20.597892 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '78bbcab9-d42f-4678-8145-7359b1fd2364', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002483C03FF00>]}
[0m14:47:20.599290 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m14:47:20.785693 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m14:47:20.946171 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:47:20.946839 [debug] [MainThread]: Partial parsing: updated file: analytics_project://models\example\analytics_orders.sql
[0m14:47:21.371190 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '78bbcab9-d42f-4678-8145-7359b1fd2364', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002483D9A0E50>]}
[0m14:47:21.448887 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\karak\dbt_cursor\analytics_project\target\manifest.json
[0m14:47:21.452173 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\karak\dbt_cursor\analytics_project\target\semantic_manifest.json
[0m14:47:21.492756 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '78bbcab9-d42f-4678-8145-7359b1fd2364', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002483C92A990>]}
[0m14:47:21.493404 [info ] [MainThread]: Found 3 models, 3 data tests, 2 sources, 433 macros
[0m14:47:21.494155 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '78bbcab9-d42f-4678-8145-7359b1fd2364', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002483DAE3310>]}
[0m14:47:21.495919 [info ] [MainThread]: 
[0m14:47:21.496606 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:47:21.497221 [info ] [MainThread]: 
[0m14:47:21.497890 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:47:21.498951 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbt_sample'
[0m14:47:21.565288 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample"
[0m14:47:21.565738 [debug] [ThreadPool]: On list_dbt_sample: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample"} */

    select distinct nspname from pg_namespace
  
[0m14:47:21.566042 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:47:21.632590 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.066 seconds
[0m14:47:21.634047 [debug] [ThreadPool]: On list_dbt_sample: Close
[0m14:47:21.638962 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbt_sample_analytics_schema'
[0m14:47:21.645653 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema"
[0m14:47:21.646174 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: BEGIN
[0m14:47:21.646514 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:47:21.687715 [debug] [ThreadPool]: SQL status: BEGIN in 0.041 seconds
[0m14:47:21.688102 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema"
[0m14:47:21.688386 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample_analytics_schema"} */
select
      'dbt_sample' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_schema'
    union all
    select
      'dbt_sample' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_schema'
    union all
    select
      'dbt_sample' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_schema'
  
[0m14:47:21.695711 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.007 seconds
[0m14:47:21.696929 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: ROLLBACK
[0m14:47:21.697498 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: Close
[0m14:47:21.698198 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dbt_sample_analytics_schema, now list_dbt_sample_analytics_schema_analytics_schema)
[0m14:47:21.700049 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema_analytics_schema"
[0m14:47:21.700439 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: BEGIN
[0m14:47:21.700722 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:47:21.741166 [debug] [ThreadPool]: SQL status: BEGIN in 0.040 seconds
[0m14:47:21.741590 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema_analytics_schema"
[0m14:47:21.741962 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample_analytics_schema_analytics_schema"} */
select
      'dbt_sample' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_schema_analytics_schema'
    union all
    select
      'dbt_sample' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_schema_analytics_schema'
    union all
    select
      'dbt_sample' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_schema_analytics_schema'
  
[0m14:47:21.749060 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.007 seconds
[0m14:47:21.750352 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: ROLLBACK
[0m14:47:21.750896 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: Close
[0m14:47:21.755476 [debug] [MainThread]: Using postgres connection "master"
[0m14:47:21.756666 [debug] [MainThread]: On master: BEGIN
[0m14:47:21.757286 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:47:21.795863 [debug] [MainThread]: SQL status: BEGIN in 0.038 seconds
[0m14:47:21.796287 [debug] [MainThread]: Using postgres connection "master"
[0m14:47:21.796619 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:47:21.803084 [debug] [MainThread]: SQL status: SELECT 9 in 0.006 seconds
[0m14:47:21.804359 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '78bbcab9-d42f-4678-8145-7359b1fd2364', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002483DFE47A0>]}
[0m14:47:21.804807 [debug] [MainThread]: On master: ROLLBACK
[0m14:47:21.805299 [debug] [MainThread]: Using postgres connection "master"
[0m14:47:21.805800 [debug] [MainThread]: On master: BEGIN
[0m14:47:21.807066 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m14:47:21.807397 [debug] [MainThread]: On master: COMMIT
[0m14:47:21.807669 [debug] [MainThread]: Using postgres connection "master"
[0m14:47:21.807907 [debug] [MainThread]: On master: COMMIT
[0m14:47:21.808285 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:47:21.808565 [debug] [MainThread]: On master: Close
[0m14:47:21.814991 [debug] [Thread-1 (]: Began running node model.analytics_project.analytics_orders
[0m14:47:21.815590 [info ] [Thread-1 (]: 1 of 1 START sql view model analytics_schema_analytics_schema.analytics_orders . [RUN]
[0m14:47:21.816304 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.analytics_project.analytics_orders'
[0m14:47:21.816700 [debug] [Thread-1 (]: Began compiling node model.analytics_project.analytics_orders
[0m14:47:21.825022 [debug] [Thread-1 (]: Writing injected SQL for node "model.analytics_project.analytics_orders"
[0m14:47:21.827237 [debug] [Thread-1 (]: Began executing node model.analytics_project.analytics_orders
[0m14:47:21.864316 [debug] [Thread-1 (]: Writing runtime sql for node "model.analytics_project.analytics_orders"
[0m14:47:21.865596 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m14:47:21.865976 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: BEGIN
[0m14:47:21.866313 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:47:21.907779 [debug] [Thread-1 (]: SQL status: BEGIN in 0.041 seconds
[0m14:47:21.908233 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m14:47:21.908559 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.analytics_orders"} */

  create view "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders__dbt_tmp"
    
    
  as (
    

WITH ecommerce_orders AS (
    -- Use source() to reference ecommerce models
    SELECT * FROM "dbt_sample"."ecommerce"."stg_orders"
),
test_project_data AS (
    -- Use source() to reference test project models
    SELECT * FROM "dbt_sample"."my_test"."my_first_dbt_model"
)

SELECT
    eo.order_id,
    eo.customer_id,
    td.id as test_project_id,
    td.amount as some_metric
FROM ecommerce_orders eo
LEFT JOIN test_project_data td
ON eo.customer_id = td.order_id
  );
[0m14:47:21.913474 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "my_test.my_first_dbt_model" does not exist
LINE 15:     SELECT * FROM "dbt_sample"."my_test"."my_first_dbt_model...
                           ^

[0m14:47:21.914022 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: ROLLBACK
[0m14:47:21.914671 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: Close
[0m14:47:21.921517 [debug] [Thread-1 (]: Database Error in model analytics_orders (models\example\analytics_orders.sql)
  relation "my_test.my_first_dbt_model" does not exist
  LINE 15:     SELECT * FROM "dbt_sample"."my_test"."my_first_dbt_model...
                             ^
  compiled code at target\run\analytics_project\models\example\analytics_orders.sql
[0m14:47:21.924811 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '78bbcab9-d42f-4678-8145-7359b1fd2364', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002483DA9E750>]}
[0m14:47:21.925864 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model analytics_schema_analytics_schema.analytics_orders  [[31mERROR[0m in 0.11s]
[0m14:47:21.926707 [debug] [Thread-1 (]: Finished running node model.analytics_project.analytics_orders
[0m14:47:21.927410 [debug] [Thread-4 (]: Marking all children of 'model.analytics_project.analytics_orders' to be skipped because of status 'error'.  Reason: Database Error in model analytics_orders (models\example\analytics_orders.sql)
  relation "my_test.my_first_dbt_model" does not exist
  LINE 15:     SELECT * FROM "dbt_sample"."my_test"."my_first_dbt_model...
                             ^
  compiled code at target\run\analytics_project\models\example\analytics_orders.sql.
[0m14:47:21.929605 [debug] [MainThread]: Using postgres connection "master"
[0m14:47:21.929953 [debug] [MainThread]: On master: BEGIN
[0m14:47:21.930217 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:47:21.979591 [debug] [MainThread]: SQL status: BEGIN in 0.049 seconds
[0m14:47:21.980020 [debug] [MainThread]: On master: COMMIT
[0m14:47:21.980345 [debug] [MainThread]: Using postgres connection "master"
[0m14:47:21.980595 [debug] [MainThread]: On master: COMMIT
[0m14:47:21.981033 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:47:21.981388 [debug] [MainThread]: On master: Close
[0m14:47:21.981864 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:47:21.982254 [debug] [MainThread]: Connection 'list_dbt_sample' was properly closed.
[0m14:47:21.982625 [debug] [MainThread]: Connection 'list_dbt_sample_analytics_schema_analytics_schema' was properly closed.
[0m14:47:21.982989 [debug] [MainThread]: Connection 'model.analytics_project.analytics_orders' was properly closed.
[0m14:47:21.983387 [info ] [MainThread]: 
[0m14:47:21.983988 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.49 seconds (0.49s).
[0m14:47:21.985294 [debug] [MainThread]: Command end result
[0m14:47:22.003265 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\karak\dbt_cursor\analytics_project\target\manifest.json
[0m14:47:22.005288 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\karak\dbt_cursor\analytics_project\target\semantic_manifest.json
[0m14:47:22.015313 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\karak\dbt_cursor\analytics_project\target\run_results.json
[0m14:47:22.015719 [info ] [MainThread]: 
[0m14:47:22.016340 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m14:47:22.016945 [info ] [MainThread]: 
[0m14:47:22.017596 [error] [MainThread]:   Database Error in model analytics_orders (models\example\analytics_orders.sql)
  relation "my_test.my_first_dbt_model" does not exist
  LINE 15:     SELECT * FROM "dbt_sample"."my_test"."my_first_dbt_model...
                             ^
  compiled code at target\run\analytics_project\models\example\analytics_orders.sql
[0m14:47:22.018148 [info ] [MainThread]: 
[0m14:47:22.018730 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m14:47:22.020486 [debug] [MainThread]: Command `dbt run` failed at 14:47:22.019886 after 1.85 seconds
[0m14:47:22.021074 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002483DBC1440>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002483DCDE8F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002483DCDC870>]}
[0m14:47:22.021582 [debug] [MainThread]: Flushing usage events
[0m14:47:23.255026 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:49:32.392729 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001388037E7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000138FE42D590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013881034F50>]}


============================== 14:49:32.401427 | c8f22372-9614-44b6-994f-dd357d2e7030 ==============================
[0m14:49:32.401427 [info ] [MainThread]: Running with dbt=1.9.3
[0m14:49:32.402261 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\karak\\dbt_cursor\\analytics_project\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\karak\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run --select analytics_orders', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:49:32.601129 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c8f22372-9614-44b6-994f-dd357d2e7030', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000138816E4E90>]}
[0m14:49:32.664199 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c8f22372-9614-44b6-994f-dd357d2e7030', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000138813AFF00>]}
[0m14:49:32.665775 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m14:49:32.851595 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m14:49:33.015926 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:49:33.016676 [debug] [MainThread]: Partial parsing: updated file: analytics_project://models\sources.yml
[0m14:49:33.549880 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c8f22372-9614-44b6-994f-dd357d2e7030', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013882D12750>]}
[0m14:49:33.624926 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\karak\dbt_cursor\analytics_project\target\manifest.json
[0m14:49:33.630244 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\karak\dbt_cursor\analytics_project\target\semantic_manifest.json
[0m14:49:33.665760 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c8f22372-9614-44b6-994f-dd357d2e7030', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013882C6F5C0>]}
[0m14:49:33.666232 [info ] [MainThread]: Found 3 models, 3 data tests, 2 sources, 433 macros
[0m14:49:33.666736 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c8f22372-9614-44b6-994f-dd357d2e7030', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013882DC2350>]}
[0m14:49:33.668160 [info ] [MainThread]: 
[0m14:49:33.668646 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:49:33.669109 [info ] [MainThread]: 
[0m14:49:33.669675 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:49:33.670644 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbt_sample'
[0m14:49:33.767355 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample"
[0m14:49:33.767796 [debug] [ThreadPool]: On list_dbt_sample: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample"} */

    select distinct nspname from pg_namespace
  
[0m14:49:33.768094 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:49:33.820186 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.052 seconds
[0m14:49:33.821760 [debug] [ThreadPool]: On list_dbt_sample: Close
[0m14:49:33.828203 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbt_sample_analytics_schema'
[0m14:49:33.833344 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema"
[0m14:49:33.833707 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: BEGIN
[0m14:49:33.833960 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:49:33.875198 [debug] [ThreadPool]: SQL status: BEGIN in 0.041 seconds
[0m14:49:33.875790 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema"
[0m14:49:33.876265 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample_analytics_schema"} */
select
      'dbt_sample' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_schema'
    union all
    select
      'dbt_sample' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_schema'
    union all
    select
      'dbt_sample' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_schema'
  
[0m14:49:33.883166 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.006 seconds
[0m14:49:33.884358 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: ROLLBACK
[0m14:49:33.884916 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: Close
[0m14:49:33.885525 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dbt_sample_analytics_schema, now list_dbt_sample_analytics_schema_analytics_schema)
[0m14:49:33.887339 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema_analytics_schema"
[0m14:49:33.887749 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: BEGIN
[0m14:49:33.888393 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:49:33.928297 [debug] [ThreadPool]: SQL status: BEGIN in 0.040 seconds
[0m14:49:33.928721 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema_analytics_schema"
[0m14:49:33.929027 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample_analytics_schema_analytics_schema"} */
select
      'dbt_sample' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_schema_analytics_schema'
    union all
    select
      'dbt_sample' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_schema_analytics_schema'
    union all
    select
      'dbt_sample' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_schema_analytics_schema'
  
[0m14:49:33.934075 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m14:49:33.935168 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: ROLLBACK
[0m14:49:33.935649 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: Close
[0m14:49:33.942674 [debug] [MainThread]: Using postgres connection "master"
[0m14:49:33.943278 [debug] [MainThread]: On master: BEGIN
[0m14:49:33.943689 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:49:33.982808 [debug] [MainThread]: SQL status: BEGIN in 0.039 seconds
[0m14:49:33.983260 [debug] [MainThread]: Using postgres connection "master"
[0m14:49:33.983597 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:49:33.991790 [debug] [MainThread]: SQL status: SELECT 9 in 0.008 seconds
[0m14:49:33.993936 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c8f22372-9614-44b6-994f-dd357d2e7030', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013882E1B110>]}
[0m14:49:33.994588 [debug] [MainThread]: On master: ROLLBACK
[0m14:49:33.995236 [debug] [MainThread]: Using postgres connection "master"
[0m14:49:33.995613 [debug] [MainThread]: On master: BEGIN
[0m14:49:33.996135 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m14:49:33.996404 [debug] [MainThread]: On master: COMMIT
[0m14:49:33.996659 [debug] [MainThread]: Using postgres connection "master"
[0m14:49:33.996877 [debug] [MainThread]: On master: COMMIT
[0m14:49:33.997263 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:49:33.997674 [debug] [MainThread]: On master: Close
[0m14:49:34.002621 [debug] [Thread-1 (]: Began running node model.analytics_project.analytics_orders
[0m14:49:34.003171 [info ] [Thread-1 (]: 1 of 1 START sql view model analytics_schema_analytics_schema.analytics_orders . [RUN]
[0m14:49:34.003928 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.analytics_project.analytics_orders'
[0m14:49:34.004269 [debug] [Thread-1 (]: Began compiling node model.analytics_project.analytics_orders
[0m14:49:34.013568 [debug] [Thread-1 (]: Writing injected SQL for node "model.analytics_project.analytics_orders"
[0m14:49:34.014662 [debug] [Thread-1 (]: Began executing node model.analytics_project.analytics_orders
[0m14:49:34.052705 [debug] [Thread-1 (]: Writing runtime sql for node "model.analytics_project.analytics_orders"
[0m14:49:34.053808 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m14:49:34.054193 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: BEGIN
[0m14:49:34.054636 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:49:34.094911 [debug] [Thread-1 (]: SQL status: BEGIN in 0.040 seconds
[0m14:49:34.095371 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m14:49:34.095710 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.analytics_orders"} */

  create view "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders__dbt_tmp"
    
    
  as (
    

WITH ecommerce_orders AS (
    -- Use source() to reference ecommerce models
    SELECT * FROM "dbt_sample"."ecommerce_schema"."stg_orders"
),
test_project_data AS (
    -- Use source() to reference test project models
    SELECT * FROM "dbt_sample"."my_test"."my_first_dbt_model"
)

SELECT
    eo.order_id,
    eo.customer_id,
    td.id as test_project_id,
    td.amount as some_metric
FROM ecommerce_orders eo
LEFT JOIN test_project_data td
ON eo.customer_id = td.order_id
  );
[0m14:49:34.096509 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "ecommerce_schema.stg_orders" does not exist
LINE 11:     SELECT * FROM "dbt_sample"."ecommerce_schema"."stg_order...
                           ^

[0m14:49:34.096841 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: ROLLBACK
[0m14:49:34.097378 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: Close
[0m14:49:34.104298 [debug] [Thread-1 (]: Database Error in model analytics_orders (models\example\analytics_orders.sql)
  relation "ecommerce_schema.stg_orders" does not exist
  LINE 11:     SELECT * FROM "dbt_sample"."ecommerce_schema"."stg_order...
                             ^
  compiled code at target\run\analytics_project\models\example\analytics_orders.sql
[0m14:49:34.107485 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8f22372-9614-44b6-994f-dd357d2e7030', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000138830CEC90>]}
[0m14:49:34.108213 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model analytics_schema_analytics_schema.analytics_orders  [[31mERROR[0m in 0.10s]
[0m14:49:34.109064 [debug] [Thread-1 (]: Finished running node model.analytics_project.analytics_orders
[0m14:49:34.109628 [debug] [Thread-4 (]: Marking all children of 'model.analytics_project.analytics_orders' to be skipped because of status 'error'.  Reason: Database Error in model analytics_orders (models\example\analytics_orders.sql)
  relation "ecommerce_schema.stg_orders" does not exist
  LINE 11:     SELECT * FROM "dbt_sample"."ecommerce_schema"."stg_order...
                             ^
  compiled code at target\run\analytics_project\models\example\analytics_orders.sql.
[0m14:49:34.111521 [debug] [MainThread]: Using postgres connection "master"
[0m14:49:34.111839 [debug] [MainThread]: On master: BEGIN
[0m14:49:34.112097 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:49:34.162730 [debug] [MainThread]: SQL status: BEGIN in 0.051 seconds
[0m14:49:34.163163 [debug] [MainThread]: On master: COMMIT
[0m14:49:34.163464 [debug] [MainThread]: Using postgres connection "master"
[0m14:49:34.163712 [debug] [MainThread]: On master: COMMIT
[0m14:49:34.164153 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:49:34.164620 [debug] [MainThread]: On master: Close
[0m14:49:34.165256 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:49:34.165620 [debug] [MainThread]: Connection 'list_dbt_sample' was properly closed.
[0m14:49:34.165876 [debug] [MainThread]: Connection 'list_dbt_sample_analytics_schema_analytics_schema' was properly closed.
[0m14:49:34.166120 [debug] [MainThread]: Connection 'model.analytics_project.analytics_orders' was properly closed.
[0m14:49:34.166580 [info ] [MainThread]: 
[0m14:49:34.168273 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.50 seconds (0.50s).
[0m14:49:34.169716 [debug] [MainThread]: Command end result
[0m14:49:34.383533 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\karak\dbt_cursor\analytics_project\target\manifest.json
[0m14:49:34.385667 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\karak\dbt_cursor\analytics_project\target\semantic_manifest.json
[0m14:49:34.402881 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\karak\dbt_cursor\analytics_project\target\run_results.json
[0m14:49:34.403389 [info ] [MainThread]: 
[0m14:49:34.404166 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m14:49:34.404874 [info ] [MainThread]: 
[0m14:49:34.405673 [error] [MainThread]:   Database Error in model analytics_orders (models\example\analytics_orders.sql)
  relation "ecommerce_schema.stg_orders" does not exist
  LINE 11:     SELECT * FROM "dbt_sample"."ecommerce_schema"."stg_order...
                             ^
  compiled code at target\run\analytics_project\models\example\analytics_orders.sql
[0m14:49:34.406552 [info ] [MainThread]: 
[0m14:49:34.407168 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m14:49:34.408030 [debug] [MainThread]: Command `dbt run` failed at 14:49:34.407916 after 2.19 seconds
[0m14:49:34.408368 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000138830D2410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013882E877F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013882E86490>]}
[0m14:49:34.408746 [debug] [MainThread]: Flushing usage events
[0m14:49:35.659067 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:49:44.435788 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C182BEA7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C180CE5590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C183884F50>]}


============================== 14:49:44.446698 | 1c881e2a-952b-45b2-a025-7f58c49c24a0 ==============================
[0m14:49:44.446698 [info ] [MainThread]: Running with dbt=1.9.3
[0m14:49:44.447585 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\karak\\dbt_cursor\\analytics_project\\logs', 'profiles_dir': 'C:\\Users\\karak\\.dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run-operation show_schemas', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:49:44.649414 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1c881e2a-952b-45b2-a025-7f58c49c24a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C184314E90>]}
[0m14:49:44.715591 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1c881e2a-952b-45b2-a025-7f58c49c24a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C183C0FF00>]}
[0m14:49:44.717182 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m14:49:44.920067 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m14:49:45.082030 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:49:45.082431 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:49:45.129865 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1c881e2a-952b-45b2-a025-7f58c49c24a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C18556CD50>]}
[0m14:49:45.213832 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\karak\dbt_cursor\analytics_project\target\manifest.json
[0m14:49:45.217491 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\karak\dbt_cursor\analytics_project\target\semantic_manifest.json
[0m14:49:45.251352 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1c881e2a-952b-45b2-a025-7f58c49c24a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C183D4A990>]}
[0m14:49:45.251869 [info ] [MainThread]: Found 3 models, 3 data tests, 2 sources, 433 macros
[0m14:49:45.252457 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1c881e2a-952b-45b2-a025-7f58c49c24a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C183C3B310>]}
[0m14:49:45.253171 [debug] [MainThread]: Acquiring new postgres connection 'macro_show_schemas'
[0m14:49:45.253631 [debug] [MainThread]: Using postgres connection "macro_show_schemas"
[0m14:49:45.254086 [debug] [MainThread]: On macro_show_schemas: BEGIN
[0m14:49:45.254979 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:49:45.325335 [debug] [MainThread]: SQL status: BEGIN in 0.071 seconds
[0m14:49:45.325894 [debug] [MainThread]: On macro_show_schemas: COMMIT
[0m14:49:45.326314 [debug] [MainThread]: Using postgres connection "macro_show_schemas"
[0m14:49:45.326580 [debug] [MainThread]: On macro_show_schemas: COMMIT
[0m14:49:45.327143 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:49:45.327631 [debug] [MainThread]: On macro_show_schemas: Close
[0m14:49:45.328222 [error] [MainThread]: Encountered an error while running operation: Runtime Error
  dbt could not find a macro with the name "show_schemas" in any package
[0m14:49:45.347276 [debug] [MainThread]: Traceback (most recent call last):
  File "C:\Users\karak\dbt_cursor\dbt-env\Lib\site-packages\dbt\task\run_operation.py", line 67, in run
    self._run_unsafe(package_name, macro_name)
    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\karak\dbt_cursor\dbt-env\Lib\site-packages\dbt\task\run_operation.py", line 48, in _run_unsafe
    res = adapter.execute_macro(
        macro_name, project=package_name, kwargs=macro_kwargs, macro_resolver=self.manifest
    )
  File "C:\Users\karak\dbt_cursor\dbt-env\Lib\site-packages\dbt\adapters\base\impl.py", line 1252, in execute_macro
    raise DbtRuntimeError(
    ...<3 lines>...
    )
dbt_common.exceptions.base.DbtRuntimeError: Runtime Error
  dbt could not find a macro with the name "show_schemas" in any package

[0m14:49:45.347730 [error] [MainThread]: Encountered an error:
Internal Error
  dbt could not find a macro with the name 'show_schemas' in any package
[0m14:49:45.348867 [debug] [MainThread]: Command `dbt run-operation` failed at 14:49:45.348726 after 1.09 seconds
[0m14:49:45.349192 [debug] [MainThread]: Connection 'macro_show_schemas' was properly closed.
[0m14:49:45.349508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C18569D710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C183BE62D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C185656C90>]}
[0m14:49:45.349825 [debug] [MainThread]: Flushing usage events
[0m14:49:46.615393 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:50:03.927749 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000151635BE7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000151616B1590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015164270F50>]}


============================== 14:50:03.935592 | 8115c319-8ed3-43fc-b882-1eaa930cfcd2 ==============================
[0m14:50:03.935592 [info ] [MainThread]: Running with dbt=1.9.3
[0m14:50:03.936373 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': 'C:\\Users\\karak\\.dbt', 'log_path': 'C:\\Users\\karak\\dbt_cursor\\analytics_project\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run --select analytics_orders', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:50:04.147344 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8115c319-8ed3-43fc-b882-1eaa930cfcd2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015164C84E90>]}
[0m14:50:04.218864 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8115c319-8ed3-43fc-b882-1eaa930cfcd2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000151645EBF00>]}
[0m14:50:04.220569 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m14:50:04.425753 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m14:50:04.584192 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:50:04.584982 [debug] [MainThread]: Partial parsing: updated file: analytics_project://models\sources.yml
[0m14:50:05.163791 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8115c319-8ed3-43fc-b882-1eaa930cfcd2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015165EE2850>]}
[0m14:50:05.253951 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\karak\dbt_cursor\analytics_project\target\manifest.json
[0m14:50:05.258214 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\karak\dbt_cursor\analytics_project\target\semantic_manifest.json
[0m14:50:05.299156 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8115c319-8ed3-43fc-b882-1eaa930cfcd2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001516472AA80>]}
[0m14:50:05.299695 [info ] [MainThread]: Found 3 models, 3 data tests, 2 sources, 433 macros
[0m14:50:05.300304 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8115c319-8ed3-43fc-b882-1eaa930cfcd2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015165F92350>]}
[0m14:50:05.302295 [info ] [MainThread]: 
[0m14:50:05.303137 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:50:05.303740 [info ] [MainThread]: 
[0m14:50:05.304996 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:50:05.307574 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbt_sample'
[0m14:50:05.401921 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample"
[0m14:50:05.402584 [debug] [ThreadPool]: On list_dbt_sample: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample"} */

    select distinct nspname from pg_namespace
  
[0m14:50:05.403054 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:50:05.455756 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.053 seconds
[0m14:50:05.457082 [debug] [ThreadPool]: On list_dbt_sample: Close
[0m14:50:05.463582 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbt_sample_analytics_schema_analytics_schema'
[0m14:50:05.468624 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema_analytics_schema"
[0m14:50:05.468963 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: BEGIN
[0m14:50:05.469242 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:50:05.507968 [debug] [ThreadPool]: SQL status: BEGIN in 0.039 seconds
[0m14:50:05.508383 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema_analytics_schema"
[0m14:50:05.508681 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample_analytics_schema_analytics_schema"} */
select
      'dbt_sample' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_schema_analytics_schema'
    union all
    select
      'dbt_sample' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_schema_analytics_schema'
    union all
    select
      'dbt_sample' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_schema_analytics_schema'
  
[0m14:50:05.514511 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m14:50:05.515667 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: ROLLBACK
[0m14:50:05.516180 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: Close
[0m14:50:05.516762 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dbt_sample_analytics_schema_analytics_schema, now list_dbt_sample_analytics_schema)
[0m14:50:05.518935 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema"
[0m14:50:05.519287 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: BEGIN
[0m14:50:05.519567 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:50:05.559746 [debug] [ThreadPool]: SQL status: BEGIN in 0.040 seconds
[0m14:50:05.560211 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema"
[0m14:50:05.560530 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample_analytics_schema"} */
select
      'dbt_sample' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_schema'
    union all
    select
      'dbt_sample' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_schema'
    union all
    select
      'dbt_sample' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_schema'
  
[0m14:50:05.565711 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m14:50:05.566865 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: ROLLBACK
[0m14:50:05.567359 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: Close
[0m14:50:05.573815 [debug] [MainThread]: Using postgres connection "master"
[0m14:50:05.574363 [debug] [MainThread]: On master: BEGIN
[0m14:50:05.574794 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:50:05.725746 [debug] [MainThread]: SQL status: BEGIN in 0.151 seconds
[0m14:50:05.726161 [debug] [MainThread]: Using postgres connection "master"
[0m14:50:05.726508 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:50:05.735364 [debug] [MainThread]: SQL status: SELECT 9 in 0.008 seconds
[0m14:50:05.736681 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8115c319-8ed3-43fc-b882-1eaa930cfcd2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000151664E9570>]}
[0m14:50:05.737150 [debug] [MainThread]: On master: ROLLBACK
[0m14:50:05.738096 [debug] [MainThread]: Using postgres connection "master"
[0m14:50:05.738941 [debug] [MainThread]: On master: BEGIN
[0m14:50:05.739572 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m14:50:05.739893 [debug] [MainThread]: On master: COMMIT
[0m14:50:05.740159 [debug] [MainThread]: Using postgres connection "master"
[0m14:50:05.740389 [debug] [MainThread]: On master: COMMIT
[0m14:50:05.740753 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:50:05.741031 [debug] [MainThread]: On master: Close
[0m14:50:05.746874 [debug] [Thread-1 (]: Began running node model.analytics_project.analytics_orders
[0m14:50:05.747492 [info ] [Thread-1 (]: 1 of 1 START sql view model analytics_schema_analytics_schema.analytics_orders . [RUN]
[0m14:50:05.748281 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.analytics_project.analytics_orders'
[0m14:50:05.748629 [debug] [Thread-1 (]: Began compiling node model.analytics_project.analytics_orders
[0m14:50:05.757079 [debug] [Thread-1 (]: Writing injected SQL for node "model.analytics_project.analytics_orders"
[0m14:50:05.758469 [debug] [Thread-1 (]: Began executing node model.analytics_project.analytics_orders
[0m14:50:05.798595 [debug] [Thread-1 (]: Writing runtime sql for node "model.analytics_project.analytics_orders"
[0m14:50:05.799776 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m14:50:05.800209 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: BEGIN
[0m14:50:05.800502 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:50:05.842109 [debug] [Thread-1 (]: SQL status: BEGIN in 0.041 seconds
[0m14:50:05.842589 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m14:50:05.842943 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.analytics_orders"} */

  create view "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders__dbt_tmp"
    
    
  as (
    

WITH ecommerce_orders AS (
    -- Use source() to reference ecommerce models
    SELECT * FROM "dbt_sample"."ecommerce_ecommerce_schema"."stg_orders"
),
test_project_data AS (
    -- Use source() to reference test project models
    SELECT * FROM "dbt_sample"."my_test_my_test"."my_first_dbt_model"
)

SELECT
    eo.order_id,
    eo.customer_id,
    td.id as test_project_id,
    td.amount as some_metric
FROM ecommerce_orders eo
LEFT JOIN test_project_data td
ON eo.customer_id = td.order_id
  );
[0m14:50:05.850591 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.007 seconds
[0m14:50:05.857596 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m14:50:05.858040 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.analytics_orders"} */
alter table "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders__dbt_tmp" rename to "analytics_orders"
[0m14:50:05.858996 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:50:05.873753 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: COMMIT
[0m14:50:05.874243 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m14:50:05.874599 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: COMMIT
[0m14:50:05.876612 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m14:50:05.882534 [debug] [Thread-1 (]: Applying DROP to: "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders__dbt_backup"
[0m14:50:05.887081 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m14:50:05.887449 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.analytics_orders"} */
drop view if exists "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders__dbt_backup" cascade
[0m14:50:05.888994 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.001 seconds
[0m14:50:05.891474 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: Close
[0m14:50:05.893760 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8115c319-8ed3-43fc-b882-1eaa930cfcd2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000151662A31D0>]}
[0m14:50:05.894903 [info ] [Thread-1 (]: 1 of 1 OK created sql view model analytics_schema_analytics_schema.analytics_orders  [[32mCREATE VIEW[0m in 0.14s]
[0m14:50:05.896591 [debug] [Thread-1 (]: Finished running node model.analytics_project.analytics_orders
[0m14:50:05.897874 [debug] [MainThread]: Using postgres connection "master"
[0m14:50:05.898200 [debug] [MainThread]: On master: BEGIN
[0m14:50:05.898594 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:50:05.951699 [debug] [MainThread]: SQL status: BEGIN in 0.053 seconds
[0m14:50:05.952379 [debug] [MainThread]: On master: COMMIT
[0m14:50:05.952865 [debug] [MainThread]: Using postgres connection "master"
[0m14:50:05.953318 [debug] [MainThread]: On master: COMMIT
[0m14:50:05.953935 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:50:05.954517 [debug] [MainThread]: On master: Close
[0m14:50:05.955277 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:50:05.955694 [debug] [MainThread]: Connection 'list_dbt_sample' was properly closed.
[0m14:50:05.956055 [debug] [MainThread]: Connection 'list_dbt_sample_analytics_schema' was properly closed.
[0m14:50:05.956406 [debug] [MainThread]: Connection 'model.analytics_project.analytics_orders' was properly closed.
[0m14:50:05.956821 [info ] [MainThread]: 
[0m14:50:05.958486 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.65 seconds (0.65s).
[0m14:50:05.960258 [debug] [MainThread]: Command end result
[0m14:50:06.075999 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\karak\dbt_cursor\analytics_project\target\manifest.json
[0m14:50:06.078900 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\karak\dbt_cursor\analytics_project\target\semantic_manifest.json
[0m14:50:06.087922 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\karak\dbt_cursor\analytics_project\target\run_results.json
[0m14:50:06.089309 [info ] [MainThread]: 
[0m14:50:06.090391 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:50:06.091104 [info ] [MainThread]: 
[0m14:50:06.092091 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m14:50:06.093301 [debug] [MainThread]: Command `dbt run` succeeded at 14:50:06.093129 after 2.34 seconds
[0m14:50:06.093832 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001516629E990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000151660531B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015165FFF750>]}
[0m14:50:06.094392 [debug] [MainThread]: Flushing usage events
[0m14:50:07.298485 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:50:15.957787 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D36449A7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D362595590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D365140F50>]}


============================== 14:50:15.967372 | 8030366c-c14a-49fd-8446-0874a6282c87 ==============================
[0m14:50:15.967372 [info ] [MainThread]: Running with dbt=1.9.3
[0m14:50:15.968148 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\karak\\dbt_cursor\\analytics_project\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\karak\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt show --select analytics_orders', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m14:50:16.181311 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8030366c-c14a-49fd-8446-0874a6282c87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D365B60E90>]}
[0m14:50:16.252268 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8030366c-c14a-49fd-8446-0874a6282c87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D3654BFF00>]}
[0m14:50:16.286833 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m14:50:16.510862 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m14:50:16.678113 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:50:16.678535 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:50:16.726497 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8030366c-c14a-49fd-8446-0874a6282c87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D366E54E50>]}
[0m14:50:16.804829 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\karak\dbt_cursor\analytics_project\target\manifest.json
[0m14:50:16.808711 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\karak\dbt_cursor\analytics_project\target\semantic_manifest.json
[0m14:50:16.811619 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8030366c-c14a-49fd-8446-0874a6282c87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D3655FEE40>]}
[0m14:50:16.812117 [info ] [MainThread]: Found 3 models, 3 data tests, 2 sources, 433 macros
[0m14:50:16.812752 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8030366c-c14a-49fd-8446-0874a6282c87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D365B05C50>]}
[0m14:50:16.814352 [info ] [MainThread]: 
[0m14:50:16.815007 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:50:16.815623 [info ] [MainThread]: 
[0m14:50:16.816352 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:50:16.820046 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbt_sample_analytics_schema'
[0m14:50:16.902182 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema"
[0m14:50:16.902592 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: BEGIN
[0m14:50:16.902891 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:50:16.951878 [debug] [ThreadPool]: SQL status: BEGIN in 0.049 seconds
[0m14:50:16.952271 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema"
[0m14:50:16.952562 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample_analytics_schema"} */
select
      'dbt_sample' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_schema'
    union all
    select
      'dbt_sample' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_schema'
    union all
    select
      'dbt_sample' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_schema'
  
[0m14:50:16.959852 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.007 seconds
[0m14:50:16.961479 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: ROLLBACK
[0m14:50:16.962053 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: Close
[0m14:50:16.962660 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dbt_sample_analytics_schema, now list_dbt_sample_analytics_schema_analytics_schema)
[0m14:50:16.964959 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema_analytics_schema"
[0m14:50:16.965459 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: BEGIN
[0m14:50:16.965765 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:50:17.120402 [debug] [ThreadPool]: SQL status: BEGIN in 0.155 seconds
[0m14:50:17.121626 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema_analytics_schema"
[0m14:50:17.122302 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample_analytics_schema_analytics_schema"} */
select
      'dbt_sample' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_schema_analytics_schema'
    union all
    select
      'dbt_sample' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_schema_analytics_schema'
    union all
    select
      'dbt_sample' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_schema_analytics_schema'
  
[0m14:50:17.129333 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.006 seconds
[0m14:50:17.130677 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: ROLLBACK
[0m14:50:17.131387 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: Close
[0m14:50:17.136921 [debug] [MainThread]: Using postgres connection "master"
[0m14:50:17.137411 [debug] [MainThread]: On master: BEGIN
[0m14:50:17.138303 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:50:17.181946 [debug] [MainThread]: SQL status: BEGIN in 0.044 seconds
[0m14:50:17.182335 [debug] [MainThread]: Using postgres connection "master"
[0m14:50:17.182662 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:50:17.192375 [debug] [MainThread]: SQL status: SELECT 11 in 0.009 seconds
[0m14:50:17.194384 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8030366c-c14a-49fd-8446-0874a6282c87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D366F982C0>]}
[0m14:50:17.194895 [debug] [MainThread]: On master: ROLLBACK
[0m14:50:17.195488 [debug] [MainThread]: On master: Close
[0m14:50:17.201569 [debug] [Thread-1 (]: Began running node model.analytics_project.analytics_orders
[0m14:50:17.202139 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.analytics_project.analytics_orders'
[0m14:50:17.202472 [debug] [Thread-1 (]: Began compiling node model.analytics_project.analytics_orders
[0m14:50:17.212677 [debug] [Thread-1 (]: Writing injected SQL for node "model.analytics_project.analytics_orders"
[0m14:50:17.213804 [debug] [Thread-1 (]: Began executing node model.analytics_project.analytics_orders
[0m14:50:17.219887 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m14:50:17.220384 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.analytics_orders"} */

  
  

WITH ecommerce_orders AS (
    -- Use source() to reference ecommerce models
    SELECT * FROM "dbt_sample"."ecommerce_ecommerce_schema"."stg_orders"
),
test_project_data AS (
    -- Use source() to reference test project models
    SELECT * FROM "dbt_sample"."my_test_my_test"."my_first_dbt_model"
)

SELECT
    eo.order_id,
    eo.customer_id,
    td.id as test_project_id,
    td.amount as some_metric
FROM ecommerce_orders eo
LEFT JOIN test_project_data td
ON eo.customer_id = td.order_id
  
  limit 5

[0m14:50:17.220989 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:50:17.268436 [debug] [Thread-1 (]: SQL status: SELECT 3 in 0.048 seconds
[0m14:50:17.270941 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: Close
[0m14:50:17.272383 [debug] [Thread-1 (]: Finished running node model.analytics_project.analytics_orders
[0m14:50:17.273452 [debug] [Thread-1 (]: Began running node test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba
[0m14:50:17.274128 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.analytics_project.analytics_orders, now test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba)
[0m14:50:17.274511 [debug] [Thread-1 (]: Began compiling node test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba
[0m14:50:17.288302 [debug] [Thread-1 (]: Writing injected SQL for node "test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba"
[0m14:50:17.289919 [debug] [Thread-1 (]: Began executing node test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba
[0m14:50:17.293768 [debug] [Thread-1 (]: Using postgres connection "test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba"
[0m14:50:17.294400 [debug] [Thread-1 (]: On test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba"} */

  
  
    
    



select customer_id
from "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders"
where customer_id is null



  
  limit 5

[0m14:50:17.294937 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:50:17.341929 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.047 seconds
[0m14:50:17.343411 [debug] [Thread-1 (]: On test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba: Close
[0m14:50:17.344501 [debug] [Thread-1 (]: Finished running node test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba
[0m14:50:17.345130 [debug] [Thread-1 (]: Began running node test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b
[0m14:50:17.345763 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba, now test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b)
[0m14:50:17.346282 [debug] [Thread-1 (]: Began compiling node test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b
[0m14:50:17.350632 [debug] [Thread-1 (]: Writing injected SQL for node "test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b"
[0m14:50:17.351704 [debug] [Thread-1 (]: Began executing node test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b
[0m14:50:17.356070 [debug] [Thread-1 (]: Using postgres connection "test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b"
[0m14:50:17.356743 [debug] [Thread-1 (]: On test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b"} */

  
  
    
    



select order_id
from "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders"
where order_id is null



  
  limit 5

[0m14:50:17.357386 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:50:17.403764 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.046 seconds
[0m14:50:17.406176 [debug] [Thread-1 (]: On test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b: Close
[0m14:50:17.407653 [debug] [Thread-1 (]: Finished running node test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b
[0m14:50:17.408058 [debug] [Thread-1 (]: Began running node test.analytics_project.unique_analytics_orders_order_id.20264248d8
[0m14:50:17.408433 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b, now test.analytics_project.unique_analytics_orders_order_id.20264248d8)
[0m14:50:17.408828 [debug] [Thread-1 (]: Began compiling node test.analytics_project.unique_analytics_orders_order_id.20264248d8
[0m14:50:17.416123 [debug] [Thread-1 (]: Writing injected SQL for node "test.analytics_project.unique_analytics_orders_order_id.20264248d8"
[0m14:50:17.425824 [debug] [Thread-1 (]: Began executing node test.analytics_project.unique_analytics_orders_order_id.20264248d8
[0m14:50:17.429389 [debug] [Thread-1 (]: Using postgres connection "test.analytics_project.unique_analytics_orders_order_id.20264248d8"
[0m14:50:17.429860 [debug] [Thread-1 (]: On test.analytics_project.unique_analytics_orders_order_id.20264248d8: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "test.analytics_project.unique_analytics_orders_order_id.20264248d8"} */

  
  
    
    

select
    order_id as unique_field,
    count(*) as n_records

from "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders"
where order_id is not null
group by order_id
having count(*) > 1



  
  limit 5

[0m14:50:17.430223 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:50:17.476743 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.046 seconds
[0m14:50:17.478042 [debug] [Thread-1 (]: On test.analytics_project.unique_analytics_orders_order_id.20264248d8: Close
[0m14:50:17.478903 [debug] [Thread-1 (]: Finished running node test.analytics_project.unique_analytics_orders_order_id.20264248d8
[0m14:50:17.480118 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:50:17.480543 [debug] [MainThread]: Connection 'list_dbt_sample_analytics_schema_analytics_schema' was properly closed.
[0m14:50:17.480959 [debug] [MainThread]: Connection 'test.analytics_project.unique_analytics_orders_order_id.20264248d8' was properly closed.
[0m14:50:17.481923 [debug] [MainThread]: Command end result
[0m14:50:17.503043 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\karak\dbt_cursor\analytics_project\target\manifest.json
[0m14:50:17.506459 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\karak\dbt_cursor\analytics_project\target\semantic_manifest.json
[0m14:50:17.514584 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\karak\dbt_cursor\analytics_project\target\run_results.json
[0m14:50:17.515058 [debug] [MainThread]: Excluded node 'not_null_analytics_orders_customer_id' from results
[0m14:50:17.515345 [debug] [MainThread]: Excluded node 'not_null_analytics_orders_order_id' from results
[0m14:50:17.515557 [debug] [MainThread]: Excluded node 'unique_analytics_orders_order_id' from results
[0m14:50:17.516189 [info ] [MainThread]: Previewing node 'analytics_orders':
| order_id | customer_id | test_project_id | some_metric |
| -------- | ----------- | --------------- | ----------- |
|        1 |           1 |               1 |         100 |
|        2 |           2 |               2 |         200 |
|        3 |           3 |               3 |         150 |

[0m14:50:17.517245 [debug] [MainThread]: Command `dbt show` succeeded at 14:50:17.517114 after 1.72 seconds
[0m14:50:17.517613 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D3654922D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D366DDBEE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D367204AA0>]}
[0m14:50:17.517962 [debug] [MainThread]: Flushing usage events
[0m14:50:18.767210 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:52:11.286124 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000155D90EA7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000155D71E1590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000155D9DA0F50>]}


============================== 14:52:11.294427 | 10996187-45ac-4b34-bf07-016a019fe625 ==============================
[0m14:52:11.294427 [info ] [MainThread]: Running with dbt=1.9.3
[0m14:52:11.295331 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\karak\\dbt_cursor\\analytics_project\\logs', 'profiles_dir': 'C:\\Users\\karak\\.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m14:52:11.460704 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '10996187-45ac-4b34-bf07-016a019fe625', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000155DA444E90>]}
[0m14:52:11.514737 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '10996187-45ac-4b34-bf07-016a019fe625', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000155DA11FF00>]}
[0m14:52:11.516015 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m14:52:11.690116 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m14:52:11.825660 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:52:11.826027 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:52:11.863496 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '10996187-45ac-4b34-bf07-016a019fe625', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000155DBA00D50>]}
[0m14:52:11.930263 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\karak\dbt_cursor\analytics_project\target\manifest.json
[0m14:52:11.933438 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\karak\dbt_cursor\analytics_project\target\semantic_manifest.json
[0m14:52:11.962774 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '10996187-45ac-4b34-bf07-016a019fe625', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000155DA25AA80>]}
[0m14:52:11.963430 [info ] [MainThread]: Found 3 models, 3 data tests, 2 sources, 433 macros
[0m14:52:11.964211 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '10996187-45ac-4b34-bf07-016a019fe625', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000155DBAAD630>]}
[0m14:52:11.965858 [info ] [MainThread]: 
[0m14:52:11.966470 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:52:11.966987 [info ] [MainThread]: 
[0m14:52:11.967643 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:52:11.971185 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbt_sample'
[0m14:52:12.037863 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample"
[0m14:52:12.038235 [debug] [ThreadPool]: On list_dbt_sample: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample"} */

    select distinct nspname from pg_namespace
  
[0m14:52:12.038490 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:52:12.083148 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.045 seconds
[0m14:52:12.084376 [debug] [ThreadPool]: On list_dbt_sample: Close
[0m14:52:12.086855 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample"
[0m14:52:12.087349 [debug] [ThreadPool]: On list_dbt_sample: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample"} */

    select distinct nspname from pg_namespace
  
[0m14:52:12.087782 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:52:12.126987 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.039 seconds
[0m14:52:12.128250 [debug] [ThreadPool]: On list_dbt_sample: Close
[0m14:52:12.129070 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dbt_sample, now create_dbt_sample_analytics_schema)
[0m14:52:12.129701 [debug] [ThreadPool]: Creating schema "database: "dbt_sample"
schema: "analytics_schema"
"
[0m14:52:12.135368 [debug] [ThreadPool]: Using postgres connection "create_dbt_sample_analytics_schema"
[0m14:52:12.135667 [debug] [ThreadPool]: On create_dbt_sample_analytics_schema: BEGIN
[0m14:52:12.135923 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:52:12.275438 [debug] [ThreadPool]: SQL status: BEGIN in 0.139 seconds
[0m14:52:12.275809 [debug] [ThreadPool]: Using postgres connection "create_dbt_sample_analytics_schema"
[0m14:52:12.276058 [debug] [ThreadPool]: On create_dbt_sample_analytics_schema: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "create_dbt_sample_analytics_schema"} */
create schema if not exists "analytics_schema"
[0m14:52:12.277353 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m14:52:12.278223 [debug] [ThreadPool]: On create_dbt_sample_analytics_schema: COMMIT
[0m14:52:12.278537 [debug] [ThreadPool]: Using postgres connection "create_dbt_sample_analytics_schema"
[0m14:52:12.278786 [debug] [ThreadPool]: On create_dbt_sample_analytics_schema: COMMIT
[0m14:52:12.280834 [debug] [ThreadPool]: SQL status: COMMIT in 0.002 seconds
[0m14:52:12.281143 [debug] [ThreadPool]: On create_dbt_sample_analytics_schema: Close
[0m14:52:12.283376 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbt_sample_analytics_schema'
[0m14:52:12.290881 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema"
[0m14:52:12.291209 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: BEGIN
[0m14:52:12.291458 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:52:12.328559 [debug] [ThreadPool]: SQL status: BEGIN in 0.037 seconds
[0m14:52:12.329034 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema"
[0m14:52:12.329556 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample_analytics_schema"} */
select
      'dbt_sample' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_schema'
    union all
    select
      'dbt_sample' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_schema'
    union all
    select
      'dbt_sample' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_schema'
  
[0m14:52:12.335931 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.006 seconds
[0m14:52:12.337036 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: ROLLBACK
[0m14:52:12.337479 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: Close
[0m14:52:12.338086 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dbt_sample_analytics_schema, now list_dbt_sample_analytics_schema_analytics_schema)
[0m14:52:12.340252 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema_analytics_schema"
[0m14:52:12.340735 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: BEGIN
[0m14:52:12.341124 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:52:12.383366 [debug] [ThreadPool]: SQL status: BEGIN in 0.042 seconds
[0m14:52:12.383758 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema_analytics_schema"
[0m14:52:12.384082 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample_analytics_schema_analytics_schema"} */
select
      'dbt_sample' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_schema_analytics_schema'
    union all
    select
      'dbt_sample' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_schema_analytics_schema'
    union all
    select
      'dbt_sample' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_schema_analytics_schema'
  
[0m14:52:12.390411 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.006 seconds
[0m14:52:12.391455 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: ROLLBACK
[0m14:52:12.391924 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: Close
[0m14:52:12.396356 [debug] [MainThread]: Using postgres connection "master"
[0m14:52:12.396709 [debug] [MainThread]: On master: BEGIN
[0m14:52:12.396961 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:52:12.431869 [debug] [MainThread]: SQL status: BEGIN in 0.035 seconds
[0m14:52:12.432265 [debug] [MainThread]: Using postgres connection "master"
[0m14:52:12.432608 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:52:12.441882 [debug] [MainThread]: SQL status: SELECT 9 in 0.009 seconds
[0m14:52:12.443654 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '10996187-45ac-4b34-bf07-016a019fe625', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000155DBE406D0>]}
[0m14:52:12.444203 [debug] [MainThread]: On master: ROLLBACK
[0m14:52:12.445015 [debug] [MainThread]: Using postgres connection "master"
[0m14:52:12.445446 [debug] [MainThread]: On master: BEGIN
[0m14:52:12.446210 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m14:52:12.446567 [debug] [MainThread]: On master: COMMIT
[0m14:52:12.446889 [debug] [MainThread]: Using postgres connection "master"
[0m14:52:12.447188 [debug] [MainThread]: On master: COMMIT
[0m14:52:12.447735 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:52:12.448130 [debug] [MainThread]: On master: Close
[0m14:52:12.454829 [debug] [Thread-1 (]: Began running node model.analytics_project.analytics_orders
[0m14:52:12.455539 [info ] [Thread-1 (]: 1 of 3 START sql view model analytics_schema_analytics_schema.analytics_orders . [RUN]
[0m14:52:12.456439 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.analytics_project.analytics_orders'
[0m14:52:12.456780 [debug] [Thread-1 (]: Began compiling node model.analytics_project.analytics_orders
[0m14:52:12.463963 [debug] [Thread-1 (]: Writing injected SQL for node "model.analytics_project.analytics_orders"
[0m14:52:12.464929 [debug] [Thread-1 (]: Began executing node model.analytics_project.analytics_orders
[0m14:52:12.500308 [debug] [Thread-1 (]: Writing runtime sql for node "model.analytics_project.analytics_orders"
[0m14:52:12.501496 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m14:52:12.501973 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: BEGIN
[0m14:52:12.502343 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:52:12.538247 [debug] [Thread-1 (]: SQL status: BEGIN in 0.036 seconds
[0m14:52:12.538683 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m14:52:12.539006 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.analytics_orders"} */

  create view "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders__dbt_tmp"
    
    
  as (
    

WITH ecommerce_orders AS (
    -- Use source() to reference ecommerce models
    SELECT * FROM "dbt_sample"."ecommerce_ecommerce_schema"."stg_orders"
),
test_project_data AS (
    -- Use source() to reference test project models
    SELECT * FROM "dbt_sample"."my_test_my_test"."my_first_dbt_model"
)

SELECT
    eo.order_id,
    eo.customer_id,
    td.id as test_project_id,
    td.amount as some_metric
FROM ecommerce_orders eo
LEFT JOIN test_project_data td
ON eo.customer_id = td.order_id
  );
[0m14:52:12.544988 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.006 seconds
[0m14:52:12.550300 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m14:52:12.550672 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.analytics_orders"} */
alter table "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders__dbt_tmp" rename to "analytics_orders"
[0m14:52:12.551475 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m14:52:12.565702 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: COMMIT
[0m14:52:12.566228 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m14:52:12.566674 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: COMMIT
[0m14:52:12.576899 [debug] [Thread-1 (]: SQL status: COMMIT in 0.010 seconds
[0m14:52:12.582542 [debug] [Thread-1 (]: Applying DROP to: "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders__dbt_backup"
[0m14:52:12.586815 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m14:52:12.587166 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.analytics_orders"} */
drop view if exists "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders__dbt_backup" cascade
[0m14:52:12.587703 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.000 seconds
[0m14:52:12.589753 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: Close
[0m14:52:12.592395 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '10996187-45ac-4b34-bf07-016a019fe625', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000155DBBA9610>]}
[0m14:52:12.593378 [info ] [Thread-1 (]: 1 of 3 OK created sql view model analytics_schema_analytics_schema.analytics_orders  [[32mCREATE VIEW[0m in 0.13s]
[0m14:52:12.594416 [debug] [Thread-1 (]: Finished running node model.analytics_project.analytics_orders
[0m14:52:12.594985 [debug] [Thread-1 (]: Began running node model.analytics_project.my_first_dbt_model
[0m14:52:12.595587 [info ] [Thread-1 (]: 2 of 3 START sql table model analytics_schema.my_first_dbt_model ............... [RUN]
[0m14:52:12.596463 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.analytics_project.analytics_orders, now model.analytics_project.my_first_dbt_model)
[0m14:52:12.596937 [debug] [Thread-1 (]: Began compiling node model.analytics_project.my_first_dbt_model
[0m14:52:12.599723 [debug] [Thread-1 (]: Writing injected SQL for node "model.analytics_project.my_first_dbt_model"
[0m14:52:12.600678 [debug] [Thread-1 (]: Began executing node model.analytics_project.my_first_dbt_model
[0m14:52:12.634946 [debug] [Thread-1 (]: Writing runtime sql for node "model.analytics_project.my_first_dbt_model"
[0m14:52:12.636080 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_first_dbt_model"
[0m14:52:12.636890 [debug] [Thread-1 (]: On model.analytics_project.my_first_dbt_model: BEGIN
[0m14:52:12.637767 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:52:12.696918 [debug] [Thread-1 (]: SQL status: BEGIN in 0.059 seconds
[0m14:52:12.697372 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_first_dbt_model"
[0m14:52:12.697705 [debug] [Thread-1 (]: On model.analytics_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.my_first_dbt_model"} */

  
    

  create  table "dbt_sample"."analytics_schema"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m14:52:12.702380 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.004 seconds
[0m14:52:12.706202 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_first_dbt_model"
[0m14:52:12.706744 [debug] [Thread-1 (]: On model.analytics_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.my_first_dbt_model"} */
alter table "dbt_sample"."analytics_schema"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m14:52:12.707785 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m14:52:12.714500 [debug] [Thread-1 (]: On model.analytics_project.my_first_dbt_model: COMMIT
[0m14:52:12.715060 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_first_dbt_model"
[0m14:52:12.715563 [debug] [Thread-1 (]: On model.analytics_project.my_first_dbt_model: COMMIT
[0m14:52:12.716862 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m14:52:12.720138 [debug] [Thread-1 (]: Applying DROP to: "dbt_sample"."analytics_schema"."my_first_dbt_model__dbt_backup"
[0m14:52:12.723215 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_first_dbt_model"
[0m14:52:12.723754 [debug] [Thread-1 (]: On model.analytics_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.my_first_dbt_model"} */
drop table if exists "dbt_sample"."analytics_schema"."my_first_dbt_model__dbt_backup" cascade
[0m14:52:12.724600 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m14:52:12.726159 [debug] [Thread-1 (]: On model.analytics_project.my_first_dbt_model: Close
[0m14:52:12.726726 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '10996187-45ac-4b34-bf07-016a019fe625', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000155DBEE8C00>]}
[0m14:52:12.727460 [info ] [Thread-1 (]: 2 of 3 OK created sql table model analytics_schema.my_first_dbt_model .......... [[32mSELECT 2[0m in 0.13s]
[0m14:52:12.728416 [debug] [Thread-1 (]: Finished running node model.analytics_project.my_first_dbt_model
[0m14:52:12.729445 [debug] [Thread-1 (]: Began running node model.analytics_project.my_second_dbt_model
[0m14:52:12.730120 [info ] [Thread-1 (]: 3 of 3 START sql view model analytics_schema.my_second_dbt_model ............... [RUN]
[0m14:52:12.731022 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.analytics_project.my_first_dbt_model, now model.analytics_project.my_second_dbt_model)
[0m14:52:12.731513 [debug] [Thread-1 (]: Began compiling node model.analytics_project.my_second_dbt_model
[0m14:52:12.734518 [debug] [Thread-1 (]: Writing injected SQL for node "model.analytics_project.my_second_dbt_model"
[0m14:52:12.736472 [debug] [Thread-1 (]: Began executing node model.analytics_project.my_second_dbt_model
[0m14:52:12.740336 [debug] [Thread-1 (]: Writing runtime sql for node "model.analytics_project.my_second_dbt_model"
[0m14:52:12.741775 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_second_dbt_model"
[0m14:52:12.742263 [debug] [Thread-1 (]: On model.analytics_project.my_second_dbt_model: BEGIN
[0m14:52:12.742575 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:52:12.800496 [debug] [Thread-1 (]: SQL status: BEGIN in 0.058 seconds
[0m14:52:12.800956 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_second_dbt_model"
[0m14:52:12.801300 [debug] [Thread-1 (]: On model.analytics_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.my_second_dbt_model"} */

  create view "dbt_sample"."analytics_schema"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "dbt_sample"."analytics_schema"."my_first_dbt_model"
where id = 1
  );
[0m14:52:12.805530 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.004 seconds
[0m14:52:12.808451 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_second_dbt_model"
[0m14:52:12.808819 [debug] [Thread-1 (]: On model.analytics_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.my_second_dbt_model"} */
alter table "dbt_sample"."analytics_schema"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m14:52:12.809442 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m14:52:12.810633 [debug] [Thread-1 (]: On model.analytics_project.my_second_dbt_model: COMMIT
[0m14:52:12.810954 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_second_dbt_model"
[0m14:52:12.811254 [debug] [Thread-1 (]: On model.analytics_project.my_second_dbt_model: COMMIT
[0m14:52:12.812670 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m14:52:12.814360 [debug] [Thread-1 (]: Applying DROP to: "dbt_sample"."analytics_schema"."my_second_dbt_model__dbt_backup"
[0m14:52:12.814924 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_second_dbt_model"
[0m14:52:12.815226 [debug] [Thread-1 (]: On model.analytics_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.my_second_dbt_model"} */
drop view if exists "dbt_sample"."analytics_schema"."my_second_dbt_model__dbt_backup" cascade
[0m14:52:12.815864 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.000 seconds
[0m14:52:12.817478 [debug] [Thread-1 (]: On model.analytics_project.my_second_dbt_model: Close
[0m14:52:12.818111 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '10996187-45ac-4b34-bf07-016a019fe625', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000155DBF2F890>]}
[0m14:52:12.818893 [info ] [Thread-1 (]: 3 of 3 OK created sql view model analytics_schema.my_second_dbt_model .......... [[32mCREATE VIEW[0m in 0.09s]
[0m14:52:12.819972 [debug] [Thread-1 (]: Finished running node model.analytics_project.my_second_dbt_model
[0m14:52:12.821639 [debug] [MainThread]: Using postgres connection "master"
[0m14:52:12.822071 [debug] [MainThread]: On master: BEGIN
[0m14:52:12.822410 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:52:12.860704 [debug] [MainThread]: SQL status: BEGIN in 0.038 seconds
[0m14:52:12.861174 [debug] [MainThread]: On master: COMMIT
[0m14:52:12.861482 [debug] [MainThread]: Using postgres connection "master"
[0m14:52:12.861845 [debug] [MainThread]: On master: COMMIT
[0m14:52:12.862295 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m14:52:12.862575 [debug] [MainThread]: On master: Close
[0m14:52:12.863007 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:52:12.863294 [debug] [MainThread]: Connection 'create_dbt_sample_analytics_schema' was properly closed.
[0m14:52:12.863608 [debug] [MainThread]: Connection 'list_dbt_sample_analytics_schema_analytics_schema' was properly closed.
[0m14:52:12.863827 [debug] [MainThread]: Connection 'model.analytics_project.my_second_dbt_model' was properly closed.
[0m14:52:12.864226 [info ] [MainThread]: 
[0m14:52:12.864847 [info ] [MainThread]: Finished running 1 table model, 2 view models in 0 hours 0 minutes and 0.90 seconds (0.90s).
[0m14:52:12.865920 [debug] [MainThread]: Command end result
[0m14:52:12.882828 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\karak\dbt_cursor\analytics_project\target\manifest.json
[0m14:52:12.884745 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\karak\dbt_cursor\analytics_project\target\semantic_manifest.json
[0m14:52:12.891691 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\karak\dbt_cursor\analytics_project\target\run_results.json
[0m14:52:12.892075 [info ] [MainThread]: 
[0m14:52:12.892680 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:52:12.893344 [info ] [MainThread]: 
[0m14:52:12.893827 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m14:52:12.894623 [debug] [MainThread]: Command `dbt run` succeeded at 14:52:12.894500 after 1.77 seconds
[0m14:52:12.894979 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000155DBE8C4D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000155DBA4D150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000155DA193A80>]}
[0m14:52:12.895301 [debug] [MainThread]: Flushing usage events
[0m14:52:14.503927 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:52:36.357167 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FED15A7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FEB251590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FEDE00F50>]}


============================== 14:52:36.365336 | b80cbd5b-6066-48c6-aacf-f08ada100599 ==============================
[0m14:52:36.365336 [info ] [MainThread]: Running with dbt=1.9.3
[0m14:52:36.366231 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\karak\\dbt_cursor\\analytics_project\\logs', 'profiles_dir': 'C:\\Users\\karak\\.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt docs generate', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:52:36.540375 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b80cbd5b-6066-48c6-aacf-f08ada100599', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FEE854FC0>]}
[0m14:52:36.593798 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b80cbd5b-6066-48c6-aacf-f08ada100599', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FEE17FF00>]}
[0m14:52:36.595129 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m14:52:36.774164 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m14:52:36.897782 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:52:36.898168 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:52:36.938804 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b80cbd5b-6066-48c6-aacf-f08ada100599', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FEFAB4D50>]}
[0m14:52:36.977536 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b80cbd5b-6066-48c6-aacf-f08ada100599', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FEEA3F020>]}
[0m14:52:36.978180 [info ] [MainThread]: Found 3 models, 3 data tests, 2 sources, 433 macros
[0m14:52:36.978847 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b80cbd5b-6066-48c6-aacf-f08ada100599', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FEE7F4910>]}
[0m14:52:36.981281 [info ] [MainThread]: 
[0m14:52:36.982087 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:52:36.982811 [info ] [MainThread]: 
[0m14:52:36.983671 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:52:36.988768 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbt_sample_analytics_schema_analytics_schema'
[0m14:52:37.075677 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema_analytics_schema"
[0m14:52:37.076079 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: BEGIN
[0m14:52:37.076347 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:52:37.119301 [debug] [ThreadPool]: SQL status: BEGIN in 0.043 seconds
[0m14:52:37.119735 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema_analytics_schema"
[0m14:52:37.120030 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample_analytics_schema_analytics_schema"} */
select
      'dbt_sample' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_schema_analytics_schema'
    union all
    select
      'dbt_sample' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_schema_analytics_schema'
    union all
    select
      'dbt_sample' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_schema_analytics_schema'
  
[0m14:52:37.125623 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.005 seconds
[0m14:52:37.126862 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: ROLLBACK
[0m14:52:37.127320 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: Close
[0m14:52:37.127975 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dbt_sample_analytics_schema_analytics_schema, now list_dbt_sample_analytics_schema)
[0m14:52:37.130151 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema"
[0m14:52:37.130950 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: BEGIN
[0m14:52:37.131324 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:52:37.176414 [debug] [ThreadPool]: SQL status: BEGIN in 0.045 seconds
[0m14:52:37.176788 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema"
[0m14:52:37.177133 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample_analytics_schema"} */
select
      'dbt_sample' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_schema'
    union all
    select
      'dbt_sample' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_schema'
    union all
    select
      'dbt_sample' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_schema'
  
[0m14:52:37.182820 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.005 seconds
[0m14:52:37.183982 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: ROLLBACK
[0m14:52:37.184443 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: Close
[0m14:52:37.190114 [debug] [MainThread]: Using postgres connection "master"
[0m14:52:37.190489 [debug] [MainThread]: On master: BEGIN
[0m14:52:37.190736 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:52:37.231468 [debug] [MainThread]: SQL status: BEGIN in 0.041 seconds
[0m14:52:37.231843 [debug] [MainThread]: Using postgres connection "master"
[0m14:52:37.232179 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:52:37.239434 [debug] [MainThread]: SQL status: SELECT 12 in 0.007 seconds
[0m14:52:37.240942 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b80cbd5b-6066-48c6-aacf-f08ada100599', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FEFDB1D90>]}
[0m14:52:37.241345 [debug] [MainThread]: On master: ROLLBACK
[0m14:52:37.241774 [debug] [MainThread]: On master: Close
[0m14:52:37.247329 [debug] [Thread-1 (]: Began running node model.analytics_project.analytics_orders
[0m14:52:37.248096 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.analytics_project.analytics_orders'
[0m14:52:37.248515 [debug] [Thread-1 (]: Began compiling node model.analytics_project.analytics_orders
[0m14:52:37.255492 [debug] [Thread-1 (]: Writing injected SQL for node "model.analytics_project.analytics_orders"
[0m14:52:37.256407 [debug] [Thread-1 (]: Began executing node model.analytics_project.analytics_orders
[0m14:52:37.257358 [debug] [Thread-1 (]: Finished running node model.analytics_project.analytics_orders
[0m14:52:37.257869 [debug] [Thread-1 (]: Began running node model.analytics_project.my_first_dbt_model
[0m14:52:37.258539 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.analytics_project.analytics_orders, now model.analytics_project.my_first_dbt_model)
[0m14:52:37.259055 [debug] [Thread-1 (]: Began compiling node model.analytics_project.my_first_dbt_model
[0m14:52:37.261392 [debug] [Thread-1 (]: Writing injected SQL for node "model.analytics_project.my_first_dbt_model"
[0m14:52:37.262283 [debug] [Thread-1 (]: Began executing node model.analytics_project.my_first_dbt_model
[0m14:52:37.263141 [debug] [Thread-1 (]: Finished running node model.analytics_project.my_first_dbt_model
[0m14:52:37.263514 [debug] [Thread-1 (]: Began running node test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba
[0m14:52:37.263940 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.analytics_project.my_first_dbt_model, now test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba)
[0m14:52:37.264347 [debug] [Thread-1 (]: Began compiling node test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba
[0m14:52:37.275632 [debug] [Thread-1 (]: Writing injected SQL for node "test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba"
[0m14:52:37.276843 [debug] [Thread-1 (]: Began executing node test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba
[0m14:52:37.277721 [debug] [Thread-1 (]: Finished running node test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba
[0m14:52:37.278256 [debug] [Thread-1 (]: Began running node test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b
[0m14:52:37.278764 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba, now test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b)
[0m14:52:37.279277 [debug] [Thread-1 (]: Began compiling node test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b
[0m14:52:37.283535 [debug] [Thread-1 (]: Writing injected SQL for node "test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b"
[0m14:52:37.284455 [debug] [Thread-1 (]: Began executing node test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b
[0m14:52:37.285362 [debug] [Thread-1 (]: Finished running node test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b
[0m14:52:37.285736 [debug] [Thread-1 (]: Began running node test.analytics_project.unique_analytics_orders_order_id.20264248d8
[0m14:52:37.286134 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b, now test.analytics_project.unique_analytics_orders_order_id.20264248d8)
[0m14:52:37.286445 [debug] [Thread-1 (]: Began compiling node test.analytics_project.unique_analytics_orders_order_id.20264248d8
[0m14:52:37.291514 [debug] [Thread-1 (]: Writing injected SQL for node "test.analytics_project.unique_analytics_orders_order_id.20264248d8"
[0m14:52:37.292348 [debug] [Thread-1 (]: Began executing node test.analytics_project.unique_analytics_orders_order_id.20264248d8
[0m14:52:37.293172 [debug] [Thread-1 (]: Finished running node test.analytics_project.unique_analytics_orders_order_id.20264248d8
[0m14:52:37.293572 [debug] [Thread-1 (]: Began running node model.analytics_project.my_second_dbt_model
[0m14:52:37.293978 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.analytics_project.unique_analytics_orders_order_id.20264248d8, now model.analytics_project.my_second_dbt_model)
[0m14:52:37.294289 [debug] [Thread-1 (]: Began compiling node model.analytics_project.my_second_dbt_model
[0m14:52:37.296487 [debug] [Thread-1 (]: Writing injected SQL for node "model.analytics_project.my_second_dbt_model"
[0m14:52:37.297307 [debug] [Thread-1 (]: Began executing node model.analytics_project.my_second_dbt_model
[0m14:52:37.298146 [debug] [Thread-1 (]: Finished running node model.analytics_project.my_second_dbt_model
[0m14:52:37.299125 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:52:37.299425 [debug] [MainThread]: Connection 'list_dbt_sample_analytics_schema' was properly closed.
[0m14:52:37.299647 [debug] [MainThread]: Connection 'model.analytics_project.my_second_dbt_model' was properly closed.
[0m14:52:37.300647 [debug] [MainThread]: Command end result
[0m14:52:37.376641 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\karak\dbt_cursor\analytics_project\target\manifest.json
[0m14:52:37.381078 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\karak\dbt_cursor\analytics_project\target\semantic_manifest.json
[0m14:52:37.390511 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\karak\dbt_cursor\analytics_project\target\run_results.json
[0m14:52:38.077077 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m14:52:38.077610 [info ] [MainThread]: Building catalog
[0m14:52:38.087696 [debug] [ThreadPool]: Acquiring new postgres connection 'dbt_sample.information_schema'
[0m14:52:38.093473 [debug] [ThreadPool]: Using postgres connection "dbt_sample.information_schema"
[0m14:52:38.093785 [debug] [ThreadPool]: On dbt_sample.information_schema: BEGIN
[0m14:52:38.094370 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:52:38.146258 [debug] [ThreadPool]: SQL status: BEGIN in 0.052 seconds
[0m14:52:38.146630 [debug] [ThreadPool]: Using postgres connection "dbt_sample.information_schema"
[0m14:52:38.146955 [debug] [ThreadPool]: On dbt_sample.information_schema: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "dbt_sample.information_schema"} */

    
    

    select
        'dbt_sample' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('ecommerce_ecommerce_schema') and
           upper(tbl.relname) = upper('stg_orders')) or (upper(sch.nspname) = upper('analytics_schema_analytics_schema') and
           upper(tbl.relname) = upper('analytics_orders')) or (upper(sch.nspname) = upper('analytics_schema') and
           upper(tbl.relname) = upper('my_first_dbt_model')) or (upper(sch.nspname) = upper('analytics_schema') and
           upper(tbl.relname) = upper('my_second_dbt_model')) or (upper(sch.nspname) = upper('my_test_my_test') and
           upper(tbl.relname) = upper('my_first_dbt_model')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m14:52:38.166777 [debug] [ThreadPool]: SQL status: SELECT 14 in 0.019 seconds
[0m14:52:38.170917 [debug] [ThreadPool]: On dbt_sample.information_schema: ROLLBACK
[0m14:52:38.171394 [debug] [ThreadPool]: On dbt_sample.information_schema: Close
[0m14:52:38.183010 [debug] [MainThread]: Wrote artifact CatalogArtifact to C:\Users\karak\dbt_cursor\analytics_project\target\catalog.json
[0m14:52:38.200754 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\karak\dbt_cursor\analytics_project\target\manifest.json
[0m14:52:38.202686 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\karak\dbt_cursor\analytics_project\target\semantic_manifest.json
[0m14:52:38.203164 [info ] [MainThread]: Catalog written to C:\Users\karak\dbt_cursor\analytics_project\target\catalog.json
[0m14:52:38.204164 [debug] [MainThread]: Command `dbt docs generate` succeeded at 14:52:38.204021 after 2.01 seconds
[0m14:52:38.204463 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m14:52:38.204694 [debug] [MainThread]: Connection 'dbt_sample.information_schema' was properly closed.
[0m14:52:38.204983 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FEE1562D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FEFB2BA10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FEFB2B8B0>]}
[0m14:52:38.205304 [debug] [MainThread]: Flushing usage events
[0m14:52:39.463836 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:52:47.818856 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002469CA5A7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002469AB51590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002469D700F50>]}


============================== 14:52:47.827199 | 8943777a-be8d-42d8-b539-960005e8e595 ==============================
[0m14:52:47.827199 [info ] [MainThread]: Running with dbt=1.9.3
[0m14:52:47.828070 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\karak\\.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\karak\\dbt_cursor\\analytics_project\\logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt docs serve', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m14:52:47.998476 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8943777a-be8d-42d8-b539-960005e8e595', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002469E0F0FC0>]}
[0m14:52:48.052543 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8943777a-be8d-42d8-b539-960005e8e595', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002469DA7FF00>]}
[0m15:22:18.898541 [error] [MainThread]: Encountered an error:

[0m15:22:18.952359 [error] [MainThread]: Traceback (most recent call last):
  File "C:\Users\karak\dbt_cursor\dbt-env\Lib\site-packages\dbt\cli\requires.py", line 153, in wrapper
    result, success = func(*args, **kwargs)
                      ~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\karak\dbt_cursor\dbt-env\Lib\site-packages\dbt\cli\requires.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\karak\dbt_cursor\dbt-env\Lib\site-packages\dbt\cli\requires.py", line 235, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\karak\dbt_cursor\dbt-env\Lib\site-packages\dbt\cli\requires.py", line 264, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\karak\dbt_cursor\dbt-env\Lib\site-packages\dbt\cli\requires.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\karak\dbt_cursor\dbt-env\Lib\site-packages\dbt\cli\main.py", line 301, in docs_serve
    results = task.run()
  File "C:\Users\karak\dbt_cursor\dbt-env\Lib\site-packages\dbt\task\docs\serve.py", line 29, in run
    httpd.serve_forever()
    ~~~~~~~~~~~~~~~~~~~^^
  File "C:\Python313\Lib\socketserver.py", line 235, in serve_forever
    ready = selector.select(poll_interval)
  File "C:\Python313\Lib\selectors.py", line 314, in select
    r, w, _ = self._select(self._readers, self._writers, [], timeout)
              ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python313\Lib\selectors.py", line 305, in _select
    r, w, x = select.select(r, w, w, timeout)
              ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

[0m15:22:18.955386 [debug] [MainThread]: Command `dbt docs serve` failed at 15:22:18.955208 after 1771.29 seconds
[0m15:22:18.955840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002469E231F50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002469E231E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002469E1B2A80>]}
[0m15:22:18.956257 [debug] [MainThread]: Flushing usage events
[0m15:22:20.202295 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:32:30.281914 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000216FAA8A7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000216F8B81590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000216FB730F50>]}


============================== 18:32:30.290207 | 193fe640-b404-4676-a8d9-3a14db80c03c ==============================
[0m18:32:30.290207 [info ] [MainThread]: Running with dbt=1.9.3
[0m18:32:30.291021 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\karak\\.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\karak\\dbt_cursor\\analytics_project\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt docs serve', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m18:32:30.473408 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '193fe640-b404-4676-a8d9-3a14db80c03c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000216FC11CFC0>]}
[0m18:32:30.527709 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '193fe640-b404-4676-a8d9-3a14db80c03c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000216FBAAFF00>]}
[0m18:35:50.249186 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000193E750A7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000193E5605590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000193E81A4F50>]}


============================== 18:35:50.258861 | cf5683e6-8ad2-4cb0-8dd9-75274110be31 ==============================
[0m18:35:50.258861 [info ] [MainThread]: Running with dbt=1.9.3
[0m18:35:50.259737 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\karak\\.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\karak\\dbt_cursor\\analytics_project\\logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt docs serve', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m18:35:50.411596 [error] [MainThread]: Encountered an error:
Runtime Error
  The packages.yml file in this project is malformed. Please double check
  the contents of this file and fix any errors before retrying.
  
  You can find more information on the syntax for this file here:
  https://docs.getdbt.com/docs/package-management
  
  Validator Error:
  ecommerce_project was not found in the package index. Packages on the index require a namespace, e.g dbt-labs/dbt_utils
  

Error encountered in C:\Users\karak\dbt_cursor\analytics_project\dbt_project.yml
[0m18:35:50.412990 [debug] [MainThread]: Command `dbt docs serve` failed at 18:35:50.412824 after 0.42 seconds
[0m18:35:50.413355 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000193E8C90510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000193E8C44EF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000193E852BAC0>]}
[0m18:35:50.413721 [debug] [MainThread]: Flushing usage events
[0m18:35:51.558238 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:37:25.930759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E3CE6FA7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E3CC7ED590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E3CF3A0F50>]}


============================== 18:37:25.939678 | e2ebeb5f-d1a1-4422-bf5e-5d0f4843c960 ==============================
[0m18:37:25.939678 [info ] [MainThread]: Running with dbt=1.9.3
[0m18:37:25.940436 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\karak\\dbt_cursor\\analytics_project\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\karak\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m18:37:26.084223 [error] [MainThread]: Encountered an error:
Runtime Error
  The packages.yml file in this project is malformed. Please double check
  the contents of this file and fix any errors before retrying.
  
  You can find more information on the syntax for this file here:
  https://docs.getdbt.com/docs/package-management
  
  Validator Error:
  ecommerce_project was not found in the package index. Packages on the index require a namespace, e.g dbt-labs/dbt_utils
  

Error encountered in C:\Users\karak\dbt_cursor\analytics_project\dbt_project.yml
[0m18:37:26.085544 [debug] [MainThread]: Command `dbt run` failed at 18:37:26.085398 after 0.42 seconds
[0m18:37:26.085895 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E3CFDA43E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E3CFD70EF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E3CF71E7A0>]}
[0m18:37:26.086248 [debug] [MainThread]: Flushing usage events
[0m18:37:27.339819 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:37:53.573264 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF39E8A7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF37F79590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF3AB40F50>]}


============================== 18:37:53.583504 | 3c00a011-c257-4399-a550-213d2dcceea2 ==============================
[0m18:37:53.583504 [info ] [MainThread]: Running with dbt=1.9.3
[0m18:37:53.584322 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\karak\\.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\karak\\dbt_cursor\\analytics_project\\logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m18:37:53.748195 [error] [MainThread]: Encountered an error:
Runtime Error
  The packages.yml file in this project is malformed. Please double check
  the contents of this file and fix any errors before retrying.
  
  You can find more information on the syntax for this file here:
  https://docs.getdbt.com/docs/package-management
  
  Validator Error:
  ecommerce_project was not found in the package index. Packages on the index require a namespace, e.g dbt-labs/dbt_utils
  

Error encountered in C:\Users\karak\dbt_cursor\analytics_project\dbt_project.yml
[0m18:37:53.749586 [debug] [MainThread]: Command `dbt run` failed at 18:37:53.749438 after 0.36 seconds
[0m18:37:53.749959 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF3B1E43E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF3B198EF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF3AEBE7A0>]}
[0m18:37:53.750379 [debug] [MainThread]: Flushing usage events
[0m18:37:54.783287 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:38:28.125372 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023798D4A7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023796E45590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000237999F0F50>]}


============================== 18:38:28.135303 | a90ba233-4ed3-44af-abe2-cbcd7de64cb5 ==============================
[0m18:38:28.135303 [info ] [MainThread]: Running with dbt=1.9.3
[0m18:38:28.136054 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\karak\\.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\karak\\dbt_cursor\\analytics_project\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run --select analytics_orders', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m18:38:28.307095 [error] [MainThread]: Encountered an error:
Runtime Error
  The packages.yml file in this project is malformed. Please double check
  the contents of this file and fix any errors before retrying.
  
  You can find more information on the syntax for this file here:
  https://docs.getdbt.com/docs/package-management
  
  Validator Error:
  ecommerce_project was not found in the package index. Packages on the index require a namespace, e.g dbt-labs/dbt_utils
  

Error encountered in C:\Users\karak\dbt_cursor\analytics_project\dbt_project.yml
[0m18:38:28.308318 [debug] [MainThread]: Command `dbt run` failed at 18:38:28.308166 after 0.38 seconds
[0m18:38:28.309132 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002379A4243E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002379A3C8EF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023799D6A7A0>]}
[0m18:38:28.310031 [debug] [MainThread]: Flushing usage events
[0m18:38:29.294281 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:38:37.643850 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298FA50A7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298F8605590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298FB1B0F50>]}


============================== 18:38:37.653960 | 18875871-bda6-45a1-96eb-02a1f1f5e964 ==============================
[0m18:38:37.653960 [info ] [MainThread]: Running with dbt=1.9.3
[0m18:38:37.654849 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': 'C:\\Users\\karak\\.dbt', 'log_path': 'C:\\Users\\karak\\dbt_cursor\\analytics_project\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt clean', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m18:38:37.752358 [error] [MainThread]: Encountered an error:
Runtime Error
  The packages.yml file in this project is malformed. Please double check
  the contents of this file and fix any errors before retrying.
  
  You can find more information on the syntax for this file here:
  https://docs.getdbt.com/docs/package-management
  
  Validator Error:
  ecommerce_project was not found in the package index. Packages on the index require a namespace, e.g dbt-labs/dbt_utils
  

Error encountered in C:\Users\karak\dbt_cursor\analytics_project\dbt_project.yml
[0m18:38:37.753599 [debug] [MainThread]: Command `dbt clean` failed at 18:38:37.753452 after 0.30 seconds
[0m18:38:37.753956 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298FB721350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298FB4ED5B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298FB52ACF0>]}
[0m18:38:37.754329 [debug] [MainThread]: Flushing usage events
[0m18:38:38.815196 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:39:19.083040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FA1D5A7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025F9FE55590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FA2A10F50>]}


============================== 18:39:19.092008 | 198d5f3c-cd53-4fdb-b3e2-9d8e8cb29791 ==============================
[0m18:39:19.092008 [info ] [MainThread]: Running with dbt=1.9.3
[0m18:39:19.093571 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\karak\\.dbt', 'log_path': 'C:\\Users\\karak\\dbt_cursor\\analytics_project\\logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --select analytics_orders', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m18:39:19.279918 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '198d5f3c-cd53-4fdb-b3e2-9d8e8cb29791', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FA3474E90>]}
[0m18:39:19.349629 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '198d5f3c-cd53-4fdb-b3e2-9d8e8cb29791', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FA2D8FF00>]}
[0m18:39:19.351167 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m18:39:19.561067 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m18:39:19.723991 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:39:19.724621 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:39:19.768865 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '198d5f3c-cd53-4fdb-b3e2-9d8e8cb29791', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FA46D0D50>]}
[0m18:39:19.846483 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\karak\dbt_cursor\analytics_project\target\manifest.json
[0m18:39:19.849922 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\karak\dbt_cursor\analytics_project\target\semantic_manifest.json
[0m18:39:19.887067 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '198d5f3c-cd53-4fdb-b3e2-9d8e8cb29791', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FA2ECAA80>]}
[0m18:39:19.887547 [info ] [MainThread]: Found 3 models, 3 data tests, 2 sources, 433 macros
[0m18:39:19.888054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '198d5f3c-cd53-4fdb-b3e2-9d8e8cb29791', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FA4781630>]}
[0m18:39:19.889650 [info ] [MainThread]: 
[0m18:39:19.890310 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:39:19.890874 [info ] [MainThread]: 
[0m18:39:19.891966 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m18:39:19.894286 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbt_sample'
[0m18:39:19.967145 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample"
[0m18:39:19.967565 [debug] [ThreadPool]: On list_dbt_sample: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample"} */

    select distinct nspname from pg_namespace
  
[0m18:39:19.967851 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:39:20.014639 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.047 seconds
[0m18:39:20.016053 [debug] [ThreadPool]: On list_dbt_sample: Close
[0m18:39:20.020784 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbt_sample_analytics_schema_analytics_schema'
[0m18:39:20.027283 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema_analytics_schema"
[0m18:39:20.027693 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: BEGIN
[0m18:39:20.027960 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:39:20.067689 [debug] [ThreadPool]: SQL status: BEGIN in 0.040 seconds
[0m18:39:20.068103 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema_analytics_schema"
[0m18:39:20.068399 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample_analytics_schema_analytics_schema"} */
select
      'dbt_sample' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_schema_analytics_schema'
    union all
    select
      'dbt_sample' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_schema_analytics_schema'
    union all
    select
      'dbt_sample' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_schema_analytics_schema'
  
[0m18:39:20.073511 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m18:39:20.074647 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: ROLLBACK
[0m18:39:20.075476 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: Close
[0m18:39:20.076064 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dbt_sample_analytics_schema_analytics_schema, now list_dbt_sample_analytics_schema)
[0m18:39:20.077555 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema"
[0m18:39:20.077917 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: BEGIN
[0m18:39:20.078211 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:39:20.118540 [debug] [ThreadPool]: SQL status: BEGIN in 0.040 seconds
[0m18:39:20.118954 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema"
[0m18:39:20.119246 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample_analytics_schema"} */
select
      'dbt_sample' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_schema'
    union all
    select
      'dbt_sample' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_schema'
    union all
    select
      'dbt_sample' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_schema'
  
[0m18:39:20.124272 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.005 seconds
[0m18:39:20.125677 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: ROLLBACK
[0m18:39:20.126166 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: Close
[0m18:39:20.131905 [debug] [MainThread]: Using postgres connection "master"
[0m18:39:20.132293 [debug] [MainThread]: On master: BEGIN
[0m18:39:20.132555 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:39:20.174341 [debug] [MainThread]: SQL status: BEGIN in 0.042 seconds
[0m18:39:20.174980 [debug] [MainThread]: Using postgres connection "master"
[0m18:39:20.175405 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:39:20.183970 [debug] [MainThread]: SQL status: SELECT 10 in 0.008 seconds
[0m18:39:20.185639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '198d5f3c-cd53-4fdb-b3e2-9d8e8cb29791', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FA2E61710>]}
[0m18:39:20.186143 [debug] [MainThread]: On master: ROLLBACK
[0m18:39:20.186626 [debug] [MainThread]: Using postgres connection "master"
[0m18:39:20.186916 [debug] [MainThread]: On master: BEGIN
[0m18:39:20.187373 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m18:39:20.187634 [debug] [MainThread]: On master: COMMIT
[0m18:39:20.187865 [debug] [MainThread]: Using postgres connection "master"
[0m18:39:20.188081 [debug] [MainThread]: On master: COMMIT
[0m18:39:20.188411 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:39:20.188703 [debug] [MainThread]: On master: Close
[0m18:39:20.194888 [debug] [Thread-1 (]: Began running node model.analytics_project.analytics_orders
[0m18:39:20.195719 [info ] [Thread-1 (]: 1 of 1 START sql view model analytics_schema_analytics_schema.analytics_orders . [RUN]
[0m18:39:20.196669 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.analytics_project.analytics_orders'
[0m18:39:20.197278 [debug] [Thread-1 (]: Began compiling node model.analytics_project.analytics_orders
[0m18:39:20.203871 [debug] [Thread-1 (]: Writing injected SQL for node "model.analytics_project.analytics_orders"
[0m18:39:20.204886 [debug] [Thread-1 (]: Began executing node model.analytics_project.analytics_orders
[0m18:39:20.247272 [debug] [Thread-1 (]: Writing runtime sql for node "model.analytics_project.analytics_orders"
[0m18:39:20.248977 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m18:39:20.249965 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: BEGIN
[0m18:39:20.250505 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m18:39:20.416876 [debug] [Thread-1 (]: SQL status: BEGIN in 0.166 seconds
[0m18:39:20.417303 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m18:39:20.417625 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.analytics_orders"} */

  create view "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders__dbt_tmp"
    
    
  as (
    

WITH ecommerce_orders AS (
    -- Use source() to reference ecommerce models
    SELECT * FROM "dbt_sample"."ecommerce_ecommerce_schema"."stg_orders"
),
test_project_data AS (
    -- Use source() to reference test project models
    SELECT * FROM "dbt_sample"."my_test_my_test"."my_first_dbt_model"
)

SELECT
    eo.order_id,
    eo.customer_id,
    td.id as test_project_id,
    td.amount as some_metric
FROM ecommerce_orders eo
LEFT JOIN test_project_data td
ON eo.customer_id = td.order_id
  );
[0m18:39:20.427040 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.009 seconds
[0m18:39:20.433545 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m18:39:20.433938 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.analytics_orders"} */
alter table "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders__dbt_tmp" rename to "analytics_orders"
[0m18:39:20.434969 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:39:20.448501 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: COMMIT
[0m18:39:20.449035 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m18:39:20.449388 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: COMMIT
[0m18:39:20.459869 [debug] [Thread-1 (]: SQL status: COMMIT in 0.010 seconds
[0m18:39:20.466240 [debug] [Thread-1 (]: Applying DROP to: "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders__dbt_backup"
[0m18:39:20.470792 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m18:39:20.471165 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.analytics_orders"} */
drop view if exists "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders__dbt_backup" cascade
[0m18:39:20.471871 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.000 seconds
[0m18:39:20.473965 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: Close
[0m18:39:20.476904 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '198d5f3c-cd53-4fdb-b3e2-9d8e8cb29791', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FA4A110D0>]}
[0m18:39:20.478071 [info ] [Thread-1 (]: 1 of 1 OK created sql view model analytics_schema_analytics_schema.analytics_orders  [[32mCREATE VIEW[0m in 0.28s]
[0m18:39:20.479539 [debug] [Thread-1 (]: Finished running node model.analytics_project.analytics_orders
[0m18:39:20.481007 [debug] [MainThread]: Using postgres connection "master"
[0m18:39:20.481511 [debug] [MainThread]: On master: BEGIN
[0m18:39:20.481926 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:39:20.524158 [debug] [MainThread]: SQL status: BEGIN in 0.042 seconds
[0m18:39:20.525070 [debug] [MainThread]: On master: COMMIT
[0m18:39:20.525573 [debug] [MainThread]: Using postgres connection "master"
[0m18:39:20.526077 [debug] [MainThread]: On master: COMMIT
[0m18:39:20.526860 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:39:20.527863 [debug] [MainThread]: On master: Close
[0m18:39:20.528959 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:39:20.530021 [debug] [MainThread]: Connection 'list_dbt_sample' was properly closed.
[0m18:39:20.530427 [debug] [MainThread]: Connection 'list_dbt_sample_analytics_schema' was properly closed.
[0m18:39:20.530891 [debug] [MainThread]: Connection 'model.analytics_project.analytics_orders' was properly closed.
[0m18:39:20.531375 [info ] [MainThread]: 
[0m18:39:20.532217 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.64 seconds (0.64s).
[0m18:39:20.533462 [debug] [MainThread]: Command end result
[0m18:39:20.562640 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\karak\dbt_cursor\analytics_project\target\manifest.json
[0m18:39:20.565465 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\karak\dbt_cursor\analytics_project\target\semantic_manifest.json
[0m18:39:20.581241 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\karak\dbt_cursor\analytics_project\target\run_results.json
[0m18:39:20.581824 [info ] [MainThread]: 
[0m18:39:20.582573 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:39:20.583016 [info ] [MainThread]: 
[0m18:39:20.583533 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m18:39:20.584329 [debug] [MainThread]: Command `dbt run` succeeded at 18:39:20.584206 after 1.68 seconds
[0m18:39:20.584684 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FA47E7EE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FA481EFD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FA481EF30>]}
[0m18:39:20.585049 [debug] [MainThread]: Flushing usage events
[0m18:39:21.662088 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:39:30.021508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000214940E67B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000214921E5590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021494D84F50>]}


============================== 18:39:30.030659 | 9eafd30b-fd79-4c75-850e-dc265d3706ab ==============================
[0m18:39:30.030659 [info ] [MainThread]: Running with dbt=1.9.3
[0m18:39:30.031464 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\karak\\.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\karak\\dbt_cursor\\analytics_project\\logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt show --select analytics_orders', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m18:39:30.219935 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9eafd30b-fd79-4c75-850e-dc265d3706ab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021495780E90>]}
[0m18:39:30.281545 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9eafd30b-fd79-4c75-850e-dc265d3706ab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002149510FF00>]}
[0m18:39:30.318438 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m18:39:30.510262 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m18:39:30.642626 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:39:30.643135 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:39:30.687499 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9eafd30b-fd79-4c75-850e-dc265d3706ab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021496A78E50>]}
[0m18:39:30.763762 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\karak\dbt_cursor\analytics_project\target\manifest.json
[0m18:39:30.767559 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\karak\dbt_cursor\analytics_project\target\semantic_manifest.json
[0m18:39:30.770082 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9eafd30b-fd79-4c75-850e-dc265d3706ab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002149524AE40>]}
[0m18:39:30.770522 [info ] [MainThread]: Found 3 models, 3 data tests, 2 sources, 433 macros
[0m18:39:30.771028 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9eafd30b-fd79-4c75-850e-dc265d3706ab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021495725C50>]}
[0m18:39:30.773153 [info ] [MainThread]: 
[0m18:39:30.773917 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:39:30.774465 [info ] [MainThread]: 
[0m18:39:30.775989 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m18:39:30.782186 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbt_sample_analytics_schema_analytics_schema'
[0m18:39:30.857473 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema_analytics_schema"
[0m18:39:30.857903 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: BEGIN
[0m18:39:30.859823 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:39:30.905616 [debug] [ThreadPool]: SQL status: BEGIN in 0.046 seconds
[0m18:39:30.906017 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema_analytics_schema"
[0m18:39:30.906316 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample_analytics_schema_analytics_schema"} */
select
      'dbt_sample' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_schema_analytics_schema'
    union all
    select
      'dbt_sample' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_schema_analytics_schema'
    union all
    select
      'dbt_sample' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_schema_analytics_schema'
  
[0m18:39:30.913759 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.007 seconds
[0m18:39:30.915703 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: ROLLBACK
[0m18:39:30.916354 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: Close
[0m18:39:30.916962 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dbt_sample_analytics_schema_analytics_schema, now list_dbt_sample_analytics_schema)
[0m18:39:30.918465 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema"
[0m18:39:30.919261 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: BEGIN
[0m18:39:30.919564 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:39:30.956879 [debug] [ThreadPool]: SQL status: BEGIN in 0.037 seconds
[0m18:39:30.957520 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema"
[0m18:39:30.957834 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample_analytics_schema"} */
select
      'dbt_sample' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_schema'
    union all
    select
      'dbt_sample' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_schema'
    union all
    select
      'dbt_sample' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_schema'
  
[0m18:39:30.965301 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.007 seconds
[0m18:39:30.966552 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: ROLLBACK
[0m18:39:30.967121 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: Close
[0m18:39:30.971817 [debug] [MainThread]: Using postgres connection "master"
[0m18:39:30.972136 [debug] [MainThread]: On master: BEGIN
[0m18:39:30.972393 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:39:31.010718 [debug] [MainThread]: SQL status: BEGIN in 0.038 seconds
[0m18:39:31.011125 [debug] [MainThread]: Using postgres connection "master"
[0m18:39:31.011493 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:39:31.018217 [debug] [MainThread]: SQL status: SELECT 12 in 0.006 seconds
[0m18:39:31.019721 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9eafd30b-fd79-4c75-850e-dc265d3706ab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021496BB8390>]}
[0m18:39:31.020119 [debug] [MainThread]: On master: ROLLBACK
[0m18:39:31.020576 [debug] [MainThread]: On master: Close
[0m18:39:31.026279 [debug] [Thread-1 (]: Began running node model.analytics_project.analytics_orders
[0m18:39:31.026880 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.analytics_project.analytics_orders'
[0m18:39:31.027247 [debug] [Thread-1 (]: Began compiling node model.analytics_project.analytics_orders
[0m18:39:31.034630 [debug] [Thread-1 (]: Writing injected SQL for node "model.analytics_project.analytics_orders"
[0m18:39:31.035653 [debug] [Thread-1 (]: Began executing node model.analytics_project.analytics_orders
[0m18:39:31.043201 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m18:39:31.043656 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.analytics_orders"} */

  
  

WITH ecommerce_orders AS (
    -- Use source() to reference ecommerce models
    SELECT * FROM "dbt_sample"."ecommerce_ecommerce_schema"."stg_orders"
),
test_project_data AS (
    -- Use source() to reference test project models
    SELECT * FROM "dbt_sample"."my_test_my_test"."my_first_dbt_model"
)

SELECT
    eo.order_id,
    eo.customer_id,
    td.id as test_project_id,
    td.amount as some_metric
FROM ecommerce_orders eo
LEFT JOIN test_project_data td
ON eo.customer_id = td.order_id
  
  limit 5

[0m18:39:31.043995 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m18:39:31.084333 [debug] [Thread-1 (]: SQL status: SELECT 3 in 0.040 seconds
[0m18:39:31.086583 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: Close
[0m18:39:31.087411 [debug] [Thread-1 (]: Finished running node model.analytics_project.analytics_orders
[0m18:39:31.088213 [debug] [Thread-1 (]: Began running node test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba
[0m18:39:31.088631 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.analytics_project.analytics_orders, now test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba)
[0m18:39:31.089015 [debug] [Thread-1 (]: Began compiling node test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba
[0m18:39:31.102478 [debug] [Thread-1 (]: Writing injected SQL for node "test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba"
[0m18:39:31.103529 [debug] [Thread-1 (]: Began executing node test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba
[0m18:39:31.106180 [debug] [Thread-1 (]: Using postgres connection "test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba"
[0m18:39:31.106709 [debug] [Thread-1 (]: On test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba"} */

  
  
    
    



select customer_id
from "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders"
where customer_id is null



  
  limit 5

[0m18:39:31.107178 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:39:31.150224 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.043 seconds
[0m18:39:31.151387 [debug] [Thread-1 (]: On test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba: Close
[0m18:39:31.152291 [debug] [Thread-1 (]: Finished running node test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba
[0m18:39:31.152811 [debug] [Thread-1 (]: Began running node test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b
[0m18:39:31.153285 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba, now test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b)
[0m18:39:31.153631 [debug] [Thread-1 (]: Began compiling node test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b
[0m18:39:31.156892 [debug] [Thread-1 (]: Writing injected SQL for node "test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b"
[0m18:39:31.157700 [debug] [Thread-1 (]: Began executing node test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b
[0m18:39:31.161414 [debug] [Thread-1 (]: Using postgres connection "test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b"
[0m18:39:31.161931 [debug] [Thread-1 (]: On test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b"} */

  
  
    
    



select order_id
from "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders"
where order_id is null



  
  limit 5

[0m18:39:31.162320 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:39:31.204154 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.042 seconds
[0m18:39:31.205350 [debug] [Thread-1 (]: On test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b: Close
[0m18:39:31.206380 [debug] [Thread-1 (]: Finished running node test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b
[0m18:39:31.206873 [debug] [Thread-1 (]: Began running node test.analytics_project.unique_analytics_orders_order_id.20264248d8
[0m18:39:31.207422 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b, now test.analytics_project.unique_analytics_orders_order_id.20264248d8)
[0m18:39:31.207925 [debug] [Thread-1 (]: Began compiling node test.analytics_project.unique_analytics_orders_order_id.20264248d8
[0m18:39:31.215175 [debug] [Thread-1 (]: Writing injected SQL for node "test.analytics_project.unique_analytics_orders_order_id.20264248d8"
[0m18:39:31.216128 [debug] [Thread-1 (]: Began executing node test.analytics_project.unique_analytics_orders_order_id.20264248d8
[0m18:39:31.218788 [debug] [Thread-1 (]: Using postgres connection "test.analytics_project.unique_analytics_orders_order_id.20264248d8"
[0m18:39:31.219158 [debug] [Thread-1 (]: On test.analytics_project.unique_analytics_orders_order_id.20264248d8: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "test.analytics_project.unique_analytics_orders_order_id.20264248d8"} */

  
  
    
    

select
    order_id as unique_field,
    count(*) as n_records

from "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders"
where order_id is not null
group by order_id
having count(*) > 1



  
  limit 5

[0m18:39:31.219452 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:39:31.268084 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.049 seconds
[0m18:39:31.269346 [debug] [Thread-1 (]: On test.analytics_project.unique_analytics_orders_order_id.20264248d8: Close
[0m18:39:31.270398 [debug] [Thread-1 (]: Finished running node test.analytics_project.unique_analytics_orders_order_id.20264248d8
[0m18:39:31.271724 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:39:31.272063 [debug] [MainThread]: Connection 'list_dbt_sample_analytics_schema' was properly closed.
[0m18:39:31.272377 [debug] [MainThread]: Connection 'test.analytics_project.unique_analytics_orders_order_id.20264248d8' was properly closed.
[0m18:39:31.273435 [debug] [MainThread]: Command end result
[0m18:39:31.294033 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\karak\dbt_cursor\analytics_project\target\manifest.json
[0m18:39:31.296190 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\karak\dbt_cursor\analytics_project\target\semantic_manifest.json
[0m18:39:31.302623 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\karak\dbt_cursor\analytics_project\target\run_results.json
[0m18:39:31.303087 [debug] [MainThread]: Excluded node 'not_null_analytics_orders_customer_id' from results
[0m18:39:31.303493 [debug] [MainThread]: Excluded node 'not_null_analytics_orders_order_id' from results
[0m18:39:31.303853 [debug] [MainThread]: Excluded node 'unique_analytics_orders_order_id' from results
[0m18:39:31.304624 [info ] [MainThread]: Previewing node 'analytics_orders':
| order_id | customer_id | test_project_id | some_metric |
| -------- | ----------- | --------------- | ----------- |
|        1 |           1 |               1 |         100 |
|        2 |           2 |               2 |         200 |
|        3 |           3 |               3 |         150 |

[0m18:39:31.305731 [debug] [MainThread]: Command `dbt show` succeeded at 18:39:31.305609 after 1.47 seconds
[0m18:39:31.306079 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000214950E62D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021496B87070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021496E68AA0>]}
[0m18:39:31.306405 [debug] [MainThread]: Flushing usage events
[0m18:39:32.471568 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:43:38.004041 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022461CA67B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002245FDA5590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022462950F50>]}


============================== 18:43:38.015178 | eacbe927-065f-4ef5-b29d-945fc47d6898 ==============================
[0m18:43:38.015178 [info ] [MainThread]: Running with dbt=1.9.3
[0m18:43:38.015896 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\karak\\.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\karak\\dbt_cursor\\analytics_project\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m18:43:38.199343 [error] [MainThread]: Encountered an error:
Runtime Error
  The packages.yml file in this project is malformed. Please double check
  the contents of this file and fix any errors before retrying.
  
  You can find more information on the syntax for this file here:
  https://docs.getdbt.com/docs/package-management
  
  Validator Error:
  Additional properties are not allowed ('sources', 'version' were unexpected)
  

Error encountered in C:\Users\karak\dbt_cursor\analytics_project\dbt_project.yml
[0m18:43:38.200716 [debug] [MainThread]: Command `dbt run` failed at 18:43:38.200557 after 0.43 seconds
[0m18:43:38.201072 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022463348D60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000224633429F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022462CCE7A0>]}
[0m18:43:38.201434 [debug] [MainThread]: Flushing usage events
[0m18:43:39.257913 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:44:34.232690 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025AD3BDA7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025AD1CFD590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025AD4880F50>]}


============================== 18:44:34.241663 | 36394a2a-80f5-4728-a8f8-ee1372c64b67 ==============================
[0m18:44:34.241663 [info ] [MainThread]: Running with dbt=1.9.3
[0m18:44:34.242454 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\karak\\.dbt', 'log_path': 'C:\\Users\\karak\\dbt_cursor\\analytics_project\\logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m18:44:34.414933 [error] [MainThread]: Encountered an error:
Runtime Error
  The packages.yml file in this project is malformed. Please double check
  the contents of this file and fix any errors before retrying.
  
  You can find more information on the syntax for this file here:
  https://docs.getdbt.com/docs/package-management
  
  Validator Error:
  Additional properties are not allowed ('sources', 'version' were unexpected)
  

Error encountered in C:\Users\karak\dbt_cursor\analytics_project\dbt_project.yml
[0m18:44:34.416462 [debug] [MainThread]: Command `dbt run` failed at 18:44:34.416303 after 0.37 seconds
[0m18:44:34.416840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025AD5368D60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025AD53629F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025AD4BFE7A0>]}
[0m18:44:34.417200 [debug] [MainThread]: Flushing usage events
[0m18:44:35.664548 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:48:17.327405 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016EED0567B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016EEB14D590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016EEDD00F50>]}


============================== 18:48:17.336350 | 0fb4817f-644f-4a12-8f96-4be33bec9195 ==============================
[0m18:48:17.336350 [info ] [MainThread]: Running with dbt=1.9.3
[0m18:48:17.337367 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\karak\\.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\karak\\dbt_cursor\\analytics_project\\logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m18:48:17.540330 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0fb4817f-644f-4a12-8f96-4be33bec9195', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016EEE6F4E90>]}
[0m18:48:17.604389 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0fb4817f-644f-4a12-8f96-4be33bec9195', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016EEE07FF00>]}
[0m18:48:17.606200 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m18:48:17.817298 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m18:48:17.964200 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:48:17.964621 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:48:18.009375 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0fb4817f-644f-4a12-8f96-4be33bec9195', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016EEF954D50>]}
[0m18:48:18.096410 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\karak\dbt_cursor\analytics_project\target\manifest.json
[0m18:48:18.100327 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\karak\dbt_cursor\analytics_project\target\semantic_manifest.json
[0m18:48:18.137787 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0fb4817f-644f-4a12-8f96-4be33bec9195', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016EEE1BAA80>]}
[0m18:48:18.138715 [info ] [MainThread]: Found 3 models, 3 data tests, 2 sources, 433 macros
[0m18:48:18.139318 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0fb4817f-644f-4a12-8f96-4be33bec9195', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016EEF9FD630>]}
[0m18:48:18.141220 [info ] [MainThread]: 
[0m18:48:18.141958 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:48:18.143388 [info ] [MainThread]: 
[0m18:48:18.144412 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m18:48:18.148404 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbt_sample'
[0m18:48:18.241535 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample"
[0m18:48:18.242077 [debug] [ThreadPool]: On list_dbt_sample: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample"} */

    select distinct nspname from pg_namespace
  
[0m18:48:18.242531 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:48:18.293587 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.051 seconds
[0m18:48:18.294859 [debug] [ThreadPool]: On list_dbt_sample: Close
[0m18:48:18.297143 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample"
[0m18:48:18.297660 [debug] [ThreadPool]: On list_dbt_sample: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample"} */

    select distinct nspname from pg_namespace
  
[0m18:48:18.298139 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:48:18.342279 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.044 seconds
[0m18:48:18.343519 [debug] [ThreadPool]: On list_dbt_sample: Close
[0m18:48:18.345374 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbt_sample_analytics_schema_analytics_schema'
[0m18:48:18.351241 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema_analytics_schema"
[0m18:48:18.351577 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: BEGIN
[0m18:48:18.351854 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:48:18.391968 [debug] [ThreadPool]: SQL status: BEGIN in 0.040 seconds
[0m18:48:18.392379 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema_analytics_schema"
[0m18:48:18.392668 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample_analytics_schema_analytics_schema"} */
select
      'dbt_sample' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_schema_analytics_schema'
    union all
    select
      'dbt_sample' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_schema_analytics_schema'
    union all
    select
      'dbt_sample' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_schema_analytics_schema'
  
[0m18:48:18.397841 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m18:48:18.398893 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: ROLLBACK
[0m18:48:18.399360 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: Close
[0m18:48:18.399991 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dbt_sample_analytics_schema_analytics_schema, now list_dbt_sample_analytics_schema)
[0m18:48:18.402745 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema"
[0m18:48:18.403448 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: BEGIN
[0m18:48:18.403894 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:48:18.448707 [debug] [ThreadPool]: SQL status: BEGIN in 0.045 seconds
[0m18:48:18.449091 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema"
[0m18:48:18.449370 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample_analytics_schema"} */
select
      'dbt_sample' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_schema'
    union all
    select
      'dbt_sample' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_schema'
    union all
    select
      'dbt_sample' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_schema'
  
[0m18:48:18.457970 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.008 seconds
[0m18:48:18.459290 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: ROLLBACK
[0m18:48:18.459850 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: Close
[0m18:48:18.465598 [debug] [MainThread]: Using postgres connection "master"
[0m18:48:18.466134 [debug] [MainThread]: On master: BEGIN
[0m18:48:18.466550 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:48:18.517159 [debug] [MainThread]: SQL status: BEGIN in 0.051 seconds
[0m18:48:18.517553 [debug] [MainThread]: Using postgres connection "master"
[0m18:48:18.517898 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:48:18.526854 [debug] [MainThread]: SQL status: SELECT 10 in 0.008 seconds
[0m18:48:18.528425 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0fb4817f-644f-4a12-8f96-4be33bec9195', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016EEFDDC2C0>]}
[0m18:48:18.528845 [debug] [MainThread]: On master: ROLLBACK
[0m18:48:18.529354 [debug] [MainThread]: Using postgres connection "master"
[0m18:48:18.529633 [debug] [MainThread]: On master: BEGIN
[0m18:48:18.530087 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m18:48:18.530351 [debug] [MainThread]: On master: COMMIT
[0m18:48:18.530578 [debug] [MainThread]: Using postgres connection "master"
[0m18:48:18.530825 [debug] [MainThread]: On master: COMMIT
[0m18:48:18.531166 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:48:18.531441 [debug] [MainThread]: On master: Close
[0m18:48:18.538867 [debug] [Thread-1 (]: Began running node model.analytics_project.analytics_orders
[0m18:48:18.539471 [info ] [Thread-1 (]: 1 of 3 START sql view model analytics_schema_analytics_schema.analytics_orders . [RUN]
[0m18:48:18.540595 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.analytics_project.analytics_orders'
[0m18:48:18.541194 [debug] [Thread-1 (]: Began compiling node model.analytics_project.analytics_orders
[0m18:48:18.549746 [debug] [Thread-1 (]: Writing injected SQL for node "model.analytics_project.analytics_orders"
[0m18:48:18.550707 [debug] [Thread-1 (]: Began executing node model.analytics_project.analytics_orders
[0m18:48:18.589498 [debug] [Thread-1 (]: Writing runtime sql for node "model.analytics_project.analytics_orders"
[0m18:48:18.591374 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m18:48:18.591902 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: BEGIN
[0m18:48:18.592302 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m18:48:18.631826 [debug] [Thread-1 (]: SQL status: BEGIN in 0.039 seconds
[0m18:48:18.632265 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m18:48:18.632595 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.analytics_orders"} */

  create view "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders__dbt_tmp"
    
    
  as (
    

WITH ecommerce_orders AS (
    -- Use source() to reference ecommerce models
    SELECT * FROM "dbt_sample"."ecommerce_ecommerce_schema"."stg_orders"
),
test_project_data AS (
    -- Use source() to reference test project models
    SELECT * FROM "dbt_sample"."my_test_my_test"."my_first_dbt_model"
)

SELECT
    eo.order_id,
    eo.customer_id,
    td.id as test_project_id,
    td.amount as some_metric
FROM ecommerce_orders eo
LEFT JOIN test_project_data td
ON eo.customer_id = td.order_id
  );
[0m18:48:18.640438 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.007 seconds
[0m18:48:18.646447 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m18:48:18.646868 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.analytics_orders"} */
alter table "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders__dbt_tmp" rename to "analytics_orders"
[0m18:48:18.647739 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:48:18.662472 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: COMMIT
[0m18:48:18.663022 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m18:48:18.663363 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: COMMIT
[0m18:48:18.665156 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m18:48:18.671751 [debug] [Thread-1 (]: Applying DROP to: "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders__dbt_backup"
[0m18:48:18.678616 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m18:48:18.679182 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.analytics_orders"} */
drop view if exists "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders__dbt_backup" cascade
[0m18:48:18.680004 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.000 seconds
[0m18:48:18.682217 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: Close
[0m18:48:18.684666 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0fb4817f-644f-4a12-8f96-4be33bec9195', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016EEFAF9790>]}
[0m18:48:18.685482 [info ] [Thread-1 (]: 1 of 3 OK created sql view model analytics_schema_analytics_schema.analytics_orders  [[32mCREATE VIEW[0m in 0.14s]
[0m18:48:18.686999 [debug] [Thread-1 (]: Finished running node model.analytics_project.analytics_orders
[0m18:48:18.687556 [debug] [Thread-1 (]: Began running node model.analytics_project.my_first_dbt_model
[0m18:48:18.688152 [info ] [Thread-1 (]: 2 of 3 START sql table model analytics_schema.my_first_dbt_model ............... [RUN]
[0m18:48:18.690239 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.analytics_project.analytics_orders, now model.analytics_project.my_first_dbt_model)
[0m18:48:18.690789 [debug] [Thread-1 (]: Began compiling node model.analytics_project.my_first_dbt_model
[0m18:48:18.694056 [debug] [Thread-1 (]: Writing injected SQL for node "model.analytics_project.my_first_dbt_model"
[0m18:48:18.695029 [debug] [Thread-1 (]: Began executing node model.analytics_project.my_first_dbt_model
[0m18:48:18.721517 [debug] [Thread-1 (]: Writing runtime sql for node "model.analytics_project.my_first_dbt_model"
[0m18:48:18.723597 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_first_dbt_model"
[0m18:48:18.724032 [debug] [Thread-1 (]: On model.analytics_project.my_first_dbt_model: BEGIN
[0m18:48:18.724359 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:48:18.775783 [debug] [Thread-1 (]: SQL status: BEGIN in 0.051 seconds
[0m18:48:18.776302 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_first_dbt_model"
[0m18:48:18.776638 [debug] [Thread-1 (]: On model.analytics_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.my_first_dbt_model"} */

  
    

  create  table "dbt_sample"."analytics_schema"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m18:48:18.781256 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.004 seconds
[0m18:48:18.788481 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_first_dbt_model"
[0m18:48:18.789283 [debug] [Thread-1 (]: On model.analytics_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.my_first_dbt_model"} */
alter table "dbt_sample"."analytics_schema"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m18:48:18.790499 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:48:18.794308 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_first_dbt_model"
[0m18:48:18.794743 [debug] [Thread-1 (]: On model.analytics_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.my_first_dbt_model"} */
alter table "dbt_sample"."analytics_schema"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m18:48:18.795694 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:48:18.802505 [debug] [Thread-1 (]: On model.analytics_project.my_first_dbt_model: COMMIT
[0m18:48:18.802955 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_first_dbt_model"
[0m18:48:18.803572 [debug] [Thread-1 (]: On model.analytics_project.my_first_dbt_model: COMMIT
[0m18:48:18.814047 [debug] [Thread-1 (]: SQL status: COMMIT in 0.010 seconds
[0m18:48:18.816318 [debug] [Thread-1 (]: Applying DROP to: "dbt_sample"."analytics_schema"."my_first_dbt_model__dbt_backup"
[0m18:48:18.819679 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_first_dbt_model"
[0m18:48:18.821049 [debug] [Thread-1 (]: On model.analytics_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.my_first_dbt_model"} */
drop table if exists "dbt_sample"."analytics_schema"."my_first_dbt_model__dbt_backup" cascade
[0m18:48:18.825524 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m18:48:18.826882 [debug] [Thread-1 (]: On model.analytics_project.my_first_dbt_model: Close
[0m18:48:18.827544 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0fb4817f-644f-4a12-8f96-4be33bec9195', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016EEFE54EC0>]}
[0m18:48:18.828332 [info ] [Thread-1 (]: 2 of 3 OK created sql table model analytics_schema.my_first_dbt_model .......... [[32mSELECT 2[0m in 0.14s]
[0m18:48:18.829182 [debug] [Thread-1 (]: Finished running node model.analytics_project.my_first_dbt_model
[0m18:48:18.829966 [debug] [Thread-1 (]: Began running node model.analytics_project.my_second_dbt_model
[0m18:48:18.830436 [info ] [Thread-1 (]: 3 of 3 START sql view model analytics_schema.my_second_dbt_model ............... [RUN]
[0m18:48:18.831091 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.analytics_project.my_first_dbt_model, now model.analytics_project.my_second_dbt_model)
[0m18:48:18.831605 [debug] [Thread-1 (]: Began compiling node model.analytics_project.my_second_dbt_model
[0m18:48:18.833931 [debug] [Thread-1 (]: Writing injected SQL for node "model.analytics_project.my_second_dbt_model"
[0m18:48:18.834789 [debug] [Thread-1 (]: Began executing node model.analytics_project.my_second_dbt_model
[0m18:48:18.838507 [debug] [Thread-1 (]: Writing runtime sql for node "model.analytics_project.my_second_dbt_model"
[0m18:48:18.839973 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_second_dbt_model"
[0m18:48:18.840552 [debug] [Thread-1 (]: On model.analytics_project.my_second_dbt_model: BEGIN
[0m18:48:18.841043 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:48:18.892951 [debug] [Thread-1 (]: SQL status: BEGIN in 0.052 seconds
[0m18:48:18.893548 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_second_dbt_model"
[0m18:48:18.894034 [debug] [Thread-1 (]: On model.analytics_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.my_second_dbt_model"} */

  create view "dbt_sample"."analytics_schema"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "dbt_sample"."analytics_schema"."my_first_dbt_model"
where id = 1
  );
[0m18:48:18.898714 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.004 seconds
[0m18:48:18.902733 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_second_dbt_model"
[0m18:48:18.903344 [debug] [Thread-1 (]: On model.analytics_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.my_second_dbt_model"} */
alter table "dbt_sample"."analytics_schema"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m18:48:18.904897 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:48:18.906372 [debug] [Thread-1 (]: On model.analytics_project.my_second_dbt_model: COMMIT
[0m18:48:18.906747 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_second_dbt_model"
[0m18:48:18.907049 [debug] [Thread-1 (]: On model.analytics_project.my_second_dbt_model: COMMIT
[0m18:48:18.908852 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m18:48:18.911407 [debug] [Thread-1 (]: Applying DROP to: "dbt_sample"."analytics_schema"."my_second_dbt_model__dbt_backup"
[0m18:48:18.912259 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_second_dbt_model"
[0m18:48:18.912700 [debug] [Thread-1 (]: On model.analytics_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.my_second_dbt_model"} */
drop view if exists "dbt_sample"."analytics_schema"."my_second_dbt_model__dbt_backup" cascade
[0m18:48:18.913357 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.000 seconds
[0m18:48:18.915011 [debug] [Thread-1 (]: On model.analytics_project.my_second_dbt_model: Close
[0m18:48:18.915702 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0fb4817f-644f-4a12-8f96-4be33bec9195', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016EEFECCB90>]}
[0m18:48:18.916457 [info ] [Thread-1 (]: 3 of 3 OK created sql view model analytics_schema.my_second_dbt_model .......... [[32mCREATE VIEW[0m in 0.08s]
[0m18:48:18.917678 [debug] [Thread-1 (]: Finished running node model.analytics_project.my_second_dbt_model
[0m18:48:18.919033 [debug] [MainThread]: Using postgres connection "master"
[0m18:48:18.919473 [debug] [MainThread]: On master: BEGIN
[0m18:48:18.920052 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:48:18.966793 [debug] [MainThread]: SQL status: BEGIN in 0.047 seconds
[0m18:48:18.967190 [debug] [MainThread]: On master: COMMIT
[0m18:48:18.967463 [debug] [MainThread]: Using postgres connection "master"
[0m18:48:18.967691 [debug] [MainThread]: On master: COMMIT
[0m18:48:18.968039 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:48:18.968296 [debug] [MainThread]: On master: Close
[0m18:48:18.968674 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:48:18.969475 [debug] [MainThread]: Connection 'list_dbt_sample' was properly closed.
[0m18:48:18.970135 [debug] [MainThread]: Connection 'list_dbt_sample_analytics_schema' was properly closed.
[0m18:48:18.970757 [debug] [MainThread]: Connection 'model.analytics_project.my_second_dbt_model' was properly closed.
[0m18:48:18.971302 [info ] [MainThread]: 
[0m18:48:18.973994 [info ] [MainThread]: Finished running 1 table model, 2 view models in 0 hours 0 minutes and 0.83 seconds (0.83s).
[0m18:48:18.975761 [debug] [MainThread]: Command end result
[0m18:48:18.998793 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\karak\dbt_cursor\analytics_project\target\manifest.json
[0m18:48:19.000834 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\karak\dbt_cursor\analytics_project\target\semantic_manifest.json
[0m18:48:19.011104 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\karak\dbt_cursor\analytics_project\target\run_results.json
[0m18:48:19.011751 [info ] [MainThread]: 
[0m18:48:19.012587 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:48:19.013286 [info ] [MainThread]: 
[0m18:48:19.013948 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m18:48:19.015737 [debug] [MainThread]: Command `dbt run` succeeded at 18:48:19.015594 after 1.90 seconds
[0m18:48:19.016105 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016EEF99D150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016EEF92F4D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016EEE0F3A80>]}
[0m18:48:19.016440 [debug] [MainThread]: Flushing usage events
[0m18:48:20.034208 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:48:33.751157 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D8C2B67B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D8A425590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D8CF60F50>]}


============================== 18:48:33.761700 | 2a6b373d-5935-4149-b6c5-11e68decd0f7 ==============================
[0m18:48:33.761700 [info ] [MainThread]: Running with dbt=1.9.3
[0m18:48:33.762496 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\karak\\dbt_cursor\\analytics_project\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\karak\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt show --select analytics_orders', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m18:48:33.955518 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2a6b373d-5935-4149-b6c5-11e68decd0f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D8D5D0E90>]}
[0m18:48:34.019352 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2a6b373d-5935-4149-b6c5-11e68decd0f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D8D2D7F00>]}
[0m18:48:34.061390 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m18:48:34.264126 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m18:48:34.409317 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:48:34.409710 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:48:34.451388 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2a6b373d-5935-4149-b6c5-11e68decd0f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D8ECB8E50>]}
[0m18:48:34.531840 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\karak\dbt_cursor\analytics_project\target\manifest.json
[0m18:48:34.535255 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\karak\dbt_cursor\analytics_project\target\semantic_manifest.json
[0m18:48:34.539399 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2a6b373d-5935-4149-b6c5-11e68decd0f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D8D416E40>]}
[0m18:48:34.540124 [info ] [MainThread]: Found 3 models, 3 data tests, 2 sources, 433 macros
[0m18:48:34.540829 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2a6b373d-5935-4149-b6c5-11e68decd0f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D8D575C50>]}
[0m18:48:34.542473 [info ] [MainThread]: 
[0m18:48:34.543163 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:48:34.543786 [info ] [MainThread]: 
[0m18:48:34.544503 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m18:48:34.548235 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbt_sample_analytics_schema_analytics_schema'
[0m18:48:34.630745 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema_analytics_schema"
[0m18:48:34.631142 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: BEGIN
[0m18:48:34.631764 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:48:34.683718 [debug] [ThreadPool]: SQL status: BEGIN in 0.052 seconds
[0m18:48:34.684112 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema_analytics_schema"
[0m18:48:34.684426 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample_analytics_schema_analytics_schema"} */
select
      'dbt_sample' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_schema_analytics_schema'
    union all
    select
      'dbt_sample' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_schema_analytics_schema'
    union all
    select
      'dbt_sample' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_schema_analytics_schema'
  
[0m18:48:34.692762 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.008 seconds
[0m18:48:34.694662 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: ROLLBACK
[0m18:48:34.695234 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: Close
[0m18:48:34.695828 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dbt_sample_analytics_schema_analytics_schema, now list_dbt_sample_analytics_schema)
[0m18:48:34.698059 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema"
[0m18:48:34.698848 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: BEGIN
[0m18:48:34.699228 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:48:34.738774 [debug] [ThreadPool]: SQL status: BEGIN in 0.039 seconds
[0m18:48:34.739357 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema"
[0m18:48:34.739857 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample_analytics_schema"} */
select
      'dbt_sample' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_schema'
    union all
    select
      'dbt_sample' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_schema'
    union all
    select
      'dbt_sample' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_schema'
  
[0m18:48:34.745619 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.005 seconds
[0m18:48:34.746835 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: ROLLBACK
[0m18:48:34.747311 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: Close
[0m18:48:34.752790 [debug] [MainThread]: Using postgres connection "master"
[0m18:48:34.754140 [debug] [MainThread]: On master: BEGIN
[0m18:48:34.754600 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:48:34.794664 [debug] [MainThread]: SQL status: BEGIN in 0.040 seconds
[0m18:48:34.795071 [debug] [MainThread]: Using postgres connection "master"
[0m18:48:34.795445 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:48:34.801805 [debug] [MainThread]: SQL status: SELECT 12 in 0.006 seconds
[0m18:48:34.803895 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2a6b373d-5935-4149-b6c5-11e68decd0f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D8EDF8390>]}
[0m18:48:34.804479 [debug] [MainThread]: On master: ROLLBACK
[0m18:48:34.805595 [debug] [MainThread]: On master: Close
[0m18:48:34.811438 [debug] [Thread-1 (]: Began running node model.analytics_project.analytics_orders
[0m18:48:34.812018 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.analytics_project.analytics_orders'
[0m18:48:34.812373 [debug] [Thread-1 (]: Began compiling node model.analytics_project.analytics_orders
[0m18:48:34.820766 [debug] [Thread-1 (]: Writing injected SQL for node "model.analytics_project.analytics_orders"
[0m18:48:34.822153 [debug] [Thread-1 (]: Began executing node model.analytics_project.analytics_orders
[0m18:48:34.828925 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m18:48:34.829366 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.analytics_orders"} */

  
  

WITH ecommerce_orders AS (
    -- Use source() to reference ecommerce models
    SELECT * FROM "dbt_sample"."ecommerce_ecommerce_schema"."stg_orders"
),
test_project_data AS (
    -- Use source() to reference test project models
    SELECT * FROM "dbt_sample"."my_test_my_test"."my_first_dbt_model"
)

SELECT
    eo.order_id,
    eo.customer_id,
    td.id as test_project_id,
    td.amount as some_metric
FROM ecommerce_orders eo
LEFT JOIN test_project_data td
ON eo.customer_id = td.order_id
  
  limit 5

[0m18:48:34.829722 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m18:48:34.873048 [debug] [Thread-1 (]: SQL status: SELECT 3 in 0.043 seconds
[0m18:48:34.875614 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: Close
[0m18:48:34.876546 [debug] [Thread-1 (]: Finished running node model.analytics_project.analytics_orders
[0m18:48:34.877491 [debug] [Thread-1 (]: Began running node test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba
[0m18:48:34.878054 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.analytics_project.analytics_orders, now test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba)
[0m18:48:34.878506 [debug] [Thread-1 (]: Began compiling node test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba
[0m18:48:34.891540 [debug] [Thread-1 (]: Writing injected SQL for node "test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba"
[0m18:48:34.892651 [debug] [Thread-1 (]: Began executing node test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba
[0m18:48:34.895188 [debug] [Thread-1 (]: Using postgres connection "test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba"
[0m18:48:34.895566 [debug] [Thread-1 (]: On test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba"} */

  
  
    
    



select customer_id
from "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders"
where customer_id is null



  
  limit 5

[0m18:48:34.895885 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:48:34.938349 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.042 seconds
[0m18:48:34.939914 [debug] [Thread-1 (]: On test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba: Close
[0m18:48:34.941043 [debug] [Thread-1 (]: Finished running node test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba
[0m18:48:34.941590 [debug] [Thread-1 (]: Began running node test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b
[0m18:48:34.942102 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba, now test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b)
[0m18:48:34.942596 [debug] [Thread-1 (]: Began compiling node test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b
[0m18:48:34.947172 [debug] [Thread-1 (]: Writing injected SQL for node "test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b"
[0m18:48:34.948054 [debug] [Thread-1 (]: Began executing node test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b
[0m18:48:34.950803 [debug] [Thread-1 (]: Using postgres connection "test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b"
[0m18:48:34.951151 [debug] [Thread-1 (]: On test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b"} */

  
  
    
    



select order_id
from "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders"
where order_id is null



  
  limit 5

[0m18:48:34.951456 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:48:34.993984 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.042 seconds
[0m18:48:34.995132 [debug] [Thread-1 (]: On test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b: Close
[0m18:48:34.996118 [debug] [Thread-1 (]: Finished running node test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b
[0m18:48:34.996658 [debug] [Thread-1 (]: Began running node test.analytics_project.unique_analytics_orders_order_id.20264248d8
[0m18:48:34.997178 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b, now test.analytics_project.unique_analytics_orders_order_id.20264248d8)
[0m18:48:34.997733 [debug] [Thread-1 (]: Began compiling node test.analytics_project.unique_analytics_orders_order_id.20264248d8
[0m18:48:35.003513 [debug] [Thread-1 (]: Writing injected SQL for node "test.analytics_project.unique_analytics_orders_order_id.20264248d8"
[0m18:48:35.004709 [debug] [Thread-1 (]: Began executing node test.analytics_project.unique_analytics_orders_order_id.20264248d8
[0m18:48:35.007848 [debug] [Thread-1 (]: Using postgres connection "test.analytics_project.unique_analytics_orders_order_id.20264248d8"
[0m18:48:35.008249 [debug] [Thread-1 (]: On test.analytics_project.unique_analytics_orders_order_id.20264248d8: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "test.analytics_project.unique_analytics_orders_order_id.20264248d8"} */

  
  
    
    

select
    order_id as unique_field,
    count(*) as n_records

from "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders"
where order_id is not null
group by order_id
having count(*) > 1



  
  limit 5

[0m18:48:35.008577 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:48:35.049450 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.041 seconds
[0m18:48:35.050582 [debug] [Thread-1 (]: On test.analytics_project.unique_analytics_orders_order_id.20264248d8: Close
[0m18:48:35.051360 [debug] [Thread-1 (]: Finished running node test.analytics_project.unique_analytics_orders_order_id.20264248d8
[0m18:48:35.052532 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:48:35.053446 [debug] [MainThread]: Connection 'list_dbt_sample_analytics_schema' was properly closed.
[0m18:48:35.054366 [debug] [MainThread]: Connection 'test.analytics_project.unique_analytics_orders_order_id.20264248d8' was properly closed.
[0m18:48:35.055585 [debug] [MainThread]: Command end result
[0m18:48:35.077973 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\karak\dbt_cursor\analytics_project\target\manifest.json
[0m18:48:35.080333 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\karak\dbt_cursor\analytics_project\target\semantic_manifest.json
[0m18:48:35.088907 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\karak\dbt_cursor\analytics_project\target\run_results.json
[0m18:48:35.089465 [debug] [MainThread]: Excluded node 'not_null_analytics_orders_customer_id' from results
[0m18:48:35.089887 [debug] [MainThread]: Excluded node 'not_null_analytics_orders_order_id' from results
[0m18:48:35.090224 [debug] [MainThread]: Excluded node 'unique_analytics_orders_order_id' from results
[0m18:48:35.091022 [info ] [MainThread]: Previewing node 'analytics_orders':
| order_id | customer_id | test_project_id | some_metric |
| -------- | ----------- | --------------- | ----------- |
|        1 |           1 |               1 |         100 |
|        2 |           2 |               2 |         200 |
|        3 |           3 |               3 |         150 |

[0m18:48:35.092045 [debug] [MainThread]: Command `dbt show` succeeded at 18:48:35.091922 after 1.53 seconds
[0m18:48:35.092395 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D8D2B62D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D8EDC3070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D8F098AA0>]}
[0m18:48:35.092723 [debug] [MainThread]: Flushing usage events
[0m18:48:36.338013 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:54:11.992595 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B13A3EA7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B1384DD590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B13B0A0F50>]}


============================== 18:54:12.002346 | ce7cb286-81f1-4b3d-8821-52c022199f76 ==============================
[0m18:54:12.002346 [info ] [MainThread]: Running with dbt=1.9.3
[0m18:54:12.003184 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\karak\\.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\karak\\dbt_cursor\\analytics_project\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m18:54:12.206667 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ce7cb286-81f1-4b3d-8821-52c022199f76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B13BB74E90>]}
[0m18:54:12.270882 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ce7cb286-81f1-4b3d-8821-52c022199f76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B13B41FF00>]}
[0m18:54:12.272545 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m18:54:12.474622 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m18:54:12.616119 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:54:12.618156 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:54:12.661647 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ce7cb286-81f1-4b3d-8821-52c022199f76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B13CDD0D50>]}
[0m18:54:12.742846 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\karak\dbt_cursor\analytics_project\target\manifest.json
[0m18:54:12.746063 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\karak\dbt_cursor\analytics_project\target\semantic_manifest.json
[0m18:54:12.790624 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ce7cb286-81f1-4b3d-8821-52c022199f76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B13B55AA80>]}
[0m18:54:12.791122 [info ] [MainThread]: Found 3 models, 3 data tests, 2 sources, 433 macros
[0m18:54:12.791704 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ce7cb286-81f1-4b3d-8821-52c022199f76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B13CE7D630>]}
[0m18:54:12.793489 [info ] [MainThread]: 
[0m18:54:12.794011 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:54:12.794479 [info ] [MainThread]: 
[0m18:54:12.795128 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m18:54:12.799289 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbt_sample'
[0m18:54:12.963333 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample"
[0m18:54:12.963952 [debug] [ThreadPool]: On list_dbt_sample: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample"} */

    select distinct nspname from pg_namespace
  
[0m18:54:12.964710 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:54:13.054829 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.090 seconds
[0m18:54:13.056310 [debug] [ThreadPool]: On list_dbt_sample: Close
[0m18:54:13.058548 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample"
[0m18:54:13.059228 [debug] [ThreadPool]: On list_dbt_sample: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample"} */

    select distinct nspname from pg_namespace
  
[0m18:54:13.059570 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:54:13.099068 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.039 seconds
[0m18:54:13.100415 [debug] [ThreadPool]: On list_dbt_sample: Close
[0m18:54:13.102960 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbt_sample_analytics_schema'
[0m18:54:13.108256 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema"
[0m18:54:13.108622 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: BEGIN
[0m18:54:13.108910 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:54:13.148594 [debug] [ThreadPool]: SQL status: BEGIN in 0.040 seconds
[0m18:54:13.148984 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema"
[0m18:54:13.149264 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample_analytics_schema"} */
select
      'dbt_sample' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_schema'
    union all
    select
      'dbt_sample' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_schema'
    union all
    select
      'dbt_sample' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_schema'
  
[0m18:54:13.156789 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.007 seconds
[0m18:54:13.158085 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: ROLLBACK
[0m18:54:13.158927 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: Close
[0m18:54:13.159825 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dbt_sample_analytics_schema, now list_dbt_sample_analytics_schema_analytics_schema)
[0m18:54:13.162111 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema_analytics_schema"
[0m18:54:13.163099 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: BEGIN
[0m18:54:13.163403 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:54:13.202089 [debug] [ThreadPool]: SQL status: BEGIN in 0.039 seconds
[0m18:54:13.202712 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema_analytics_schema"
[0m18:54:13.203201 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample_analytics_schema_analytics_schema"} */
select
      'dbt_sample' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_schema_analytics_schema'
    union all
    select
      'dbt_sample' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_schema_analytics_schema'
    union all
    select
      'dbt_sample' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_schema_analytics_schema'
  
[0m18:54:13.208672 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.005 seconds
[0m18:54:13.209830 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: ROLLBACK
[0m18:54:13.210424 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: Close
[0m18:54:13.215069 [debug] [MainThread]: Using postgres connection "master"
[0m18:54:13.215407 [debug] [MainThread]: On master: BEGIN
[0m18:54:13.215677 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:54:13.254734 [debug] [MainThread]: SQL status: BEGIN in 0.039 seconds
[0m18:54:13.255168 [debug] [MainThread]: Using postgres connection "master"
[0m18:54:13.255519 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:54:13.263026 [debug] [MainThread]: SQL status: SELECT 12 in 0.007 seconds
[0m18:54:13.264561 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ce7cb286-81f1-4b3d-8821-52c022199f76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B13D204530>]}
[0m18:54:13.264959 [debug] [MainThread]: On master: ROLLBACK
[0m18:54:13.265473 [debug] [MainThread]: Using postgres connection "master"
[0m18:54:13.265773 [debug] [MainThread]: On master: BEGIN
[0m18:54:13.266240 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m18:54:13.266627 [debug] [MainThread]: On master: COMMIT
[0m18:54:13.267109 [debug] [MainThread]: Using postgres connection "master"
[0m18:54:13.267689 [debug] [MainThread]: On master: COMMIT
[0m18:54:13.268378 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:54:13.268744 [debug] [MainThread]: On master: Close
[0m18:54:13.274552 [debug] [Thread-1 (]: Began running node model.analytics_project.analytics_orders
[0m18:54:13.275135 [info ] [Thread-1 (]: 1 of 3 START sql view model analytics_schema_analytics_schema.analytics_orders . [RUN]
[0m18:54:13.275847 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.analytics_project.analytics_orders'
[0m18:54:13.276191 [debug] [Thread-1 (]: Began compiling node model.analytics_project.analytics_orders
[0m18:54:13.283034 [debug] [Thread-1 (]: Writing injected SQL for node "model.analytics_project.analytics_orders"
[0m18:54:13.285369 [debug] [Thread-1 (]: Began executing node model.analytics_project.analytics_orders
[0m18:54:13.322733 [debug] [Thread-1 (]: Writing runtime sql for node "model.analytics_project.analytics_orders"
[0m18:54:13.324294 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m18:54:13.324867 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: BEGIN
[0m18:54:13.325170 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m18:54:13.364368 [debug] [Thread-1 (]: SQL status: BEGIN in 0.039 seconds
[0m18:54:13.364813 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m18:54:13.365143 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.analytics_orders"} */

  create view "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders__dbt_tmp"
    
    
  as (
    

WITH ecommerce_orders AS (
    -- Use source() to reference ecommerce models
    SELECT * FROM "dbt_sample"."ecommerce_ecommerce_schema"."stg_orders"
),
test_project_data AS (
    -- Use source() to reference test project models
    SELECT * FROM "dbt_sample"."my_test_my_test"."my_first_dbt_model"
)

SELECT
    eo.order_id,
    eo.customer_id,
    td.id as test_project_id,
    td.amount as some_metric
FROM ecommerce_orders eo
LEFT JOIN test_project_data td
ON eo.customer_id = td.order_id
  );
[0m18:54:13.371906 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.006 seconds
[0m18:54:13.377918 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m18:54:13.378331 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.analytics_orders"} */
alter table "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders" rename to "analytics_orders__dbt_backup"
[0m18:54:13.379133 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m18:54:13.381332 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m18:54:13.381669 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.analytics_orders"} */
alter table "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders__dbt_tmp" rename to "analytics_orders"
[0m18:54:13.382260 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m18:54:13.398297 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: COMMIT
[0m18:54:13.398760 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m18:54:13.399103 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: COMMIT
[0m18:54:13.402647 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m18:54:13.410017 [debug] [Thread-1 (]: Applying DROP to: "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders__dbt_backup"
[0m18:54:13.414450 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m18:54:13.414814 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.analytics_orders"} */
drop view if exists "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders__dbt_backup" cascade
[0m18:54:13.417939 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.003 seconds
[0m18:54:13.421010 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: Close
[0m18:54:13.423945 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ce7cb286-81f1-4b3d-8821-52c022199f76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B13CF71CD0>]}
[0m18:54:13.424775 [info ] [Thread-1 (]: 1 of 3 OK created sql view model analytics_schema_analytics_schema.analytics_orders  [[32mCREATE VIEW[0m in 0.15s]
[0m18:54:13.425726 [debug] [Thread-1 (]: Finished running node model.analytics_project.analytics_orders
[0m18:54:13.426142 [debug] [Thread-1 (]: Began running node model.analytics_project.my_first_dbt_model
[0m18:54:13.426653 [info ] [Thread-1 (]: 2 of 3 START sql table model analytics_schema.my_first_dbt_model ............... [RUN]
[0m18:54:13.427185 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.analytics_project.analytics_orders, now model.analytics_project.my_first_dbt_model)
[0m18:54:13.427533 [debug] [Thread-1 (]: Began compiling node model.analytics_project.my_first_dbt_model
[0m18:54:13.429617 [debug] [Thread-1 (]: Writing injected SQL for node "model.analytics_project.my_first_dbt_model"
[0m18:54:13.430484 [debug] [Thread-1 (]: Began executing node model.analytics_project.my_first_dbt_model
[0m18:54:13.455953 [debug] [Thread-1 (]: Writing runtime sql for node "model.analytics_project.my_first_dbt_model"
[0m18:54:13.457865 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_first_dbt_model"
[0m18:54:13.458568 [debug] [Thread-1 (]: On model.analytics_project.my_first_dbt_model: BEGIN
[0m18:54:13.459104 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:54:13.505503 [debug] [Thread-1 (]: SQL status: BEGIN in 0.046 seconds
[0m18:54:13.505952 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_first_dbt_model"
[0m18:54:13.506282 [debug] [Thread-1 (]: On model.analytics_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.my_first_dbt_model"} */

  
    

  create  table "dbt_sample"."analytics_schema"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m18:54:13.511026 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.004 seconds
[0m18:54:13.514073 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_first_dbt_model"
[0m18:54:13.514436 [debug] [Thread-1 (]: On model.analytics_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.my_first_dbt_model"} */
alter table "dbt_sample"."analytics_schema"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m18:54:13.515174 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m18:54:13.518942 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_first_dbt_model"
[0m18:54:13.519563 [debug] [Thread-1 (]: On model.analytics_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.my_first_dbt_model"} */
alter table "dbt_sample"."analytics_schema"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m18:54:13.520794 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:54:13.526533 [debug] [Thread-1 (]: On model.analytics_project.my_first_dbt_model: COMMIT
[0m18:54:13.526905 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_first_dbt_model"
[0m18:54:13.527214 [debug] [Thread-1 (]: On model.analytics_project.my_first_dbt_model: COMMIT
[0m18:54:13.529349 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m18:54:13.531161 [debug] [Thread-1 (]: Applying DROP to: "dbt_sample"."analytics_schema"."my_first_dbt_model__dbt_backup"
[0m18:54:13.534140 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_first_dbt_model"
[0m18:54:13.535118 [debug] [Thread-1 (]: On model.analytics_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.my_first_dbt_model"} */
drop table if exists "dbt_sample"."analytics_schema"."my_first_dbt_model__dbt_backup" cascade
[0m18:54:13.539238 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m18:54:13.540592 [debug] [Thread-1 (]: On model.analytics_project.my_first_dbt_model: Close
[0m18:54:13.541249 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ce7cb286-81f1-4b3d-8821-52c022199f76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B13D224E10>]}
[0m18:54:13.542001 [info ] [Thread-1 (]: 2 of 3 OK created sql table model analytics_schema.my_first_dbt_model .......... [[32mSELECT 2[0m in 0.11s]
[0m18:54:13.542882 [debug] [Thread-1 (]: Finished running node model.analytics_project.my_first_dbt_model
[0m18:54:13.543657 [debug] [Thread-1 (]: Began running node model.analytics_project.my_second_dbt_model
[0m18:54:13.544278 [info ] [Thread-1 (]: 3 of 3 START sql view model analytics_schema.my_second_dbt_model ............... [RUN]
[0m18:54:13.544981 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.analytics_project.my_first_dbt_model, now model.analytics_project.my_second_dbt_model)
[0m18:54:13.545494 [debug] [Thread-1 (]: Began compiling node model.analytics_project.my_second_dbt_model
[0m18:54:13.547996 [debug] [Thread-1 (]: Writing injected SQL for node "model.analytics_project.my_second_dbt_model"
[0m18:54:13.548888 [debug] [Thread-1 (]: Began executing node model.analytics_project.my_second_dbt_model
[0m18:54:13.553833 [debug] [Thread-1 (]: Writing runtime sql for node "model.analytics_project.my_second_dbt_model"
[0m18:54:13.555037 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_second_dbt_model"
[0m18:54:13.555492 [debug] [Thread-1 (]: On model.analytics_project.my_second_dbt_model: BEGIN
[0m18:54:13.555840 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:54:13.598515 [debug] [Thread-1 (]: SQL status: BEGIN in 0.043 seconds
[0m18:54:13.598943 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_second_dbt_model"
[0m18:54:13.599279 [debug] [Thread-1 (]: On model.analytics_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.my_second_dbt_model"} */

  create view "dbt_sample"."analytics_schema"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "dbt_sample"."analytics_schema"."my_first_dbt_model"
where id = 1
  );
[0m18:54:13.606861 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.007 seconds
[0m18:54:13.609420 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_second_dbt_model"
[0m18:54:13.609806 [debug] [Thread-1 (]: On model.analytics_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.my_second_dbt_model"} */
alter table "dbt_sample"."analytics_schema"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m18:54:13.610566 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m18:54:13.611824 [debug] [Thread-1 (]: On model.analytics_project.my_second_dbt_model: COMMIT
[0m18:54:13.612205 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_second_dbt_model"
[0m18:54:13.612745 [debug] [Thread-1 (]: On model.analytics_project.my_second_dbt_model: COMMIT
[0m18:54:13.614840 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m18:54:13.616649 [debug] [Thread-1 (]: Applying DROP to: "dbt_sample"."analytics_schema"."my_second_dbt_model__dbt_backup"
[0m18:54:13.618185 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_second_dbt_model"
[0m18:54:13.618731 [debug] [Thread-1 (]: On model.analytics_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.my_second_dbt_model"} */
drop view if exists "dbt_sample"."analytics_schema"."my_second_dbt_model__dbt_backup" cascade
[0m18:54:13.619662 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.000 seconds
[0m18:54:13.621563 [debug] [Thread-1 (]: On model.analytics_project.my_second_dbt_model: Close
[0m18:54:13.622378 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ce7cb286-81f1-4b3d-8821-52c022199f76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B13D2F9C70>]}
[0m18:54:13.623270 [info ] [Thread-1 (]: 3 of 3 OK created sql view model analytics_schema.my_second_dbt_model .......... [[32mCREATE VIEW[0m in 0.08s]
[0m18:54:13.624221 [debug] [Thread-1 (]: Finished running node model.analytics_project.my_second_dbt_model
[0m18:54:13.625984 [debug] [MainThread]: Using postgres connection "master"
[0m18:54:13.626474 [debug] [MainThread]: On master: BEGIN
[0m18:54:13.626859 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:54:13.667296 [debug] [MainThread]: SQL status: BEGIN in 0.040 seconds
[0m18:54:13.668213 [debug] [MainThread]: On master: COMMIT
[0m18:54:13.668867 [debug] [MainThread]: Using postgres connection "master"
[0m18:54:13.669297 [debug] [MainThread]: On master: COMMIT
[0m18:54:13.669998 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:54:13.670414 [debug] [MainThread]: On master: Close
[0m18:54:13.670976 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:54:13.671349 [debug] [MainThread]: Connection 'list_dbt_sample' was properly closed.
[0m18:54:13.671670 [debug] [MainThread]: Connection 'list_dbt_sample_analytics_schema_analytics_schema' was properly closed.
[0m18:54:13.671970 [debug] [MainThread]: Connection 'model.analytics_project.my_second_dbt_model' was properly closed.
[0m18:54:13.672319 [info ] [MainThread]: 
[0m18:54:13.672891 [info ] [MainThread]: Finished running 1 table model, 2 view models in 0 hours 0 minutes and 0.88 seconds (0.88s).
[0m18:54:13.674148 [debug] [MainThread]: Command end result
[0m18:54:13.693140 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\karak\dbt_cursor\analytics_project\target\manifest.json
[0m18:54:13.695180 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\karak\dbt_cursor\analytics_project\target\semantic_manifest.json
[0m18:54:13.702057 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\karak\dbt_cursor\analytics_project\target\run_results.json
[0m18:54:13.702596 [info ] [MainThread]: 
[0m18:54:13.703310 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:54:13.704024 [info ] [MainThread]: 
[0m18:54:13.704785 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m18:54:13.705692 [debug] [MainThread]: Command `dbt run` succeeded at 18:54:13.705564 after 2.02 seconds
[0m18:54:13.706035 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B13BBC58D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B13AA389D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B13B493A80>]}
[0m18:54:13.706363 [debug] [MainThread]: Flushing usage events
[0m18:54:14.747062 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:54:57.790749 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D79716A7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D795265590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D797E10F50>]}


============================== 18:54:57.799078 | cbf6d837-ab9d-4bdf-b239-0a2692b1b016 ==============================
[0m18:54:57.799078 [info ] [MainThread]: Running with dbt=1.9.3
[0m18:54:57.801641 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\karak\\.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\karak\\dbt_cursor\\analytics_project\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m18:54:57.992145 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cbf6d837-ab9d-4bdf-b239-0a2692b1b016', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D7984B4E90>]}
[0m18:54:58.051850 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cbf6d837-ab9d-4bdf-b239-0a2692b1b016', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D79818FF00>]}
[0m18:54:58.053433 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m18:54:58.231752 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m18:54:58.364978 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:54:58.365364 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:54:58.407620 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cbf6d837-ab9d-4bdf-b239-0a2692b1b016', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D799ABCD50>]}
[0m18:54:58.488304 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\karak\dbt_cursor\analytics_project\target\manifest.json
[0m18:54:58.491458 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\karak\dbt_cursor\analytics_project\target\semantic_manifest.json
[0m18:54:58.526188 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cbf6d837-ab9d-4bdf-b239-0a2692b1b016', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D7982CAA80>]}
[0m18:54:58.526681 [info ] [MainThread]: Found 3 models, 3 data tests, 2 sources, 433 macros
[0m18:54:58.527294 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cbf6d837-ab9d-4bdf-b239-0a2692b1b016', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D799B71630>]}
[0m18:54:58.529230 [info ] [MainThread]: 
[0m18:54:58.529952 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:54:58.530497 [info ] [MainThread]: 
[0m18:54:58.531258 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m18:54:58.537131 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbt_sample'
[0m18:54:58.610703 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample"
[0m18:54:58.611114 [debug] [ThreadPool]: On list_dbt_sample: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample"} */

    select distinct nspname from pg_namespace
  
[0m18:54:58.611390 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:54:58.668468 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.057 seconds
[0m18:54:58.669807 [debug] [ThreadPool]: On list_dbt_sample: Close
[0m18:54:58.671697 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample"
[0m18:54:58.672046 [debug] [ThreadPool]: On list_dbt_sample: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample"} */

    select distinct nspname from pg_namespace
  
[0m18:54:58.672298 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:54:58.713153 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.041 seconds
[0m18:54:58.714313 [debug] [ThreadPool]: On list_dbt_sample: Close
[0m18:54:58.717253 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbt_sample_analytics_schema_analytics_schema'
[0m18:54:58.723864 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema_analytics_schema"
[0m18:54:58.724260 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: BEGIN
[0m18:54:58.724519 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:54:58.765022 [debug] [ThreadPool]: SQL status: BEGIN in 0.040 seconds
[0m18:54:58.765425 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema_analytics_schema"
[0m18:54:58.765711 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample_analytics_schema_analytics_schema"} */
select
      'dbt_sample' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_schema_analytics_schema'
    union all
    select
      'dbt_sample' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_schema_analytics_schema'
    union all
    select
      'dbt_sample' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_schema_analytics_schema'
  
[0m18:54:58.772975 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.007 seconds
[0m18:54:58.774170 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: ROLLBACK
[0m18:54:58.774707 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: Close
[0m18:54:58.775313 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dbt_sample_analytics_schema_analytics_schema, now list_dbt_sample_analytics_schema)
[0m18:54:58.777647 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema"
[0m18:54:58.778049 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: BEGIN
[0m18:54:58.778309 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:54:58.818127 [debug] [ThreadPool]: SQL status: BEGIN in 0.040 seconds
[0m18:54:58.818542 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema"
[0m18:54:58.818828 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample_analytics_schema"} */
select
      'dbt_sample' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_schema'
    union all
    select
      'dbt_sample' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_schema'
    union all
    select
      'dbt_sample' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_schema'
  
[0m18:54:58.825967 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.007 seconds
[0m18:54:58.827235 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: ROLLBACK
[0m18:54:58.827830 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: Close
[0m18:54:58.832443 [debug] [MainThread]: Using postgres connection "master"
[0m18:54:58.833636 [debug] [MainThread]: On master: BEGIN
[0m18:54:58.834178 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:54:58.872775 [debug] [MainThread]: SQL status: BEGIN in 0.039 seconds
[0m18:54:58.873170 [debug] [MainThread]: Using postgres connection "master"
[0m18:54:58.873515 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:54:58.880558 [debug] [MainThread]: SQL status: SELECT 10 in 0.007 seconds
[0m18:54:58.881999 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cbf6d837-ab9d-4bdf-b239-0a2692b1b016', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D799F342C0>]}
[0m18:54:58.882423 [debug] [MainThread]: On master: ROLLBACK
[0m18:54:58.883680 [debug] [MainThread]: Using postgres connection "master"
[0m18:54:58.884233 [debug] [MainThread]: On master: BEGIN
[0m18:54:58.884782 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m18:54:58.885087 [debug] [MainThread]: On master: COMMIT
[0m18:54:58.885348 [debug] [MainThread]: Using postgres connection "master"
[0m18:54:58.885581 [debug] [MainThread]: On master: COMMIT
[0m18:54:58.886008 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:54:58.886481 [debug] [MainThread]: On master: Close
[0m18:54:58.892087 [debug] [Thread-1 (]: Began running node model.analytics_project.analytics_orders
[0m18:54:58.892792 [info ] [Thread-1 (]: 1 of 3 START sql view model analytics_schema_analytics_schema.analytics_orders . [RUN]
[0m18:54:58.893478 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.analytics_project.analytics_orders'
[0m18:54:58.893815 [debug] [Thread-1 (]: Began compiling node model.analytics_project.analytics_orders
[0m18:54:58.901839 [debug] [Thread-1 (]: Writing injected SQL for node "model.analytics_project.analytics_orders"
[0m18:54:58.903765 [debug] [Thread-1 (]: Began executing node model.analytics_project.analytics_orders
[0m18:54:58.938977 [debug] [Thread-1 (]: Writing runtime sql for node "model.analytics_project.analytics_orders"
[0m18:54:58.940940 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m18:54:58.941347 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: BEGIN
[0m18:54:58.941635 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m18:54:58.981071 [debug] [Thread-1 (]: SQL status: BEGIN in 0.039 seconds
[0m18:54:58.981531 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m18:54:58.981861 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.analytics_orders"} */

  create view "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders__dbt_tmp"
    
    
  as (
    

WITH ecommerce_orders AS (
    -- Use source() to reference ecommerce models
    SELECT * FROM "dbt_sample"."ecommerce_ecommerce_schema"."stg_orders"
),
test_project_data AS (
    -- Use source() to reference test project models
    SELECT * FROM "dbt_sample"."my_test_my_test"."my_first_dbt_model"
)

SELECT
    eo.order_id,
    eo.customer_id,
    td.id as test_project_id,
    td.amount as some_metric
FROM ecommerce_orders eo
LEFT JOIN test_project_data td
ON eo.customer_id = td.order_id
  );
[0m18:54:58.988363 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.006 seconds
[0m18:54:58.994291 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m18:54:58.994684 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.analytics_orders"} */
alter table "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders__dbt_tmp" rename to "analytics_orders"
[0m18:54:58.995414 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m18:54:59.009515 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: COMMIT
[0m18:54:59.009978 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m18:54:59.010321 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: COMMIT
[0m18:54:59.021156 [debug] [Thread-1 (]: SQL status: COMMIT in 0.010 seconds
[0m18:54:59.026832 [debug] [Thread-1 (]: Applying DROP to: "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders__dbt_backup"
[0m18:54:59.031217 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m18:54:59.031565 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.analytics_orders"} */
drop view if exists "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders__dbt_backup" cascade
[0m18:54:59.032192 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.000 seconds
[0m18:54:59.035668 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: Close
[0m18:54:59.038389 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cbf6d837-ab9d-4bdf-b239-0a2692b1b016', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D799C6D790>]}
[0m18:54:59.039396 [info ] [Thread-1 (]: 1 of 3 OK created sql view model analytics_schema_analytics_schema.analytics_orders  [[32mCREATE VIEW[0m in 0.14s]
[0m18:54:59.040684 [debug] [Thread-1 (]: Finished running node model.analytics_project.analytics_orders
[0m18:54:59.041174 [debug] [Thread-1 (]: Began running node model.analytics_project.my_first_dbt_model
[0m18:54:59.041855 [info ] [Thread-1 (]: 2 of 3 START sql table model analytics_schema.my_first_dbt_model ............... [RUN]
[0m18:54:59.042565 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.analytics_project.analytics_orders, now model.analytics_project.my_first_dbt_model)
[0m18:54:59.042903 [debug] [Thread-1 (]: Began compiling node model.analytics_project.my_first_dbt_model
[0m18:54:59.045373 [debug] [Thread-1 (]: Writing injected SQL for node "model.analytics_project.my_first_dbt_model"
[0m18:54:59.046229 [debug] [Thread-1 (]: Began executing node model.analytics_project.my_first_dbt_model
[0m18:54:59.072886 [debug] [Thread-1 (]: Writing runtime sql for node "model.analytics_project.my_first_dbt_model"
[0m18:54:59.074742 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_first_dbt_model"
[0m18:54:59.075193 [debug] [Thread-1 (]: On model.analytics_project.my_first_dbt_model: BEGIN
[0m18:54:59.075582 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:54:59.132071 [debug] [Thread-1 (]: SQL status: BEGIN in 0.056 seconds
[0m18:54:59.132510 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_first_dbt_model"
[0m18:54:59.133284 [debug] [Thread-1 (]: On model.analytics_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.my_first_dbt_model"} */

  
    

  create  table "dbt_sample"."analytics_schema"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m18:54:59.139053 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.005 seconds
[0m18:54:59.144916 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_first_dbt_model"
[0m18:54:59.145349 [debug] [Thread-1 (]: On model.analytics_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.my_first_dbt_model"} */
alter table "dbt_sample"."analytics_schema"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m18:54:59.146314 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:54:59.148753 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_first_dbt_model"
[0m18:54:59.149102 [debug] [Thread-1 (]: On model.analytics_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.my_first_dbt_model"} */
alter table "dbt_sample"."analytics_schema"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m18:54:59.150867 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:54:59.158895 [debug] [Thread-1 (]: On model.analytics_project.my_first_dbt_model: COMMIT
[0m18:54:59.159319 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_first_dbt_model"
[0m18:54:59.159663 [debug] [Thread-1 (]: On model.analytics_project.my_first_dbt_model: COMMIT
[0m18:54:59.169841 [debug] [Thread-1 (]: SQL status: COMMIT in 0.010 seconds
[0m18:54:59.172944 [debug] [Thread-1 (]: Applying DROP to: "dbt_sample"."analytics_schema"."my_first_dbt_model__dbt_backup"
[0m18:54:59.176446 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_first_dbt_model"
[0m18:54:59.176842 [debug] [Thread-1 (]: On model.analytics_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.my_first_dbt_model"} */
drop table if exists "dbt_sample"."analytics_schema"."my_first_dbt_model__dbt_backup" cascade
[0m18:54:59.179894 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m18:54:59.181143 [debug] [Thread-1 (]: On model.analytics_project.my_first_dbt_model: Close
[0m18:54:59.181775 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cbf6d837-ab9d-4bdf-b239-0a2692b1b016', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D799FB4EC0>]}
[0m18:54:59.182475 [info ] [Thread-1 (]: 2 of 3 OK created sql table model analytics_schema.my_first_dbt_model .......... [[32mSELECT 2[0m in 0.14s]
[0m18:54:59.184162 [debug] [Thread-1 (]: Finished running node model.analytics_project.my_first_dbt_model
[0m18:54:59.185003 [debug] [Thread-1 (]: Began running node model.analytics_project.my_second_dbt_model
[0m18:54:59.185615 [info ] [Thread-1 (]: 3 of 3 START sql view model analytics_schema.my_second_dbt_model ............... [RUN]
[0m18:54:59.186459 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.analytics_project.my_first_dbt_model, now model.analytics_project.my_second_dbt_model)
[0m18:54:59.186835 [debug] [Thread-1 (]: Began compiling node model.analytics_project.my_second_dbt_model
[0m18:54:59.189512 [debug] [Thread-1 (]: Writing injected SQL for node "model.analytics_project.my_second_dbt_model"
[0m18:54:59.190449 [debug] [Thread-1 (]: Began executing node model.analytics_project.my_second_dbt_model
[0m18:54:59.193180 [debug] [Thread-1 (]: Writing runtime sql for node "model.analytics_project.my_second_dbt_model"
[0m18:54:59.194058 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_second_dbt_model"
[0m18:54:59.194400 [debug] [Thread-1 (]: On model.analytics_project.my_second_dbt_model: BEGIN
[0m18:54:59.194700 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:54:59.238159 [debug] [Thread-1 (]: SQL status: BEGIN in 0.043 seconds
[0m18:54:59.238679 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_second_dbt_model"
[0m18:54:59.239379 [debug] [Thread-1 (]: On model.analytics_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.my_second_dbt_model"} */

  create view "dbt_sample"."analytics_schema"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "dbt_sample"."analytics_schema"."my_first_dbt_model"
where id = 1
  );
[0m18:54:59.245468 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.005 seconds
[0m18:54:59.249014 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_second_dbt_model"
[0m18:54:59.249662 [debug] [Thread-1 (]: On model.analytics_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.my_second_dbt_model"} */
alter table "dbt_sample"."analytics_schema"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m18:54:59.252696 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:54:59.254881 [debug] [Thread-1 (]: On model.analytics_project.my_second_dbt_model: COMMIT
[0m18:54:59.255520 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_second_dbt_model"
[0m18:54:59.256019 [debug] [Thread-1 (]: On model.analytics_project.my_second_dbt_model: COMMIT
[0m18:54:59.257977 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m18:54:59.260798 [debug] [Thread-1 (]: Applying DROP to: "dbt_sample"."analytics_schema"."my_second_dbt_model__dbt_backup"
[0m18:54:59.261831 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.my_second_dbt_model"
[0m18:54:59.262328 [debug] [Thread-1 (]: On model.analytics_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.my_second_dbt_model"} */
drop view if exists "dbt_sample"."analytics_schema"."my_second_dbt_model__dbt_backup" cascade
[0m18:54:59.263151 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.000 seconds
[0m18:54:59.264783 [debug] [Thread-1 (]: On model.analytics_project.my_second_dbt_model: Close
[0m18:54:59.265496 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cbf6d837-ab9d-4bdf-b239-0a2692b1b016', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D79A02CB90>]}
[0m18:54:59.266344 [info ] [Thread-1 (]: 3 of 3 OK created sql view model analytics_schema.my_second_dbt_model .......... [[32mCREATE VIEW[0m in 0.08s]
[0m18:54:59.268361 [debug] [Thread-1 (]: Finished running node model.analytics_project.my_second_dbt_model
[0m18:54:59.270418 [debug] [MainThread]: Using postgres connection "master"
[0m18:54:59.270915 [debug] [MainThread]: On master: BEGIN
[0m18:54:59.271333 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:54:59.314159 [debug] [MainThread]: SQL status: BEGIN in 0.043 seconds
[0m18:54:59.314558 [debug] [MainThread]: On master: COMMIT
[0m18:54:59.314830 [debug] [MainThread]: Using postgres connection "master"
[0m18:54:59.315059 [debug] [MainThread]: On master: COMMIT
[0m18:54:59.315391 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:54:59.315679 [debug] [MainThread]: On master: Close
[0m18:54:59.316238 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:54:59.316720 [debug] [MainThread]: Connection 'list_dbt_sample' was properly closed.
[0m18:54:59.318118 [debug] [MainThread]: Connection 'list_dbt_sample_analytics_schema' was properly closed.
[0m18:54:59.318564 [debug] [MainThread]: Connection 'model.analytics_project.my_second_dbt_model' was properly closed.
[0m18:54:59.319098 [info ] [MainThread]: 
[0m18:54:59.319668 [info ] [MainThread]: Finished running 1 table model, 2 view models in 0 hours 0 minutes and 0.79 seconds (0.79s).
[0m18:54:59.321355 [debug] [MainThread]: Command end result
[0m18:54:59.343658 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\karak\dbt_cursor\analytics_project\target\manifest.json
[0m18:54:59.346155 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\karak\dbt_cursor\analytics_project\target\semantic_manifest.json
[0m18:54:59.355273 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\karak\dbt_cursor\analytics_project\target\run_results.json
[0m18:54:59.355844 [info ] [MainThread]: 
[0m18:54:59.356522 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:54:59.357067 [info ] [MainThread]: 
[0m18:54:59.357782 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m18:54:59.358996 [debug] [MainThread]: Command `dbt run` succeeded at 18:54:59.358804 after 1.76 seconds
[0m18:54:59.359505 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D799B0D150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D798AD34D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D798203A80>]}
[0m18:54:59.359933 [debug] [MainThread]: Flushing usage events
[0m18:55:00.624340 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:55:11.153422 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B45AA4E7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B458B45590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B45B6F0F50>]}


============================== 18:55:11.161733 | b5effd91-f28a-45ff-b349-50ba656f3610 ==============================
[0m18:55:11.161733 [info ] [MainThread]: Running with dbt=1.9.3
[0m18:55:11.162840 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\karak\\.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\karak\\dbt_cursor\\analytics_project\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt show --select analytics_orders', 'send_anonymous_usage_stats': 'True'}
[0m18:55:11.356472 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b5effd91-f28a-45ff-b349-50ba656f3610', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B45C170E90>]}
[0m18:55:11.419207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b5effd91-f28a-45ff-b349-50ba656f3610', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B45BA6BF00>]}
[0m18:55:11.458636 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m18:55:11.650619 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m18:55:11.790004 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:55:11.790432 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:55:11.839169 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b5effd91-f28a-45ff-b349-50ba656f3610', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B45D468E50>]}
[0m18:55:11.914714 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\karak\dbt_cursor\analytics_project\target\manifest.json
[0m18:55:11.919828 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\karak\dbt_cursor\analytics_project\target\semantic_manifest.json
[0m18:55:11.922783 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b5effd91-f28a-45ff-b349-50ba656f3610', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B45BBAEE40>]}
[0m18:55:11.923237 [info ] [MainThread]: Found 3 models, 3 data tests, 2 sources, 433 macros
[0m18:55:11.923779 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b5effd91-f28a-45ff-b349-50ba656f3610', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B45C115C50>]}
[0m18:55:11.925499 [info ] [MainThread]: 
[0m18:55:11.926233 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:55:11.926902 [info ] [MainThread]: 
[0m18:55:11.927818 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m18:55:11.934442 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbt_sample_analytics_schema'
[0m18:55:12.013012 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema"
[0m18:55:12.013434 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: BEGIN
[0m18:55:12.013706 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:55:12.065025 [debug] [ThreadPool]: SQL status: BEGIN in 0.051 seconds
[0m18:55:12.065439 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema"
[0m18:55:12.066004 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample_analytics_schema"} */
select
      'dbt_sample' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_schema'
    union all
    select
      'dbt_sample' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_schema'
    union all
    select
      'dbt_sample' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_schema'
  
[0m18:55:12.073327 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.007 seconds
[0m18:55:12.074689 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: ROLLBACK
[0m18:55:12.075248 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema: Close
[0m18:55:12.075866 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dbt_sample_analytics_schema, now list_dbt_sample_analytics_schema_analytics_schema)
[0m18:55:12.077839 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema_analytics_schema"
[0m18:55:12.078597 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: BEGIN
[0m18:55:12.078874 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:55:12.122065 [debug] [ThreadPool]: SQL status: BEGIN in 0.043 seconds
[0m18:55:12.122471 [debug] [ThreadPool]: Using postgres connection "list_dbt_sample_analytics_schema_analytics_schema"
[0m18:55:12.122766 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "list_dbt_sample_analytics_schema_analytics_schema"} */
select
      'dbt_sample' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_schema_analytics_schema'
    union all
    select
      'dbt_sample' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_schema_analytics_schema'
    union all
    select
      'dbt_sample' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_schema_analytics_schema'
  
[0m18:55:12.127760 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.005 seconds
[0m18:55:12.128904 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: ROLLBACK
[0m18:55:12.129372 [debug] [ThreadPool]: On list_dbt_sample_analytics_schema_analytics_schema: Close
[0m18:55:12.135425 [debug] [MainThread]: Using postgres connection "master"
[0m18:55:12.135823 [debug] [MainThread]: On master: BEGIN
[0m18:55:12.136106 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:55:12.177255 [debug] [MainThread]: SQL status: BEGIN in 0.041 seconds
[0m18:55:12.177662 [debug] [MainThread]: Using postgres connection "master"
[0m18:55:12.178012 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:55:12.185668 [debug] [MainThread]: SQL status: SELECT 12 in 0.007 seconds
[0m18:55:12.187327 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b5effd91-f28a-45ff-b349-50ba656f3610', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B45D5A8390>]}
[0m18:55:12.187879 [debug] [MainThread]: On master: ROLLBACK
[0m18:55:12.188389 [debug] [MainThread]: On master: Close
[0m18:55:12.193113 [debug] [Thread-1 (]: Began running node model.analytics_project.analytics_orders
[0m18:55:12.193666 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.analytics_project.analytics_orders'
[0m18:55:12.194006 [debug] [Thread-1 (]: Began compiling node model.analytics_project.analytics_orders
[0m18:55:12.202488 [debug] [Thread-1 (]: Writing injected SQL for node "model.analytics_project.analytics_orders"
[0m18:55:12.203719 [debug] [Thread-1 (]: Began executing node model.analytics_project.analytics_orders
[0m18:55:12.209883 [debug] [Thread-1 (]: Using postgres connection "model.analytics_project.analytics_orders"
[0m18:55:12.210278 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "model.analytics_project.analytics_orders"} */

  
  

WITH ecommerce_orders AS (
    -- Use source() to reference ecommerce models
    SELECT * FROM "dbt_sample"."ecommerce_ecommerce_schema"."stg_orders"
),
test_project_data AS (
    -- Use source() to reference test project models
    SELECT * FROM "dbt_sample"."my_test_my_test"."my_first_dbt_model"
)

SELECT
    eo.order_id,
    eo.customer_id,
    td.id as test_project_id,
    td.amount as some_metric
FROM ecommerce_orders eo
LEFT JOIN test_project_data td
ON eo.customer_id = td.order_id
  
  limit 5

[0m18:55:12.210613 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m18:55:12.252263 [debug] [Thread-1 (]: SQL status: SELECT 3 in 0.042 seconds
[0m18:55:12.254795 [debug] [Thread-1 (]: On model.analytics_project.analytics_orders: Close
[0m18:55:12.255696 [debug] [Thread-1 (]: Finished running node model.analytics_project.analytics_orders
[0m18:55:12.256681 [debug] [Thread-1 (]: Began running node test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba
[0m18:55:12.257274 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.analytics_project.analytics_orders, now test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba)
[0m18:55:12.257760 [debug] [Thread-1 (]: Began compiling node test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba
[0m18:55:12.270440 [debug] [Thread-1 (]: Writing injected SQL for node "test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba"
[0m18:55:12.271602 [debug] [Thread-1 (]: Began executing node test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba
[0m18:55:12.274203 [debug] [Thread-1 (]: Using postgres connection "test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba"
[0m18:55:12.274628 [debug] [Thread-1 (]: On test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba"} */

  
  
    
    



select customer_id
from "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders"
where customer_id is null



  
  limit 5

[0m18:55:12.274945 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:55:12.315724 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.041 seconds
[0m18:55:12.317425 [debug] [Thread-1 (]: On test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba: Close
[0m18:55:12.318394 [debug] [Thread-1 (]: Finished running node test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba
[0m18:55:12.318933 [debug] [Thread-1 (]: Began running node test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b
[0m18:55:12.319928 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.analytics_project.not_null_analytics_orders_customer_id.44fac949ba, now test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b)
[0m18:55:12.320627 [debug] [Thread-1 (]: Began compiling node test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b
[0m18:55:12.324744 [debug] [Thread-1 (]: Writing injected SQL for node "test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b"
[0m18:55:12.325732 [debug] [Thread-1 (]: Began executing node test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b
[0m18:55:12.328478 [debug] [Thread-1 (]: Using postgres connection "test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b"
[0m18:55:12.328838 [debug] [Thread-1 (]: On test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b"} */

  
  
    
    



select order_id
from "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders"
where order_id is null



  
  limit 5

[0m18:55:12.329171 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:55:12.371464 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.042 seconds
[0m18:55:12.372664 [debug] [Thread-1 (]: On test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b: Close
[0m18:55:12.373570 [debug] [Thread-1 (]: Finished running node test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b
[0m18:55:12.374116 [debug] [Thread-1 (]: Began running node test.analytics_project.unique_analytics_orders_order_id.20264248d8
[0m18:55:12.374604 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.analytics_project.not_null_analytics_orders_order_id.16cbd1632b, now test.analytics_project.unique_analytics_orders_order_id.20264248d8)
[0m18:55:12.375144 [debug] [Thread-1 (]: Began compiling node test.analytics_project.unique_analytics_orders_order_id.20264248d8
[0m18:55:12.380694 [debug] [Thread-1 (]: Writing injected SQL for node "test.analytics_project.unique_analytics_orders_order_id.20264248d8"
[0m18:55:12.381630 [debug] [Thread-1 (]: Began executing node test.analytics_project.unique_analytics_orders_order_id.20264248d8
[0m18:55:12.386715 [debug] [Thread-1 (]: Using postgres connection "test.analytics_project.unique_analytics_orders_order_id.20264248d8"
[0m18:55:12.387302 [debug] [Thread-1 (]: On test.analytics_project.unique_analytics_orders_order_id.20264248d8: /* {"app": "dbt", "dbt_version": "1.9.3", "profile_name": "analytics_project", "target_name": "dev", "node_id": "test.analytics_project.unique_analytics_orders_order_id.20264248d8"} */

  
  
    
    

select
    order_id as unique_field,
    count(*) as n_records

from "dbt_sample"."analytics_schema_analytics_schema"."analytics_orders"
where order_id is not null
group by order_id
having count(*) > 1



  
  limit 5

[0m18:55:12.387689 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:55:12.430683 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.043 seconds
[0m18:55:12.431861 [debug] [Thread-1 (]: On test.analytics_project.unique_analytics_orders_order_id.20264248d8: Close
[0m18:55:12.432878 [debug] [Thread-1 (]: Finished running node test.analytics_project.unique_analytics_orders_order_id.20264248d8
[0m18:55:12.435041 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:55:12.435378 [debug] [MainThread]: Connection 'list_dbt_sample_analytics_schema_analytics_schema' was properly closed.
[0m18:55:12.435619 [debug] [MainThread]: Connection 'test.analytics_project.unique_analytics_orders_order_id.20264248d8' was properly closed.
[0m18:55:12.436507 [debug] [MainThread]: Command end result
[0m18:55:12.456974 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\karak\dbt_cursor\analytics_project\target\manifest.json
[0m18:55:12.459021 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\karak\dbt_cursor\analytics_project\target\semantic_manifest.json
[0m18:55:12.465363 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\karak\dbt_cursor\analytics_project\target\run_results.json
[0m18:55:12.465747 [debug] [MainThread]: Excluded node 'not_null_analytics_orders_customer_id' from results
[0m18:55:12.467004 [debug] [MainThread]: Excluded node 'not_null_analytics_orders_order_id' from results
[0m18:55:12.467565 [debug] [MainThread]: Excluded node 'unique_analytics_orders_order_id' from results
[0m18:55:12.468239 [info ] [MainThread]: Previewing node 'analytics_orders':
| order_id | customer_id | test_project_id | some_metric |
| -------- | ----------- | --------------- | ----------- |
|        1 |           1 |               1 |         100 |
|        2 |           2 |               2 |         200 |
|        3 |           3 |               3 |         150 |

[0m18:55:12.470681 [debug] [MainThread]: Command `dbt show` succeeded at 18:55:12.470405 after 1.49 seconds
[0m18:55:12.471280 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B45BA462D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B45D577070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B45D848AA0>]}
[0m18:55:12.472012 [debug] [MainThread]: Flushing usage events
[0m18:55:13.728351 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:00:20.700675 [error] [MainThread]: Encountered an error:

[0m19:00:20.747716 [error] [MainThread]: Traceback (most recent call last):
  File "C:\Users\karak\dbt_cursor\dbt-env\Lib\site-packages\dbt\cli\requires.py", line 153, in wrapper
    result, success = func(*args, **kwargs)
                      ~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\karak\dbt_cursor\dbt-env\Lib\site-packages\dbt\cli\requires.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\karak\dbt_cursor\dbt-env\Lib\site-packages\dbt\cli\requires.py", line 235, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\karak\dbt_cursor\dbt-env\Lib\site-packages\dbt\cli\requires.py", line 264, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\karak\dbt_cursor\dbt-env\Lib\site-packages\dbt\cli\requires.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\karak\dbt_cursor\dbt-env\Lib\site-packages\dbt\cli\main.py", line 301, in docs_serve
    results = task.run()
  File "C:\Users\karak\dbt_cursor\dbt-env\Lib\site-packages\dbt\task\docs\serve.py", line 29, in run
    httpd.serve_forever()
    ~~~~~~~~~~~~~~~~~~~^^
  File "C:\Python313\Lib\socketserver.py", line 240, in serve_forever
    self._handle_request_noblock()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Python313\Lib\socketserver.py", line 318, in _handle_request_noblock
    self.process_request(request, client_address)
    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python313\Lib\socketserver.py", line 349, in process_request
    self.finish_request(request, client_address)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python313\Lib\socketserver.py", line 362, in finish_request
    self.RequestHandlerClass(request, client_address, self)
    ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python313\Lib\http\server.py", line 672, in __init__
    super().__init__(*args, **kwargs)
    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Python313\Lib\socketserver.py", line 761, in __init__
    self.handle()
    ~~~~~~~~~~~^^
  File "C:\Python313\Lib\http\server.py", line 436, in handle
    self.handle_one_request()
    ~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Python313\Lib\http\server.py", line 404, in handle_one_request
    self.raw_requestline = self.rfile.readline(65537)
                           ~~~~~~~~~~~~~~~~~~~^^^^^^^
  File "C:\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
KeyboardInterrupt

[0m19:00:20.749647 [debug] [MainThread]: Command `dbt docs serve` failed at 19:00:20.749475 after 1670.67 seconds
[0m19:00:20.750087 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000216FD231C50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000216FD231D50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000216FD1B2F30>]}
[0m19:00:20.750495 [debug] [MainThread]: Flushing usage events
[0m19:00:21.728078 [debug] [MainThread]: An error was encountered while trying to flush usage events
